{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "training_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "training_device\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "# Define the mapping from labels to values\n",
    "label_mapping = {\n",
    "    'A1': 0,\n",
    "    'A2': 1,\n",
    "    'B1': 2,\n",
    "    'B2': 3,\n",
    "    'C1': 4,\n",
    "    'C2': 5\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"data/evp.csv\")\n",
    "\n",
    "# Apply the mapping to the 'labels' column\n",
    "df['label'] = df['label'].map(label_mapping)\n",
    "df.dropna(subset=['label'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Value, Sequence\n",
    "new_features = ds.features.copy()\n",
    "new_features[\"label\"] = ClassLabel(names=[0, 1, 2, 3, 4, 5])\n",
    "ds = ds.cast(new_features)\n",
    "\n",
    "# Step 1: Initial train/test split with stratification\n",
    "train_test_ds = ds.train_test_split(test_size=0.20, seed=20)\n",
    "\n",
    "# Step 2: Split the test set into half test, half validation\n",
    "test_valid_split = train_test_ds['test'].train_test_split(test_size=0.5, seed=20)\n",
    "\n",
    "# Step 3: Combine everything into a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_test_ds['train'],\n",
    "    'test': test_valid_split['train'],    # This becomes the test set\n",
    "    'validation': test_valid_split['test']  # This becomes the validation set\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify label distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Train label counts:\", Counter(ds['train']['label']))\n",
    "print(\"Test label counts:\", Counter(ds['test']['label']))\n",
    "print(\"Validation label counts:\", Counter(ds['validation']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(ds[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = ds[\"train\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = ds[\"test\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_validation = ds[\"validation\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(ds['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../model_saved/distilbert-base-ft-speaking-range\",\n",
    "    evaluation_strategy= \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,   \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_test)\n",
    "logits = predictions.predictions\n",
    "\n",
    "predic_ = np.argmax(logits, axis=-1)\n",
    "ref = predictions.label_ids\n",
    "#print(predic_)\n",
    "#print(predictions.predictions, predictions.label_ids)\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "ck = round(cohen_kappa_score(predic_, ref, weights=\"quadratic\"), 2)\n",
    "print(\"cohen kappa==> \",ck)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ref, predic_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the bucket name and file details\n",
    "bucket_name = \"sagemaker-eu-central-1-505049265445\"\n",
    "file_path = \"/home/ec2-user/tmps/llm_fine_tuning/model_saved/distilbert-base-ft-speaking-range_onnx/config.json\"\n",
    "object_name = \"models/config.json\"  # S3 key for the file\n",
    "\n",
    "# Upload the file\n",
    "s3.upload_file(file_path, bucket_name, object_name)\n",
    "print(f\"File {file_path} uploaded to s3://{bucket_name}/{object_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
