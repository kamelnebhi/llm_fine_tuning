{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "training_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "training_device\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate datasets transformers accelerate==1.9.0 wandb safetensors==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>cefr_level</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0015056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3e46481f-4bef-4900-b990-169da9305089</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0000241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>d3ca8e74-ec0f-41a1-8bc3-030edf392772</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>A1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A new colleague is looking for a place to go f...</td>\n",
       "      <td>From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0022001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ad6bb8ac-07c2-415e-8195-19d3791f83d3</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You work for a market research firm. You take ...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0022165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85dc4eb7-4a04-4142-aeb4-740d466bbad1</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write a summary of the report in no more than ...</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0000146</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>57e620bf-efb2-49bf-9f36-ada83b46768d</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>A1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Write a paragraph about how your friend stays ...</td>\n",
       "      <td>My friend stays healthy and fit by exercising ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  nova_judge_score  llama3_judge_score  \\\n",
       "0  CALL0015056                0.0               0.0                 0.0   \n",
       "1  CALL0000241                0.0               0.0                 0.0   \n",
       "2  CALL0022001                0.0               0.0                 0.0   \n",
       "3  CALL0022165                0.0               0.0                 0.0   \n",
       "4  CALL0000146                4.0               5.0                 5.0   \n",
       "\n",
       "   majority_value  agreement_percentage                            writing_id  \\\n",
       "0             0.0            100.000000  3e46481f-4bef-4900-b990-169da9305089   \n",
       "1             0.0            100.000000  d3ca8e74-ec0f-41a1-8bc3-030edf392772   \n",
       "2             0.0            100.000000  ad6bb8ac-07c2-415e-8195-19d3791f83d3   \n",
       "3             0.0            100.000000  85dc4eb7-4a04-4142-aeb4-740d466bbad1   \n",
       "4             5.0             66.666667  57e620bf-efb2-49bf-9f36-ada83b46768d   \n",
       "\n",
       "                                task_id level_title cefr_level  ef_level  \\\n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings         B1       NaN   \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner         A1       2.0   \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research         B1       NaN   \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research         B1       NaN   \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner         A1       2.0   \n",
       "\n",
       "                               activity_instructions  \\\n",
       "0  Your meeting is finishing, and your boss is re...   \n",
       "1  A new colleague is looking for a place to go f...   \n",
       "2  You work for a market research firm. You take ...   \n",
       "3  Write a summary of the report in no more than ...   \n",
       "4  Write a paragraph about how your friend stays ...   \n",
       "\n",
       "                                  student_submission  \n",
       "0  Your meeting is finishing, and your boss is re...  \n",
       "1  From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...  \n",
       "2                                                  s  \n",
       "3                                                  G  \n",
       "4  My friend stays healthy and fit by exercising ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "df = pd.read_csv(\"data/acc_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id\n",
       "cfb893f1-bee1-4894-99f3-43af284493a5    205\n",
       "5c44f26d-2f5c-4039-bcf5-378754d2fe4e    199\n",
       "bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4    196\n",
       "4ce13bf1-4384-44a6-9ff7-5084e02f9e2d    195\n",
       "7e3ee056-1866-488e-88f3-f56af8d22613    193\n",
       "                                       ... \n",
       "e5780a8d-f6ef-4218-9d34-74e064c3e413     25\n",
       "178cfadd-4162-4b5b-aaee-97a1bdcd4d98     25\n",
       "9cf6c0c9-e87b-4e02-84c9-11266ea51d28     25\n",
       "511ccd73-9db8-45e5-8f85-10e244841ce2     23\n",
       "d2196935-4153-4f5c-a1d2-dae31174ae55     19\n",
       "Name: count, Length: 161, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"task_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = (\n",
    "    \"Prompt Level: \" + df['level_title'].astype(str) +\n",
    "    \" [SEP] Prompt: \" + df['activity_instructions'] +\n",
    "    \" [SEP] Response: \" + df['student_submission']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>cefr_level</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0015056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3e46481f-4bef-4900-b990-169da9305089</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "      <td>Prompt Level: Meetings [SEP] Prompt: Your meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0000241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>d3ca8e74-ec0f-41a1-8bc3-030edf392772</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>A1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A new colleague is looking for a place to go f...</td>\n",
       "      <td>From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...</td>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: A new c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0022001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ad6bb8ac-07c2-415e-8195-19d3791f83d3</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You work for a market research firm. You take ...</td>\n",
       "      <td>s</td>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: You work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0022165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85dc4eb7-4a04-4142-aeb4-740d466bbad1</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write a summary of the report in no more than ...</td>\n",
       "      <td>G</td>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: Write a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0000146</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>57e620bf-efb2-49bf-9f36-ada83b46768d</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>A1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Write a paragraph about how your friend stays ...</td>\n",
       "      <td>My friend stays healthy and fit by exercising ...</td>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: Write a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  nova_judge_score  llama3_judge_score  \\\n",
       "0  CALL0015056                0.0               0.0                 0.0   \n",
       "1  CALL0000241                0.0               0.0                 0.0   \n",
       "2  CALL0022001                0.0               0.0                 0.0   \n",
       "3  CALL0022165                0.0               0.0                 0.0   \n",
       "4  CALL0000146                4.0               5.0                 5.0   \n",
       "\n",
       "   majority_value  agreement_percentage                            writing_id  \\\n",
       "0             0.0            100.000000  3e46481f-4bef-4900-b990-169da9305089   \n",
       "1             0.0            100.000000  d3ca8e74-ec0f-41a1-8bc3-030edf392772   \n",
       "2             0.0            100.000000  ad6bb8ac-07c2-415e-8195-19d3791f83d3   \n",
       "3             0.0            100.000000  85dc4eb7-4a04-4142-aeb4-740d466bbad1   \n",
       "4             5.0             66.666667  57e620bf-efb2-49bf-9f36-ada83b46768d   \n",
       "\n",
       "                                task_id level_title cefr_level  ef_level  \\\n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings         B1       NaN   \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner         A1       2.0   \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research         B1       NaN   \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research         B1       NaN   \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner         A1       2.0   \n",
       "\n",
       "                               activity_instructions  \\\n",
       "0  Your meeting is finishing, and your boss is re...   \n",
       "1  A new colleague is looking for a place to go f...   \n",
       "2  You work for a market research firm. You take ...   \n",
       "3  Write a summary of the report in no more than ...   \n",
       "4  Write a paragraph about how your friend stays ...   \n",
       "\n",
       "                                  student_submission  \\\n",
       "0  Your meeting is finishing, and your boss is re...   \n",
       "1  From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...   \n",
       "2                                                  s   \n",
       "3                                                  G   \n",
       "4  My friend stays healthy and fit by exercising ...   \n",
       "\n",
       "                                                text  \n",
       "0  Prompt Level: Meetings [SEP] Prompt: Your meet...  \n",
       "1  Prompt Level: 2-Beginner [SEP] Prompt: A new c...  \n",
       "2  Prompt Level: Research [SEP] Prompt: You work ...  \n",
       "3  Prompt Level: Research [SEP] Prompt: Write a s...  \n",
       "4  Prompt Level: 2-Beginner [SEP] Prompt: Write a...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: Meetings [SEP] Prompt: Your meet...</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: A new c...</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: You work ...</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: Write a s...</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: Write a...</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: Meetings [SEP] Prompt: Your meet...   \n",
       "1  Prompt Level: 2-Beginner [SEP] Prompt: A new c...   \n",
       "2  Prompt Level: Research [SEP] Prompt: You work ...   \n",
       "3  Prompt Level: Research [SEP] Prompt: Write a s...   \n",
       "4  Prompt Level: 2-Beginner [SEP] Prompt: Write a...   \n",
       "\n",
       "                                task_id level_title  label  \n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings    0.0  \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner    0.0  \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research    0.0  \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research    0.0  \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner    5.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"task_id\", \"level_title\", \"majority_value\"]]\n",
    "df = df.rename(columns={'majority_value': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: Meetings [SEP] Prompt: Your meet...</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: A new c...</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: You work ...</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: Write a s...</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: Write a...</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: Meetings [SEP] Prompt: Your meet...   \n",
       "1  Prompt Level: 2-Beginner [SEP] Prompt: A new c...   \n",
       "2  Prompt Level: Research [SEP] Prompt: You work ...   \n",
       "3  Prompt Level: Research [SEP] Prompt: Write a s...   \n",
       "4  Prompt Level: 2-Beginner [SEP] Prompt: Write a...   \n",
       "\n",
       "                                task_id level_title  label  \n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings    0.0  \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner    0.0  \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research    0.0  \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research    0.0  \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner    5.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the mapping to the 'labels' column\n",
    "#df['label'] = df['label'].map(label_mapping)\n",
    "df.dropna(subset=['label', 'text'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "5.0    5682\n",
       "2.0    3726\n",
       "0.0    3662\n",
       "3.0    3018\n",
       "4.0    2985\n",
       "1.0     968\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'task_id', 'level_title', 'label'],\n",
       "    num_rows: 20041\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38ba64c8f66460b8e04d20487075d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/20041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 16032\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 2004\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 2005\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Value, Sequence\n",
    "new_features = ds.features.copy()\n",
    "new_features[\"label\"] = ClassLabel(names=[0, 1, 2, 3, 4, 5])\n",
    "ds = ds.cast(new_features)\n",
    "\n",
    "# Step 1: Initial train/test split with stratification\n",
    "train_test_ds = ds.train_test_split(test_size=0.20, seed=20)\n",
    "\n",
    "# Step 2: Split the test set into half test, half validation\n",
    "test_valid_split = train_test_ds['test'].train_test_split(test_size=0.5, seed=20)\n",
    "\n",
    "# Step 3: Combine everything into a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_test_ds['train'],\n",
    "    'test': test_valid_split['train'],    # This becomes the test set\n",
    "    'validation': test_valid_split['test']  # This becomes the validation set\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts: Counter({5: 4579, 2: 2970, 0: 2910, 3: 2424, 4: 2374, 1: 775})\n",
      "Test label counts: Counter({5: 552, 0: 381, 2: 371, 3: 307, 4: 281, 1: 112})\n",
      "Validation label counts: Counter({5: 551, 2: 385, 0: 371, 4: 330, 3: 287, 1: 81})\n"
     ]
    }
   ],
   "source": [
    "# Verify label distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Train label counts:\", Counter(ds['train']['label']))\n",
    "print(\"Test label counts:\", Counter(ds['test']['label']))\n",
    "print(\"Validation label counts:\", Counter(ds['validation']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fonction utilitaire pour sauvegarder un split en JSONL\n",
    "def save_split_to_jsonl(dataset_split, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for record in dataset_split:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Sauvegarde des trois splits\n",
    "save_split_to_jsonl(ds['train'], 'data/train.jsonl')\n",
    "save_split_to_jsonl(ds['test'], 'data/test.jsonl')\n",
    "save_split_to_jsonl(ds['validation'], 'data/validation.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score, classification_report\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convertir les logits en classes pr√©dictes\n",
    "\n",
    "    # üéØ Exactitude (Accuracy)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # üéØ Pr√©cision, Rappel et F1-score (pond√©r√©s)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # üéØ Score de Cohen's Kappa (pond√©r√©)\n",
    "    cohen_kappa = cohen_kappa_score(labels, predictions, weights=\"quadratic\")\n",
    "\n",
    "    # üéØ Corr√©lation de Pearson\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)  # Retourne (coef, p-valeur), on garde seulement coef\n",
    "\n",
    "     # üéØ Classification Report\n",
    "    class_report = classification_report(labels, predictions, output_dict=True)  # Get a dictionary of the report\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"cohen_kappa\": cohen_kappa,\n",
    "        \"pearson_corr\": pearson_corr,\n",
    "        \"classification_report\": class_report  # Add classification report to the return\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# Charger les fichiers JSONL en DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=\"data/train.jsonl\")[\"train\"],\n",
    "    \"test\": load_dataset(\"json\", data_files=\"data/test.jsonl\")[\"train\"],\n",
    "    \"valid\": load_dataset(\"json\", data_files=\"data/validation.jsonl\")[\"train\"]\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_test = tokenizer(dataset[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-large\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/roberta-large-ft-acc-writing-task-augmented\",\n",
    "    eval_strategy=\"steps\",  # √âvaluation aux m√™mes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # ‚ö† IMPORTANT : √âvaluation aux m√™mes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic = dataset[\"valid\"][\"task_id\"]\n",
    "list_t_set = set(list_topic)\n",
    "unique_t = (list(list_t_set))\n",
    "\n",
    "list_level = dataset[\"valid\"][\"level_title\"]\n",
    "list_l_set = set(list_level)\n",
    "unique_l = (list(list_l_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for t in unique_t:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['task_id'] == t)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"task_id\": t,\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r_level = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for l in unique_l:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['level_title'] == l)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r_level.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results = pd.DataFrame(list_r, columns=[\"task_id\", \"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results.to_csv(\"result_eval_data_roberta_large_writing_task_acc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results_level = pd.DataFrame(list_r_level, columns=[\"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results_level.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results_level.to_csv(\"result_eval_data_roberta_large_acc_by_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from onnxruntime) (4.25.3)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from onnxruntime) (1.14.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/4\u001b[0m [onnxruntime]\u001b[0m [onnxruntime]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnxruntime-1.16.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Chemin vers ton dossier contenant le .bin et le config.json\n",
    "model_dir = \"model_saved/roberta-large-ft-acc-writing-task-augmented/checkpoint-1800\"\n",
    "onnx_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800.onnx\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800-quantized.onnx\"\n",
    "\n",
    "# === √âTAPE 1 : Charger le mod√®le et tokenizer ===\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")\n",
    "model.eval()\n",
    "\n",
    "# === √âTAPE 2 : Pr√©parer un input fictif ===\n",
    "dummy_text = \"Texte d'exemple pour conversion ONNX\"\n",
    "inputs = tokenizer(dummy_text, return_tensors=\"pt\", padding=\"max_length\", max_length=32)\n",
    "\n",
    "# === √âTAPE 3 : Exporter vers ONNX ===\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n",
    "    onnx_model_path,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits\": {0: \"batch_size\"},\n",
    "    },\n",
    "    opset_version=14  # ‚¨ÖÔ∏è change ici\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Mod√®le export√© en ONNX : {onnx_model_path}\")\n",
    "\n",
    "# === √âTAPE 4 : Quantization dynamique ===\n",
    "quantize_dynamic(\n",
    "    model_input=onnx_model_path,\n",
    "    model_output=quantized_model_path,\n",
    "    weight_type=QuantType.QInt8\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Mod√®le quantifi√© en ONNX : {quantized_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "onnx_session_quant = onnxruntime.InferenceSession(quantized_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256  # Ajuste selon la taille maximale de ton mod√®le\n",
    "\n",
    "# Fonction d'inf√©rence ONNX\n",
    "def onnx_infer(input_texts, onnx_model):\n",
    "    inputs = tokenizer(input_texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()\n",
    "    attention_mask = inputs[\"attention_mask\"].numpy()\n",
    "    onnx_inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "    onnx_outputs = onnx_model.run(None, onnx_inputs)\n",
    "    return onnx_outputs[0]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_with_metrics(dataset, onnx_model, batch_size=16):\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    # tqdm pour afficher la progression sur les batches\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Evaluation\"):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = batch[\"text\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        logits = onnx_infer(texts, onnx_model)\n",
    "        all_logits.extend(logits)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    all_logits = np.array(all_logits)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # üî• Appliquer compute_metrics\n",
    "    metrics = compute_metrics((all_logits, all_labels))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'√©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session)\n",
    "print(\"üéØ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nüìã Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'√©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session_quant)\n",
    "print(\"üéØ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nüìã Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ONNX model uploaded to s3://sagemaker-studio-oxs6vznjds/writing_task_models/accuracy/model_1800_roberta_large.onnx\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    \"s3\"\n",
    ")\n",
    "\n",
    "# Define your bucket name and desired path in S3\n",
    "\n",
    "bucket_name = \"sagemaker-studio-oxs6vznjds\"\n",
    "\n",
    "s3_key = \"writing_task_models/accuracy/model_1800_roberta_large.onnx\"  # Change path as needed\n",
    "# Upload the ONNX file\n",
    "bucket_path = \"sagemaker-studio-oxs6vznjds\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800.onnx\"\n",
    "\n",
    "s3.upload_file(quantized_model_path, bucket_path, s3_key)\n",
    "\n",
    "print(f\"‚úÖ ONNX model uploaded to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Onnx from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Define S3 bucket and model key\n",
    "bucket_name = 'sagemaker-studio-oxs6vznjds'\n",
    "model_key = 'writing_task_models/accuracy/model_1800_roberta_large.onnx'\n",
    "local_model_path = '/tmp/roberta-large-ft-acc-writing-task-1800.onnx'  # or wherever you want to save temporarily\n",
    "\n",
    "# Initialize boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Download the ONNX model from S3 to local path\n",
    "s3.download_file(bucket_name, model_key, local_model_path)\n",
    "\n",
    "# Load the ONNX model using onnxruntime\n",
    "session = ort.InferenceSession(local_model_path)\n",
    "\n",
    "print(\"ONNX model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [20:57<00:00,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Evaluation Results ONNX :\n",
      "accuracy: 0.7571072319201995\n",
      "precision: 0.754690191285516\n",
      "recall: 0.7571072319201995\n",
      "f1: 0.7550283590999475\n",
      "cohen_kappa: 0.9127375223497928\n",
      "pearson_corr: 0.9133259543888621\n",
      "\n",
      "üìã Classification Report :\n",
      "0: {'precision': 0.9378378378378378, 'recall': 0.9353099730458221, 'f1-score': 0.9365721997300944, 'support': 371.0}\n",
      "1: {'precision': 0.5964912280701754, 'recall': 0.41975308641975306, 'f1-score': 0.4927536231884058, 'support': 81.0}\n",
      "2: {'precision': 0.7876344086021505, 'recall': 0.7610389610389611, 'f1-score': 0.774108322324967, 'support': 385.0}\n",
      "3: {'precision': 0.5753424657534246, 'recall': 0.5853658536585366, 'f1-score': 0.5803108808290155, 'support': 287.0}\n",
      "4: {'precision': 0.5757575757575758, 'recall': 0.5757575757575758, 'f1-score': 0.5757575757575758, 'support': 330.0}\n",
      "5: {'precision': 0.8321917808219178, 'recall': 0.8820326678765881, 'f1-score': 0.8563876651982378, 'support': 551.0}\n",
      "accuracy: 0.7571072319201995\n",
      "macro avg: {'precision': 0.7175425494738471, 'recall': 0.6932096862995394, 'f1-score': 0.7026483778380493, 'support': 2005.0}\n",
      "weighted avg: {'precision': 0.754690191285516, 'recall': 0.7571072319201995, 'f1-score': 0.7550283590999475, 'support': 2005.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_with_metrics(valid_data, onnx_model=session)\n",
    "print(\"üéØ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nüìã Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
