{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "training_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "training_device\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate datasets transformers accelerate==1.9.0 wandb safetensors==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>cefr_level</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0021715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>295f109e-cfeb-48ce-82ba-ce6f2bf423d2</td>\n",
       "      <td>d491686c-8998-4062-bd13-27562deecdbe</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A client who is thinking about expanding into ...</td>\n",
       "      <td>N n n n n n. N nn n. N n n. N. NN n n n nn n n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0019540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8216749c-2498-4ff2-a241-d66d650689c0</td>\n",
       "      <td>2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now write your counter-proposal. Remember to a...</td>\n",
       "      <td>df f fws wf f wf wf wef we fw fw ef wef ew few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0012294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>dd1cf6a9-aed3-47cf-b094-8a86988c79ae</td>\n",
       "      <td>9032f3ed-5da1-4efe-b4dd-c9470bb35d65</td>\n",
       "      <td>16-Upper Advanced</td>\n",
       "      <td>C2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Read an email from your friend and give advice...</td>\n",
       "      <td>Hey don give up so quickly, give time some tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0005503</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>a2376227-7402-48ee-ad9a-f909f372ccd5</td>\n",
       "      <td>493dffa9-7513-4408-be4b-5b010a1bf051</td>\n",
       "      <td>10-Upper Intermediate</td>\n",
       "      <td>B2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Your manager sent you an email, asking you to ...</td>\n",
       "      <td>Company Update Presentation Outline\\n\\nGreet e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0007695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85cda5c8-7fe7-46ab-83ba-60c3e09c6afd</td>\n",
       "      <td>d040caa5-7bd8-412c-aee2-3d9010b91821</td>\n",
       "      <td>12-Upper Intermediate</td>\n",
       "      <td>B2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>You're going to reply to Alice's blog post abo...</td>\n",
       "      <td>Hi Team,\\n\\nHope you are doing good and it was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  nova_judge_score  llama3_judge_score  \\\n",
       "0  CALL0021715                0.0               0.0                 0.0   \n",
       "1  CALL0019540                0.0               0.0                 0.0   \n",
       "2  CALL0012294                2.0               NaN                 2.0   \n",
       "3  CALL0005503                4.0               4.0                 3.0   \n",
       "4  CALL0007695                0.0               0.0                 0.0   \n",
       "\n",
       "   majority_value  agreement_percentage                            writing_id  \\\n",
       "0             0.0            100.000000  295f109e-cfeb-48ce-82ba-ce6f2bf423d2   \n",
       "1             0.0            100.000000  8216749c-2498-4ff2-a241-d66d650689c0   \n",
       "2             2.0             66.666667  dd1cf6a9-aed3-47cf-b094-8a86988c79ae   \n",
       "3             4.0             66.666667  a2376227-7402-48ee-ad9a-f909f372ccd5   \n",
       "4             0.0            100.000000  85cda5c8-7fe7-46ab-83ba-60c3e09c6afd   \n",
       "\n",
       "                                task_id            level_title cefr_level  \\\n",
       "0  d491686c-8998-4062-bd13-27562deecdbe     Telecommunications         B1   \n",
       "1  2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7              Logistics         B1   \n",
       "2  9032f3ed-5da1-4efe-b4dd-c9470bb35d65      16-Upper Advanced         C2   \n",
       "3  493dffa9-7513-4408-be4b-5b010a1bf051  10-Upper Intermediate         B2   \n",
       "4  d040caa5-7bd8-412c-aee2-3d9010b91821  12-Upper Intermediate         B2   \n",
       "\n",
       "   ef_level                              activity_instructions  \\\n",
       "0       NaN  A client who is thinking about expanding into ...   \n",
       "1       NaN  Now write your counter-proposal. Remember to a...   \n",
       "2      16.0  Read an email from your friend and give advice...   \n",
       "3      10.0  Your manager sent you an email, asking you to ...   \n",
       "4      12.0  You're going to reply to Alice's blog post abo...   \n",
       "\n",
       "                                  student_submission  \n",
       "0  N n n n n n. N nn n. N n n. N. NN n n n nn n n...  \n",
       "1  df f fws wf f wf wf wef we fw fw ef wef ew few...  \n",
       "2  Hey don give up so quickly, give time some tim...  \n",
       "3  Company Update Presentation Outline\\n\\nGreet e...  \n",
       "4  Hi Team,\\n\\nHope you are doing good and it was...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "df = pd.read_csv(\"data/coh_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id\n",
       "cfb893f1-bee1-4894-99f3-43af284493a5    205\n",
       "5c44f26d-2f5c-4039-bcf5-378754d2fe4e    194\n",
       "81ee255e-d4fa-4f81-b77f-dfcf3b5cf541    187\n",
       "5e5c32c9-cdbe-4b4c-9e83-aa4b8b0ec26a    186\n",
       "7e62b6a6-8685-4a0b-b0b2-d902bed0c567    186\n",
       "                                       ... \n",
       "511ccd73-9db8-45e5-8f85-10e244841ce2     26\n",
       "9cf6c0c9-e87b-4e02-84c9-11266ea51d28     24\n",
       "178cfadd-4162-4b5b-aaee-97a1bdcd4d98     24\n",
       "e5780a8d-f6ef-4218-9d34-74e064c3e413     19\n",
       "d2196935-4153-4f5c-a1d2-dae31174ae55     17\n",
       "Name: count, Length: 161, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"task_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = (\n",
    "    \"Prompt Level: \" + df['level_title'].astype(str) +\n",
    "    \" [SEP] Prompt: \" + df['activity_instructions'] +\n",
    "    \" [SEP] Response: \" + df['student_submission']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>cefr_level</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0021715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>295f109e-cfeb-48ce-82ba-ce6f2bf423d2</td>\n",
       "      <td>d491686c-8998-4062-bd13-27562deecdbe</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A client who is thinking about expanding into ...</td>\n",
       "      <td>N n n n n n. N nn n. N n n. N. NN n n n nn n n...</td>\n",
       "      <td>Prompt Level: Telecommunications [SEP] Prompt:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0019540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8216749c-2498-4ff2-a241-d66d650689c0</td>\n",
       "      <td>2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now write your counter-proposal. Remember to a...</td>\n",
       "      <td>df f fws wf f wf wf wef we fw fw ef wef ew few...</td>\n",
       "      <td>Prompt Level: Logistics [SEP] Prompt: Now writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0012294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>dd1cf6a9-aed3-47cf-b094-8a86988c79ae</td>\n",
       "      <td>9032f3ed-5da1-4efe-b4dd-c9470bb35d65</td>\n",
       "      <td>16-Upper Advanced</td>\n",
       "      <td>C2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Read an email from your friend and give advice...</td>\n",
       "      <td>Hey don give up so quickly, give time some tim...</td>\n",
       "      <td>Prompt Level: 16-Upper Advanced [SEP] Prompt: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0005503</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>a2376227-7402-48ee-ad9a-f909f372ccd5</td>\n",
       "      <td>493dffa9-7513-4408-be4b-5b010a1bf051</td>\n",
       "      <td>10-Upper Intermediate</td>\n",
       "      <td>B2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Your manager sent you an email, asking you to ...</td>\n",
       "      <td>Company Update Presentation Outline\\n\\nGreet e...</td>\n",
       "      <td>Prompt Level: 10-Upper Intermediate [SEP] Prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0007695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85cda5c8-7fe7-46ab-83ba-60c3e09c6afd</td>\n",
       "      <td>d040caa5-7bd8-412c-aee2-3d9010b91821</td>\n",
       "      <td>12-Upper Intermediate</td>\n",
       "      <td>B2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>You're going to reply to Alice's blog post abo...</td>\n",
       "      <td>Hi Team,\\n\\nHope you are doing good and it was...</td>\n",
       "      <td>Prompt Level: 12-Upper Intermediate [SEP] Prom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  nova_judge_score  llama3_judge_score  \\\n",
       "0  CALL0021715                0.0               0.0                 0.0   \n",
       "1  CALL0019540                0.0               0.0                 0.0   \n",
       "2  CALL0012294                2.0               NaN                 2.0   \n",
       "3  CALL0005503                4.0               4.0                 3.0   \n",
       "4  CALL0007695                0.0               0.0                 0.0   \n",
       "\n",
       "   majority_value  agreement_percentage                            writing_id  \\\n",
       "0             0.0            100.000000  295f109e-cfeb-48ce-82ba-ce6f2bf423d2   \n",
       "1             0.0            100.000000  8216749c-2498-4ff2-a241-d66d650689c0   \n",
       "2             2.0             66.666667  dd1cf6a9-aed3-47cf-b094-8a86988c79ae   \n",
       "3             4.0             66.666667  a2376227-7402-48ee-ad9a-f909f372ccd5   \n",
       "4             0.0            100.000000  85cda5c8-7fe7-46ab-83ba-60c3e09c6afd   \n",
       "\n",
       "                                task_id            level_title cefr_level  \\\n",
       "0  d491686c-8998-4062-bd13-27562deecdbe     Telecommunications         B1   \n",
       "1  2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7              Logistics         B1   \n",
       "2  9032f3ed-5da1-4efe-b4dd-c9470bb35d65      16-Upper Advanced         C2   \n",
       "3  493dffa9-7513-4408-be4b-5b010a1bf051  10-Upper Intermediate         B2   \n",
       "4  d040caa5-7bd8-412c-aee2-3d9010b91821  12-Upper Intermediate         B2   \n",
       "\n",
       "   ef_level                              activity_instructions  \\\n",
       "0       NaN  A client who is thinking about expanding into ...   \n",
       "1       NaN  Now write your counter-proposal. Remember to a...   \n",
       "2      16.0  Read an email from your friend and give advice...   \n",
       "3      10.0  Your manager sent you an email, asking you to ...   \n",
       "4      12.0  You're going to reply to Alice's blog post abo...   \n",
       "\n",
       "                                  student_submission  \\\n",
       "0  N n n n n n. N nn n. N n n. N. NN n n n nn n n...   \n",
       "1  df f fws wf f wf wf wef we fw fw ef wef ew few...   \n",
       "2  Hey don give up so quickly, give time some tim...   \n",
       "3  Company Update Presentation Outline\\n\\nGreet e...   \n",
       "4  Hi Team,\\n\\nHope you are doing good and it was...   \n",
       "\n",
       "                                                text  \n",
       "0  Prompt Level: Telecommunications [SEP] Prompt:...  \n",
       "1  Prompt Level: Logistics [SEP] Prompt: Now writ...  \n",
       "2  Prompt Level: 16-Upper Advanced [SEP] Prompt: ...  \n",
       "3  Prompt Level: 10-Upper Intermediate [SEP] Prom...  \n",
       "4  Prompt Level: 12-Upper Intermediate [SEP] Prom...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: Telecommunications [SEP] Prompt:...</td>\n",
       "      <td>d491686c-8998-4062-bd13-27562deecdbe</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: Logistics [SEP] Prompt: Now writ...</td>\n",
       "      <td>2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: 16-Upper Advanced [SEP] Prompt: ...</td>\n",
       "      <td>9032f3ed-5da1-4efe-b4dd-c9470bb35d65</td>\n",
       "      <td>16-Upper Advanced</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: 10-Upper Intermediate [SEP] Prom...</td>\n",
       "      <td>493dffa9-7513-4408-be4b-5b010a1bf051</td>\n",
       "      <td>10-Upper Intermediate</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 12-Upper Intermediate [SEP] Prom...</td>\n",
       "      <td>d040caa5-7bd8-412c-aee2-3d9010b91821</td>\n",
       "      <td>12-Upper Intermediate</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: Telecommunications [SEP] Prompt:...   \n",
       "1  Prompt Level: Logistics [SEP] Prompt: Now writ...   \n",
       "2  Prompt Level: 16-Upper Advanced [SEP] Prompt: ...   \n",
       "3  Prompt Level: 10-Upper Intermediate [SEP] Prom...   \n",
       "4  Prompt Level: 12-Upper Intermediate [SEP] Prom...   \n",
       "\n",
       "                                task_id            level_title  label  \n",
       "0  d491686c-8998-4062-bd13-27562deecdbe     Telecommunications    0.0  \n",
       "1  2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7              Logistics    0.0  \n",
       "2  9032f3ed-5da1-4efe-b4dd-c9470bb35d65      16-Upper Advanced    2.0  \n",
       "3  493dffa9-7513-4408-be4b-5b010a1bf051  10-Upper Intermediate    4.0  \n",
       "4  d040caa5-7bd8-412c-aee2-3d9010b91821  12-Upper Intermediate    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"task_id\", \"level_title\", \"majority_value\"]]\n",
    "df = df.rename(columns={'majority_value': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: Telecommunications [SEP] Prompt:...</td>\n",
       "      <td>d491686c-8998-4062-bd13-27562deecdbe</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: Logistics [SEP] Prompt: Now writ...</td>\n",
       "      <td>2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: 16-Upper Advanced [SEP] Prompt: ...</td>\n",
       "      <td>9032f3ed-5da1-4efe-b4dd-c9470bb35d65</td>\n",
       "      <td>16-Upper Advanced</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: 10-Upper Intermediate [SEP] Prom...</td>\n",
       "      <td>493dffa9-7513-4408-be4b-5b010a1bf051</td>\n",
       "      <td>10-Upper Intermediate</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 12-Upper Intermediate [SEP] Prom...</td>\n",
       "      <td>d040caa5-7bd8-412c-aee2-3d9010b91821</td>\n",
       "      <td>12-Upper Intermediate</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: Telecommunications [SEP] Prompt:...   \n",
       "1  Prompt Level: Logistics [SEP] Prompt: Now writ...   \n",
       "2  Prompt Level: 16-Upper Advanced [SEP] Prompt: ...   \n",
       "3  Prompt Level: 10-Upper Intermediate [SEP] Prom...   \n",
       "4  Prompt Level: 12-Upper Intermediate [SEP] Prom...   \n",
       "\n",
       "                                task_id            level_title  label  \n",
       "0  d491686c-8998-4062-bd13-27562deecdbe     Telecommunications    0.0  \n",
       "1  2e74edfb-ed33-4ca0-b50c-d5c0ebda76b7              Logistics    0.0  \n",
       "2  9032f3ed-5da1-4efe-b4dd-c9470bb35d65      16-Upper Advanced    2.0  \n",
       "3  493dffa9-7513-4408-be4b-5b010a1bf051  10-Upper Intermediate    4.0  \n",
       "4  d040caa5-7bd8-412c-aee2-3d9010b91821  12-Upper Intermediate    0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the mapping to the 'labels' column\n",
    "#df['label'] = df['label'].map(label_mapping)\n",
    "df.dropna(subset=['label', 'text'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "5.0    5302\n",
       "4.0    4056\n",
       "0.0    3881\n",
       "2.0    2699\n",
       "3.0    1925\n",
       "1.0    1048\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'task_id', 'level_title', 'label'],\n",
       "    num_rows: 18911\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d0a336823841d4b5684791943a98b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/18911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 15128\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 1891\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 1892\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Value, Sequence\n",
    "new_features = ds.features.copy()\n",
    "new_features[\"label\"] = ClassLabel(names=[0, 1, 2, 3, 4, 5])\n",
    "ds = ds.cast(new_features)\n",
    "\n",
    "# Step 1: Initial train/test split with stratification\n",
    "train_test_ds = ds.train_test_split(test_size=0.20, seed=20)\n",
    "\n",
    "# Step 2: Split the test set into half test, half validation\n",
    "test_valid_split = train_test_ds['test'].train_test_split(test_size=0.5, seed=20)\n",
    "\n",
    "# Step 3: Combine everything into a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_test_ds['train'],\n",
    "    'test': test_valid_split['train'],    # This becomes the test set\n",
    "    'validation': test_valid_split['test']  # This becomes the validation set\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts: Counter({5: 4242, 4: 3200, 0: 3119, 2: 2161, 3: 1561, 1: 845})\n",
      "Test label counts: Counter({5: 539, 4: 416, 0: 373, 2: 275, 3: 174, 1: 114})\n",
      "Validation label counts: Counter({5: 521, 4: 440, 0: 389, 2: 263, 3: 190, 1: 89})\n"
     ]
    }
   ],
   "source": [
    "# Verify label distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Train label counts:\", Counter(ds['train']['label']))\n",
    "print(\"Test label counts:\", Counter(ds['test']['label']))\n",
    "print(\"Validation label counts:\", Counter(ds['validation']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fonction utilitaire pour sauvegarder un split en JSONL\n",
    "def save_split_to_jsonl(dataset_split, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for record in dataset_split:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Sauvegarde des trois splits\n",
    "save_split_to_jsonl(ds['train'], 'data/train.jsonl')\n",
    "save_split_to_jsonl(ds['test'], 'data/test.jsonl')\n",
    "save_split_to_jsonl(ds['validation'], 'data/validation.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score, classification_report\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convertir les logits en classes prÃ©dictes\n",
    "\n",
    "    # ðŸŽ¯ Exactitude (Accuracy)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # ðŸŽ¯ PrÃ©cision, Rappel et F1-score (pondÃ©rÃ©s)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # ðŸŽ¯ Score de Cohen's Kappa (pondÃ©rÃ©)\n",
    "    cohen_kappa = cohen_kappa_score(labels, predictions, weights=\"quadratic\")\n",
    "\n",
    "    # ðŸŽ¯ CorrÃ©lation de Pearson\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)  # Retourne (coef, p-valeur), on garde seulement coef\n",
    "\n",
    "     # ðŸŽ¯ Classification Report\n",
    "    class_report = classification_report(labels, predictions, output_dict=True)  # Get a dictionary of the report\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"cohen_kappa\": cohen_kappa,\n",
    "        \"pearson_corr\": pearson_corr,\n",
    "        \"classification_report\": class_report  # Add classification report to the return\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5000c83859e945ffa88163a9c45b55b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b507779b91460d98134770cd9de091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735523a18d0b448a892058599f249ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'task_id', 'level_title', 'label'],\n",
      "        num_rows: 15128\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'task_id', 'level_title', 'label'],\n",
      "        num_rows: 1891\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'task_id', 'level_title', 'label'],\n",
      "        num_rows: 1892\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# Charger les fichiers JSONL en DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=\"data/train.jsonl\")[\"train\"],\n",
    "    \"test\": load_dataset(\"json\", data_files=\"data/test.jsonl\")[\"train\"],\n",
    "    \"valid\": load_dataset(\"json\", data_files=\"data/validation.jsonl\")[\"train\"]\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Prompt Level: 15-Advanced [SEP] Prompt: Read Ken's email and then email Josh and Ken a third option. Use your imagination. You can create any facts about your city that will support your proposal. Type in the input box. Write 150-200 words. [SEP] Response: Hello Josh, Ken,\\nI hope I can propose third option for you. It should be the best compromise of two options which you have considered so long.\\nThe idea is based on the fact that two third of our current shop is not seen by our customers. We have cloth making area and administration area in our shop. They can be moved to south end of the town while keeping showroom and measurement space in downtown.\\nThis kind of separation cannot be done in the past because our cloth making section needs to have close contact with measurement service section. However, thanks to IT development, now we can share measurement data immediately and we can start making cloth just after measurement, even though cloth making room is far from our showroom/ measurement space. \\nIn my rough calculation, it saves us $2000 a month while keeping our current quality and visibility.\\nI hope this proposal helps you to break through the challenge you are facing now.\\n\\nSincerely\\nEF student\",\n",
       " 'task_id': 'c7972fb8-c4a3-4fd8-8892-33804a60162e',\n",
       " 'level_title': '15-Advanced',\n",
       " 'label': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 35396, 3320, 12183, 35, 508, 12, 44694, 646, 3388, 510, 742, 42944, 35, 9387, 9, 402, 7735, 6, 3571, 50, 6269, 14, 1102, 7, 47, 682, 6, 8, 6190, 24, 11, 41, 1047, 7, 10, 1441, 4, 5293, 24, 2679, 8, 42690, 6, 8, 2145, 7, 1649, 13, 44811, 5135, 4, 7773, 11, 5, 8135, 2233, 4, 21062, 3982, 12, 2619, 1617, 4, 646, 3388, 510, 742, 19121, 35, 12191, 1560, 6, 50118, 50118, 1185, 351, 75, 679, 99, 1102, 7, 162, 94, 363, 328, 38, 21, 11963, 15, 5, 26711, 2494, 10, 1569, 137, 3630, 77, 38, 1317, 10, 7735, 6496, 31, 20806, 4, 38, 34576, 89, 21, 5907, 1207, 11, 5, 2853, 1553, 27699, 6, 98, 38, 1276, 7, 8861, 24, 4, 125, 172, 6, 10, 92, 543, 2058, 2369, 37747, 162, 4, 38, 1224, 160, 5, 30016, 6, 342, 15, 127, 3581, 268, 8, 3203, 62, 7, 5, 371, 1929, 4, 38, 6536, 15, 5, 1883, 142, 24, 21, 628, 615, 7, 32366, 5670, 1493, 4, 440, 1948, 4, 38, 1381, 7, 1224, 15, 5, 1109, 9, 5, 14106, 6, 53, 24, 399, 75, 173, 4, 22, 713, 1068, 16, 1158, 7, 32580, 225, 162, 1297, 38, 802, 4, 38, 6536, 456, 6, 117, 1948, 6, 117, 27903, 31, 5, 1025, 9, 5, 790, 4, 38, 1276, 6, 172, 6, 7, 1656, 124, 184, 77, 38, 2967, 5, 1219, 9, 167, 4100, 23814, 4428, 35, 9014, 6, 5, 6269, 8, 6664, 18845, 3418, 4758, 9, 5, 12258, 4, 38, 21, 1341, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_test = tokenizer(dataset[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85214e4d3e9c46248addf71dec1c35b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13be26c8a56c41caaceac0f67b875807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1891 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77712692912d4357b5cd52f6be122d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-large\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/roberta-large-ft-acc-writing-task-augmented\",\n",
    "    eval_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic = dataset[\"valid\"][\"task_id\"]\n",
    "list_t_set = set(list_topic)\n",
    "unique_t = (list(list_t_set))\n",
    "\n",
    "list_level = dataset[\"valid\"][\"level_title\"]\n",
    "list_l_set = set(list_level)\n",
    "unique_l = (list(list_l_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for t in unique_t:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['task_id'] == t)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"task_id\": t,\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r_level = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for l in unique_l:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['level_title'] == l)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r_level.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results = pd.DataFrame(list_r, columns=[\"task_id\", \"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results.to_csv(\"result_eval_data_roberta_large_writing_task_acc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results_level = pd.DataFrame(list_r_level, columns=[\"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results_level.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results_level.to_csv(\"result_eval_data_roberta_large_acc_by_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨le exportÃ© en ONNX : model_saved/roberta-large-ft-coh-writing-task-1200.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.0/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.0/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.1/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.1/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.2/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.2/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.3/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.3/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.4/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.4/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.5/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.5/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.6/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.6/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.7/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.7/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.8/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.8/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.9/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.9/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.10/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.10/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.11/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.11/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.12/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.12/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.13/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.13/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.14/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.14/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.15/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.15/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.16/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.16/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.17/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.17/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.18/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.18/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.19/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.19/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.20/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.20/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.21/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.21/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.22/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.22/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.23/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.23/attention/self/MatMul_1]\n",
      "âœ… ModÃ¨le quantifiÃ© en ONNX : model_saved/roberta-large-ft-coh-writing-task-1200-quantized.onnx\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Chemin vers ton dossier contenant le .bin et le config.json\n",
    "model_dir = \"model_saved/roberta-large-ft-coh-writing-task-augmented/checkpoint-1200\"\n",
    "onnx_model_path = \"model_saved/roberta-large-ft-coh-writing-task-1200.onnx\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-coh-writing-task-1200-quantized.onnx\"\n",
    "\n",
    "# === Ã‰TAPE 1 : Charger le modÃ¨le et tokenizer ===\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")\n",
    "model.eval()\n",
    "\n",
    "# === Ã‰TAPE 2 : PrÃ©parer un input fictif ===\n",
    "dummy_text = \"Texte d'exemple pour conversion ONNX\"\n",
    "inputs = tokenizer(dummy_text, return_tensors=\"pt\", padding=\"max_length\", max_length=256)\n",
    "\n",
    "# === Ã‰TAPE 3 : Exporter vers ONNX ===\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n",
    "    onnx_model_path,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits\": {0: \"batch_size\"},\n",
    "    },\n",
    "    opset_version=14  # â¬…ï¸ change ici\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le exportÃ© en ONNX : {onnx_model_path}\")\n",
    "\n",
    "# === Ã‰TAPE 4 : Quantization dynamique ===\n",
    "quantize_dynamic(\n",
    "    model_input=onnx_model_path,\n",
    "    model_output=quantized_model_path,\n",
    "    weight_type=QuantType.QInt8\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le quantifiÃ© en ONNX : {quantized_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "onnx_session_quant = onnxruntime.InferenceSession(quantized_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256  # Ajuste selon la taille maximale de ton modÃ¨le\n",
    "\n",
    "# Fonction d'infÃ©rence ONNX\n",
    "def onnx_infer(input_texts, onnx_model):\n",
    "    inputs = tokenizer(input_texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()\n",
    "    attention_mask = inputs[\"attention_mask\"].numpy()\n",
    "    onnx_inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "    onnx_outputs = onnx_model.run(None, onnx_inputs)\n",
    "    return onnx_outputs[0]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_with_metrics(dataset, onnx_model, batch_size=16):\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    # tqdm pour afficher la progression sur les batches\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Evaluation\"):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = batch[\"text\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        logits = onnx_infer(texts, onnx_model)\n",
    "        all_logits.extend(logits)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    all_logits = np.array(all_logits)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # ðŸ”¥ Appliquer compute_metrics\n",
    "    metrics = compute_metrics((all_logits, all_labels))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session_quant)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ONNX model uploaded to s3://sagemaker-studio-oxs6vznjds/writing_task_models/coherence/model_1200_roberta_large.onnx\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    \"s3\"\n",
    ")\n",
    "\n",
    "# Define your bucket name and desired path in S3\n",
    "\n",
    "bucket_name = \"sagemaker-studio-oxs6vznjds\"\n",
    "\n",
    "s3_key = \"writing_task_models/coherence/model_1200_roberta_large.onnx\"  # Change path as needed\n",
    "# Upload the ONNX file\n",
    "bucket_path = \"sagemaker-studio-oxs6vznjds\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-coh-writing-task-1200.onnx\"\n",
    "\n",
    "s3.upload_file(quantized_model_path, bucket_path, s3_key)\n",
    "\n",
    "print(f\"âœ… ONNX model uploaded to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Onnx from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Define S3 bucket and model key\n",
    "bucket_name = 'sagemaker-studio-oxs6vznjds'\n",
    "model_key = 'writing_task_models/coherence/model_1200_roberta_large.onnx'\n",
    "local_model_path = '/tmp/roberta-large-ft-coh-writing-task-1200.onnx'  # or wherever you want to save temporarily\n",
    "\n",
    "# Initialize boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Download the ONNX model from S3 to local path\n",
    "s3.download_file(bucket_name, model_key, local_model_path)\n",
    "\n",
    "# Load the ONNX model using onnxruntime\n",
    "session = ort.InferenceSession(local_model_path)\n",
    "\n",
    "print(\"ONNX model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119/119 [19:14<00:00,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Evaluation Results ONNX :\n",
      "accuracy: 0.7383720930232558\n",
      "precision: 0.7296393490741157\n",
      "recall: 0.7383720930232558\n",
      "f1: 0.7317138791909125\n",
      "cohen_kappa: 0.9188212348368494\n",
      "pearson_corr: 0.9206092784398368\n",
      "\n",
      "ðŸ“‹ Classification Report :\n",
      "0: {'precision': 0.9460916442048517, 'recall': 0.9023136246786633, 'f1-score': 0.9236842105263158, 'support': 389.0}\n",
      "1: {'precision': 0.5833333333333334, 'recall': 0.39325842696629215, 'f1-score': 0.4697986577181208, 'support': 89.0}\n",
      "2: {'precision': 0.648936170212766, 'recall': 0.6958174904942965, 'f1-score': 0.671559633027523, 'support': 263.0}\n",
      "3: {'precision': 0.3973509933774834, 'recall': 0.3157894736842105, 'f1-score': 0.3519061583577713, 'support': 190.0}\n",
      "4: {'precision': 0.6591928251121076, 'recall': 0.6681818181818182, 'f1-score': 0.6636568848758465, 'support': 440.0}\n",
      "5: {'precision': 0.8144329896907216, 'recall': 0.9097888675623801, 'f1-score': 0.8594741613780599, 'support': 521.0}\n",
      "accuracy: 0.7383720930232558\n",
      "macro avg: {'precision': 0.6748896593218773, 'recall': 0.6475249502612769, 'f1-score': 0.6566799509806062, 'support': 1892.0}\n",
      "weighted avg: {'precision': 0.7296393490741157, 'recall': 0.7383720930232558, 'f1-score': 0.7317138791909125, 'support': 1892.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_with_metrics(valid_data, onnx_model=session)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
