{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate transformers[torch] wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wkddvfsm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ced3d16d9d4c06bd1e872f59cfa248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇████</td></tr><tr><td>eval/f1</td><td>▁▇████</td></tr><tr><td>eval/loss</td><td>█▁▁▆▅▁</td></tr><tr><td>eval/runtime</td><td>▆▁█▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▃█▁▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▃█▁▇▇▇</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▃▅▆███</td></tr><tr><td>train/global_step</td><td>▁▃▅▆████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.85</td></tr><tr><td>eval/f1</td><td>0.84995</td></tr><tr><td>eval/loss</td><td>0.38905</td></tr><tr><td>eval/runtime</td><td>0.2228</td></tr><tr><td>eval/samples_per_second</td><td>448.752</td></tr><tr><td>eval/steps_per_second</td><td>31.413</td></tr><tr><td>test/accuracy</td><td>0.87</td></tr><tr><td>test/f1</td><td>0.86999</td></tr><tr><td>test/loss</td><td>0.36537</td></tr><tr><td>test/runtime</td><td>0.2225</td></tr><tr><td>test/samples_per_second</td><td>449.403</td></tr><tr><td>test/steps_per_second</td><td>31.458</td></tr><tr><td>total_flos</td><td>263111055360000.0</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>250</td></tr><tr><td>train_loss</td><td>0.37392</td></tr><tr><td>train_runtime</td><td>42.0151</td></tr><tr><td>train_samples_per_second</td><td>95.204</td></tr><tr><td>train_steps_per_second</td><td>5.95</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-rain-8</strong> at: <a href='https://wandb.ai/knebhi/twitter_sentiment_classifier/runs/wkddvfsm' target=\"_blank\">https://wandb.ai/knebhi/twitter_sentiment_classifier/runs/wkddvfsm</a><br/> View project at: <a href='https://wandb.ai/knebhi/twitter_sentiment_classifier' target=\"_blank\">https://wandb.ai/knebhi/twitter_sentiment_classifier</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240908_183318-wkddvfsm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wkddvfsm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1caa5760e14891be100cfc5b23ce05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112276699956661, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/tmp/llm_fine_tuning/slm/wandb/run-20240908_183459-s3m9nwej</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/knebhi/twitter_sentiment_classifier/runs/s3m9nwej' target=\"_blank\">eager-resonance-9</a></strong> to <a href='https://wandb.ai/knebhi/twitter_sentiment_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/knebhi/twitter_sentiment_classifier' target=\"_blank\">https://wandb.ai/knebhi/twitter_sentiment_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/knebhi/twitter_sentiment_classifier/runs/s3m9nwej' target=\"_blank\">https://wandb.ai/knebhi/twitter_sentiment_classifier/runs/s3m9nwej</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/knebhi/twitter_sentiment_classifier/runs/s3m9nwej?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7a2820acb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize a W&B run\n",
    "wandb.init(project='twitter_sentiment_classifier', entity='knebhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from s3 bucket\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region_name = 'eu-central-1'\n",
    "\n",
    "session = boto3.Session(region_name=region_name)\n",
    "s3_sess = session.client('s3')\n",
    "sm_session = sagemaker.Session(boto_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_positive          id                      datetime           user  \\\n",
      "0            0  1467810672  Mon Apr 06 22:19:49 PDT 2009  scotthamilton   \n",
      "1            0  1467810917  Mon Apr 06 22:19:53 PDT 2009       mattycus   \n",
      "2            0  1467811184  Mon Apr 06 22:19:57 PDT 2009        ElleCTF   \n",
      "3            0  1467811193  Mon Apr 06 22:19:57 PDT 2009         Karoli   \n",
      "4            0  1467811372  Mon Apr 06 22:20:00 PDT 2009       joy_wolf   \n",
      "\n",
      "                                             message  \n",
      "0  is upset that he can't update his Facebook by ...  \n",
      "1  @Kenichan I dived many times for the ball. Man...  \n",
      "2    my whole body feels itchy and like its on fire   \n",
      "3  @nationwideclass no, it's not behaving at all....  \n",
      "4                      @Kwesidei not the whole crew   \n",
      "(1599999, 5)\n"
     ]
    }
   ],
   "source": [
    "# Define the bucket name and the CSV file key (path in the bucket)\n",
    "bucket_name = 'sagemaker-eu-central-1-505049265445'\n",
    "csv_file_key = 'datasets/twitter_ds/twitter_dataset_full.csv'\n",
    "\n",
    "# Fetch the CSV file content from S3\n",
    "obj = s3_sess.get_object(Bucket=bucket_name, Key=csv_file_key)\n",
    "data = obj['Body'].read().decode('utf-8')\n",
    "\n",
    "# Convert the content to a pandas DataFrame\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to check if a tweet has at least three tokens\n",
    "def has_at_least_three_tokens(message):\n",
    "    tokens = message.split()\n",
    "    return len(tokens) >= 3\n",
    "\n",
    "# Function to check if a tweet contains a URL\n",
    "def contains_url(message):\n",
    "    # Regex to detect URLs\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return bool(re.search(url_pattern, message))\n",
    "\n",
    "# Filter tweets with at least three tokens and no URLs\n",
    "df_filtered = df[df['message'].apply(lambda x: has_at_least_three_tokens(x) and not contains_url(x))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1498948, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered[[\"message\",\"is_positive\"]]\n",
    "df_filtered = df_filtered.rename(columns={'is_positive': 'label', 'message': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_filtered.sample(n=1498948, random_state=42)  # 'random_state' ensures reproducibility\n",
    "#df_sample = df  # 'random_state' ensures reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5151\n",
       "1    4849\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 8000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Drop the index from the DataFrame before conversion\n",
    "df_sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert the pandas DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df_sample)\n",
    "\n",
    "# Proceed with the train/test/validation split as before\n",
    "train_testvalid = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Combine train, validation, and test sets into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'validation': test_valid['train'],\n",
    "    'test': test_valid['test']\n",
    "})\n",
    "\n",
    "# Display the DatasetDict structure\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fb3597555747a28111e93c4ec635bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0606db78eb4c8da223d3cf559f606e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846ab0d7677c4472abadb362a95751b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to:\n",
      "s3://sagemaker-eu-central-1-505049265445/datasets/twitter_ds//train/dataset.json\n",
      "s3://sagemaker-eu-central-1-505049265445/datasets/twitter_ds//test/dataset.json\n",
      "s3://sagemaker-eu-central-1-505049265445/datasets/twitter_ds//validation/dataset.json\n",
      "https://s3.console.aws.amazon.com/s3/buckets/sagemaker-eu-central-1-505049265445/?region=eu-central-1&prefix=datasets/twitter_ds//\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "input_path = f's3://{sm_session.default_bucket()}/datasets/twitter_ds/'\n",
    "\n",
    "# save datasets to s3\n",
    "dataset[\"train\"].to_json(f\"{input_path}/train/dataset.json\", orient=\"records\")\n",
    "train_dataset_s3_path = f\"{input_path}/train/dataset.json\"\n",
    "dataset[\"test\"].to_json(f\"{input_path}/test/dataset.json\", orient=\"records\")\n",
    "test_dataset_s3_path = f\"{input_path}/test/dataset.json\"\n",
    "dataset[\"validation\"].to_json(f\"{input_path}/validation/dataset.json\", orient=\"records\")\n",
    "validation_dataset_s3_path = f\"{input_path}/validation/dataset.json\"\n",
    "\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(test_dataset_s3_path)\n",
    "print(validation_dataset_s3_path)\n",
    "\n",
    "print(f\"https://s3.console.aws.amazon.com/s3/buckets/{sm_session.default_bucket()}/?region={sm_session.boto_region_name}&prefix={input_path.split('/', 3)[-1]}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 611, 1873, 225, 23, 10721, 1253, 13, 10, 828, 2156, 1303, 939, 300, 385, 17670, 27785, 1437, 1437, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f624ae66b84488bc2e8eb3be4ba844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff88404c9484e7f8572e435d4c893b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9a8fbd7a1d46c58ca2f4abfad5958c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_validation = dataset[\"validation\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(dataset['test']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "# Load the evaluation metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    # Compute F1 score (use 'macro', 'micro', or 'weighted' depending on your task)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    \n",
    "    # Return both metrics\n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],  # Access the 'accuracy' key from the accuracy result\n",
    "        'f1': f1['f1'],                    # Access the 'f1' key from the F1 result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../model_saved/roberta-twitter-sa\",\n",
    "    eval_strategy= \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1,\n",
    "    report_to='wandb' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  32/2500 00:03 < 04:39, 8.83 it/s, Epoch 0.06/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.2570807952880859, metrics={'train_runtime': 313.8375, 'train_samples_per_second': 127.455, 'train_steps_per_second': 7.966, 'total_flos': 2631110553600000.0, 'train_loss': 0.2570807952880859, 'epoch': 5.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/63 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8474410772323608,\n",
       " 'eval_accuracy': 0.849,\n",
       " 'eval_f1': 0.8490176939124408,\n",
       " 'eval_runtime': 2.0417,\n",
       " 'eval_samples_per_second': 489.778,\n",
       " 'eval_steps_per_second': 30.856,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform evaluation on the validation dataset\n",
    "test_results = trainer.predict(test_dataset=tokenized_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.8417901396751404,\n",
       " 'test_accuracy': 0.845,\n",
       " 'test_f1': 0.8450147303176446,\n",
       " 'test_runtime': 2.1152,\n",
       " 'test_samples_per_second': 472.764,\n",
       " 'test_steps_per_second': 29.784}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract predictions, labels, and metrics\n",
    "predictions = test_results.predictions\n",
    "labels = test_results.label_ids\n",
    "metrics = test_results.metrics\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
