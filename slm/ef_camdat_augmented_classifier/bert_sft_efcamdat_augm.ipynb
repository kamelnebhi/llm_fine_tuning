{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting accelerate==0.26.0\n",
      "  Downloading accelerate-0.26.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.26.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.26.0) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.26.0) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.26.0) (2.2.2)\n",
      "Collecting huggingface-hub (from accelerate==0.26.0)\n",
      "  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate==0.26.0)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (0.3.9)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from evaluate) (0.70.17)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (19.0.0)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.26.0) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.26.0) (3.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.0) (3.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.26.0) (1.3.0)\n",
      "Downloading accelerate-0.26.0-py3-none-any.whl (270 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m169.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading aiohttp-3.11.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m167.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, accelerate, transformers, datasets, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.17\n",
      "    Uninstalling multiprocess-0.70.17:\n",
      "      Successfully uninstalled multiprocess-0.70.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.26.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.5.0 dill-0.3.8 evaluate-0.4.3 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.30.1 multidict-6.2.0 multiprocess-0.70.16 propcache-0.3.1 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.50.3 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate datasets transformers accelerate==0.26.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cac74a02a3e43e4a85d430020dfc82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7059 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aba5a77a0da4c2b9fceebcb3eb37332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/882 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 7059\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 882\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 883\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 6179\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 782\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 883\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# Charger les fichiers JSONL en DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=\"data/train.json\")[\"train\"],\n",
    "    \"test\": load_dataset(\"json\", data_files=\"data/test.json\")[\"train\"],\n",
    "    \"valid\": load_dataset(\"json\", data_files=\"data/valid.json\")[\"train\"]\n",
    "})\n",
    "\n",
    "dataset_not_synthetic_in_train = DatasetDict({\n",
    "    \"train\": dataset[\"train\"].filter(lambda example: example[\"item_id\"] <= 44),\n",
    "    \"test\": dataset[\"test\"].filter(lambda example: example[\"item_id\"] <= 44),\n",
    "    \"valid\": dataset[\"valid\"]  # Keep validation set unchanged\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "print(dataset_not_synthetic_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Prompt Level: 2 [SEP] Prompt: What activities do you do at school? [SEP] Response: I'm studying computer science and engineering, I'm learning programming languages like python, java, c++, and I'm doing project in android app development and web development, I'm also learning data science\",\n",
       " 'level': 2,\n",
       " 'item_id': 80,\n",
       " 'synthetic': True,\n",
       " 'label': 2,\n",
       " '__index_level_0__': 8371}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f11f2b26680>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095518ac63924f1aae247f33a758f27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4bd48751054bc7a5df8956f930fe6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c7129719fd451e8a968361f7a55315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c2b14ca4e141b886e1204fbc497562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 25732, 2504, 1024, 1016, 102, 25732, 1024, 2054, 3450, 2079, 2017, 2079, 2012, 2082, 1029, 102, 3433, 1024, 1045, 1005, 1049, 5702, 3274, 2671, 1998, 3330, 1010, 1045, 1005, 1049, 4083, 4730, 4155, 2066, 18750, 1010, 9262, 1010, 1039, 1009, 1009, 1010, 1998, 1045, 1005, 1049, 2725, 2622, 1999, 11924, 10439, 2458, 1998, 4773, 2458, 1010, 1045, 1005, 1049, 2036, 4083, 2951, 2671, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff8bdd4b3f64089b355369cdb4b65bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/882 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_valid = dataset[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Model Fine tuning with trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score, classification_report\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convertir les logits en classes prÃ©dictes\n",
    "\n",
    "    # ðŸŽ¯ Exactitude (Accuracy)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # ðŸŽ¯ PrÃ©cision, Rappel et F1-score (pondÃ©rÃ©s)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # ðŸŽ¯ Score de Cohen's Kappa (pondÃ©rÃ©)\n",
    "    cohen_kappa = cohen_kappa_score(labels, predictions, weights=\"quadratic\")\n",
    "\n",
    "    # ðŸŽ¯ CorrÃ©lation de Pearson\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)  # Retourne (coef, p-valeur), on garde seulement coef\n",
    "\n",
    "     # ðŸŽ¯ Classification Report\n",
    "    class_report = classification_report(labels, predictions, output_dict=True)  # Get a dictionary of the report\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"cohen_kappa\": cohen_kappa,\n",
    "        \"pearson_corr\": pearson_corr,\n",
    "        \"classification_report\": class_report  # Add classification report to the return\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/bert-ft-efcamdat-augmented\",\n",
    "    evaluation_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=250,\n",
    "    eval_steps=250,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 2 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='251' max='2652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 251/2652 00:48 < 07:42, 5.19 it/s, Epoch 0.57/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2652, training_loss=0.1628522438700922, metrics={'train_runtime': 569.1805, 'train_samples_per_second': 74.412, 'train_steps_per_second': 4.659, 'total_flos': 1.1144105805920256e+16, 'train_loss': 0.1628522438700922, 'epoch': 6.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/56 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1042550802230835,\n",
       " 'eval_accuracy': 0.7755102040816326,\n",
       " 'eval_precision': 0.7855976646593178,\n",
       " 'eval_recall': 0.7755102040816326,\n",
       " 'eval_f1': 0.7765063916759871,\n",
       " 'eval_cohen_kappa': 0.8989367655288193,\n",
       " 'eval_pearson_corr': 0.9045071867933072,\n",
       " 'eval_runtime': 3.0579,\n",
       " 'eval_samples_per_second': 288.437,\n",
       " 'eval_steps_per_second': 18.313,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta Model Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cccb1938124c75915fa5815a72944e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13be3b5e35ef4903bb92326018504128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867b12ad961840a9b054ef51303ba4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22104fda68941f6a7604d34398ee570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789e48a336c64942900346f964df57ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 35396, 3320, 12183, 35, 132, 646, 3388, 510, 742, 42944, 35, 27705, 21700, 103, 1964, 9, 5296, 47, 32, 2811, 2159, 804, 4, 646, 3388, 510, 742, 19121, 35, 939, 524, 12793, 5326, 154, 907, 118, 154, 10, 278, 9, 29784, 3119, 61, 16, 2933, 6, 44477, 2629, 1459, 6, 8, 182, 2721, 4, 635, 24, 16, 1341, 3214, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_test = tokenizer(dataset_not_synthetic_in_train[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e1036fcf4c4cd3ad92079880ea8ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6971d8e43c24a69950f3564b0d28341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/782 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = dataset_not_synthetic_in_train[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset_not_synthetic_in_train[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset_not_synthetic_in_train[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Prompt Level: 1 [SEP] Prompt: Write an email to introduce yourself. [SEP] Response: My name is john mark castillo i'm 19 years old came from donsalvador benedicto negros occendental\",\n",
       " 'level': 1,\n",
       " 'item_id': 3,\n",
       " 'synthetic': False,\n",
       " 'label': 1,\n",
       " '__index_level_0__': 1508}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_not_synthetic_in_train[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af45c85c6c3147b6a51e1131966e2052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/roberta-ft-efcamdat-augmented\",\n",
    "    eval_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='2322' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  21/2322 00:02 < 04:04, 9.43 it/s, Epoch 0.05/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2322, training_loss=0.07464339730859647, metrics={'train_runtime': 291.3094, 'train_samples_per_second': 127.267, 'train_steps_per_second': 7.971, 'total_flos': 4877421006855168.0, 'train_loss': 0.07464339730859647, 'epoch': 6.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/49 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.578270435333252,\n",
       " 'eval_accuracy': 0.7736572890025576,\n",
       " 'eval_precision': 0.7811527976162709,\n",
       " 'eval_recall': 0.7736572890025576,\n",
       " 'eval_f1': 0.7748068645603291,\n",
       " 'eval_cohen_kappa': 0.8750565698018637,\n",
       " 'eval_pearson_corr': 0.8760880596761264,\n",
       " 'eval_classification_report': {'0': {'precision': 0.9044585987261147,\n",
       "   'recall': 0.8208092485549133,\n",
       "   'f1-score': 0.8606060606060606,\n",
       "   'support': 173.0},\n",
       "  '1': {'precision': 0.729957805907173,\n",
       "   'recall': 0.7330508474576272,\n",
       "   'f1-score': 0.7315010570824524,\n",
       "   'support': 236.0},\n",
       "  '2': {'precision': 0.7649122807017544,\n",
       "   'recall': 0.7927272727272727,\n",
       "   'f1-score': 0.7785714285714286,\n",
       "   'support': 275.0},\n",
       "  '3': {'precision': 0.6593406593406593,\n",
       "   'recall': 0.7792207792207793,\n",
       "   'f1-score': 0.7142857142857143,\n",
       "   'support': 77.0},\n",
       "  '4': {'precision': 1.0,\n",
       "   'recall': 0.5714285714285714,\n",
       "   'f1-score': 0.7272727272727273,\n",
       "   'support': 21.0},\n",
       "  'accuracy': 0.7736572890025576,\n",
       "  'macro avg': {'precision': 0.8117338689351403,\n",
       "   'recall': 0.7394473438778327,\n",
       "   'f1-score': 0.7624473975636766,\n",
       "   'support': 782.0},\n",
       "  'weighted avg': {'precision': 0.7811527976162709,\n",
       "   'recall': 0.7736572890025576,\n",
       "   'f1-score': 0.7748068645603291,\n",
       "   'support': 782.0}},\n",
       " 'eval_runtime': 1.4137,\n",
       " 'eval_samples_per_second': 553.169,\n",
       " 'eval_steps_per_second': 34.662,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flan T5 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68a20d75a8b4aa0a095ee094afc6f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897ab41ff8bf4f6b9f7caed6784d8e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23baf9531f642feaa2adacc2ea4fa19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69df101b6b7e44ae8395c384fe284106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "\n",
    "model_id=\"google/flan-t5-base\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "valid_df = pd.DataFrame(dataset['valid'])\n",
    "\n",
    "dataset.clear()\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "valid_df['label'] = valid_df['label'].astype(str)\n",
    "\n",
    "dataset['train'] = Dataset.from_pandas(train_df)\n",
    "dataset['test'] = Dataset.from_pandas(test_df)\n",
    "dataset['valid'] = Dataset.from_pandas(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4c5ec908ee4266b3fda810b0f4b206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69b4afea0014eb8a3dcca7b4e9075c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 3\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "# The maximum total input sequence length after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"label\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3e0aed1a664af297fe29cad2cb9c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7059 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086ea05379cd403580cc9c0db647c062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/882 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9a8ed7acbf4a62bbbd4c3b816876fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['level', 'item_id', 'synthetic', '__index_level_0__', 'input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [item for item in sample[\"text\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"label\"], max_length=5, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['text', 'label'])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, average='macro')\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"../../../model_saved/flan-t5-base-ft-efcamdat-augmented\",\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=250,\n",
    "    eval_steps=250,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 2 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='1326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  57/1326 00:26 < 10:21, 2.04 it/s, Epoch 0.13/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1326, training_loss=0.0, metrics={'train_runtime': 776.4275, 'train_samples_per_second': 27.275, 'train_steps_per_second': 1.708, 'total_flos': 1.4274526664466432e+16, 'train_loss': 0.0, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': nan,\n",
       " 'eval_f1': 75.2442,\n",
       " 'eval_gen_len': 2.195011337868481,\n",
       " 'eval_runtime': 24.3475,\n",
       " 'eval_samples_per_second': 36.226,\n",
       " 'eval_steps_per_second': 2.3,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic = dataset_not_synthetic_in_train[\"valid\"][\"item_id\"]\n",
    "list_t_set = set(list_topic)\n",
    "unique_t = (list(list_t_set))\n",
    "\n",
    "list_level = dataset_not_synthetic_in_train[\"valid\"][\"level\"]\n",
    "list_l_set = set(list_level)\n",
    "unique_l = (list(list_l_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_r = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for t in unique_t:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['item_id'] == t)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"item_id\": t,\n",
    "        \"level\": sub_ds[\"level\"][0],\n",
    "        \"synthetic\": sub_ds[\"synthetic\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/8 00:00 < 00:00, 33.44 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/5 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/7 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/5 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/4 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/3 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_r_level = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for l in unique_l:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['level'] == l)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"level\": sub_ds[\"level\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r_level.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>level</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ck</th>\n",
       "      <th>pearson</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.796176</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.819196</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.869128</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.738950</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.677003</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.858395</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.881944</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.915837</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.869626</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.811441</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.714659</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.818671</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.727679</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.859298</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.893837</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.948181</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  level  synthetic  accuracy  precision    recall        f1    ck  \\\n",
       "0        0      1      False  0.700000   0.705000  0.700000  0.690476  0.77   \n",
       "1        1      1      False  0.812500   0.819196  0.812500  0.810714  0.87   \n",
       "2        2      1      False  0.722222   0.767196  0.722222  0.738950  0.65   \n",
       "3        3      1      False  0.791667   0.854167  0.791667  0.787037  0.85   \n",
       "4        4      1      False  0.888889   0.913580  0.888889  0.881944  0.90   \n",
       "5        5      2      False  0.777778   0.805556  0.777778  0.763889  0.85   \n",
       "6        6      2      False  0.800000   0.811111  0.800000  0.796078  0.80   \n",
       "7        7      2      False  0.722222   0.848485  0.722222  0.714659  0.79   \n",
       "8        8      2      False  0.750000   0.781250  0.750000  0.727679  0.80   \n",
       "9        9      2      False  0.894737   0.902256  0.894737  0.893837  0.94   \n",
       "\n",
       "    pearson  n_samples  \n",
       "0  0.796176         20  \n",
       "1  0.869128         16  \n",
       "2  0.677003         18  \n",
       "3  0.858395         24  \n",
       "4  0.915837         18  \n",
       "5  0.869626         18  \n",
       "6  0.811441         20  \n",
       "7  0.818671         18  \n",
       "8  0.859298         16  \n",
       "9  0.948181         19  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_eval_results = pd.DataFrame(list_r, columns=[\"item_id\", \"level\", \"synthetic\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results.to_csv(\"result_eval_data_roberta_efcamdat_no_synthetic_in_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ck</th>\n",
       "      <th>pearson</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.806723</td>\n",
       "      <td>0.813147</td>\n",
       "      <td>0.806723</td>\n",
       "      <td>0.807158</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.907929</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.828109</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.812083</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.867877</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.799479</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.907257</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.761468</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.758031</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.909071</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.779801</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.775074</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.882664</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.795776</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.781164</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.888711</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.767832</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.881607</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.863271</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.691575</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.825924</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.765850</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.846901</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.675362</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.903830</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.693810</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.860854</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level  accuracy  precision    recall        f1    ck   pearson  n_samples\n",
       "0       1  0.806723   0.813147  0.806723  0.807158  0.91  0.907929        119\n",
       "1       2  0.809524   0.828109  0.809524  0.812083  0.87  0.867877        126\n",
       "2       3  0.802632   0.812865  0.802632  0.799479  0.91  0.907257         76\n",
       "3       4  0.757282   0.761468  0.757282  0.758031  0.91  0.909071        103\n",
       "4       5  0.776000   0.779801  0.776000  0.775074  0.88  0.882664        125\n",
       "5       6  0.776119   0.795776  0.776119  0.781164  0.89  0.888711         67\n",
       "6       7  0.765957   0.783570  0.765957  0.767832  0.88  0.881607         94\n",
       "7       8  0.812500   0.828571  0.812500  0.816667  0.86  0.863271         16\n",
       "8      10  0.689655   0.715517  0.689655  0.691575  0.81  0.825924         58\n",
       "9      11  0.769231   0.775641  0.769231  0.765850  0.84  0.846901         13\n",
       "10     13  0.652174   0.760870  0.652174  0.675362  0.89  0.899571         23\n",
       "11     14  0.750000   0.822917  0.750000  0.752083  0.90  0.903830         16\n",
       "12     16  0.702128   0.693810  0.702128  0.687000  0.86  0.860854         47"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_eval_results_level = pd.DataFrame(list_r_level, columns=[\"level\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results_level.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results_level.to_csv(\"result_eval_data_roberta_efcamdat__no_synthetic_in_train_by_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ray\n",
    "#!pip install \"ray[tune]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mray\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpprint\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m pprint\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(_temp_dir=\"/home/ec2-user/model_saved/ray_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True  # set this to False to run on CPUs\n",
    "num_workers = 1  # set this to number of GPUs or CPUs you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.data\n",
    "\n",
    "ray_datasets = {\n",
    "    \"train\": ray.data.from_huggingface(raw_dataset[\"train\"]),\n",
    "    \"validation\": ray.data.from_huggingface(raw_dataset[\"eval\"]),\n",
    "    \"test\": ray.data.from_huggingface(raw_dataset[\"test\"]),\n",
    "}\n",
    "ray_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "# Tokenize input sentences\n",
    "def collate_fn(examples: Dict[str, np.array]):\n",
    "    outputs = tokenizer(\n",
    "        list(examples[\"text\"]),\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    outputs[\"labels\"] = torch.LongTensor(examples[\"label\"])\n",
    "\n",
    "    # Move all input tensors to GPU\n",
    "    for key, value in outputs.items():\n",
    "        outputs[key] = value.cuda()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_metric\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import ray.train\n",
    "from ray.train.huggingface.transformers import prepare_trainer, RayTrainReportCallback\n",
    "\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "task = \"review\"\n",
    "batch_size = 16\n",
    "\n",
    "num_labels = 5\n",
    "metric_name = (\n",
    "    \"accuracy\"\n",
    ")\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "name = f\"{model_name}-finetuned-{task}\"\n",
    "\n",
    "# Calculate the maximum steps per epoch based on the number of rows in the training dataset.\n",
    "# Make sure to scale by the total number of training workers and the per device batch size.\n",
    "max_steps_per_epoch = ray_datasets[\"train\"].count() // (batch_size * num_workers)\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "    metric = load_metric(\"glue\", \"cola\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_checkpoint, num_labels=num_labels\n",
    "    )\n",
    "\n",
    "    train_ds = ray.train.get_dataset_shard(\"train\")\n",
    "    eval_ds = ray.train.get_dataset_shard(\"eval\")\n",
    "\n",
    "    train_ds_iterable = train_ds.iter_torch_batches(\n",
    "        batch_size=batch_size, collate_fn=collate_fn\n",
    "    )\n",
    "    eval_ds_iterable = eval_ds.iter_torch_batches(\n",
    "        batch_size=batch_size, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    print(\"max_steps_per_epoch: \", max_steps_per_epoch)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=config.get(\"learning_rate\", 2e-5),\n",
    "        num_train_epochs=config.get(\"epochs\", 2),\n",
    "        weight_decay=config.get(\"weight_decay\", 0.01),\n",
    "        push_to_hub=False,\n",
    "        max_steps=max_steps_per_epoch * config.get(\"epochs\", 2),\n",
    "        disable_tqdm=True,  # declutter the output a little\n",
    "        no_cuda=not use_gpu,  # you need to explicitly set no_cuda if you want CPUs\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_ds_iterable,\n",
    "        eval_dataset=eval_ds_iterable,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.add_callback(RayTrainReportCallback())\n",
    "\n",
    "    trainer = prepare_trainer(trainer)\n",
    "\n",
    "    print(\"Starting training\")\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=num_workers, \n",
    "        resources_per_worker={\"GPU\": 1, \"CPU\": 1},\n",
    "        use_gpu=use_gpu),\n",
    "    datasets={\n",
    "        \"train\": ray_datasets[\"train\"],\n",
    "        \"eval\": ray_datasets[\"validation\"],\n",
    "    },\n",
    "    run_config=RunConfig(\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=1,\n",
    "            checkpoint_score_attribute=\"eval_loss\",\n",
    "            checkpoint_score_order=\"min\",\n",
    "            \n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
