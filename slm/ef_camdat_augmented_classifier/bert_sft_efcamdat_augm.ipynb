{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate datasets transformers accelerate==0.26.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 7059\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 882\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 883\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 6179\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 782\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'level', 'item_id', 'synthetic', 'label', '__index_level_0__'],\n",
      "        num_rows: 883\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# Charger les fichiers JSONL en DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=\"data/train.json\")[\"train\"],\n",
    "    \"test\": load_dataset(\"json\", data_files=\"data/test.json\")[\"train\"],\n",
    "    \"valid\": load_dataset(\"json\", data_files=\"data/valid.json\")[\"train\"]\n",
    "})\n",
    "\n",
    "dataset_not_synthetic_in_train = DatasetDict({\n",
    "    \"train\": dataset[\"train\"].filter(lambda example: example[\"item_id\"] <= 44),\n",
    "    \"test\": dataset[\"test\"].filter(lambda example: example[\"item_id\"] <= 44),\n",
    "    \"valid\": dataset[\"valid\"]  # Keep validation set unchanged\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "print(dataset_not_synthetic_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Prompt Level: 2 [SEP] Prompt: What activities do you do at school? [SEP] Response: I'm studying computer science and engineering, I'm learning programming languages like python, java, c++, and I'm doing project in android app development and web development, I'm also learning data science\",\n",
       " 'level': 2,\n",
       " 'item_id': 80,\n",
       " 'synthetic': True,\n",
       " 'label': 2,\n",
       " '__index_level_0__': 8371}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(dataset[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_valid = dataset[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Model Fine tuning with trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score, classification_report\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convertir les logits en classes prÃ©dictes\n",
    "\n",
    "    # ðŸŽ¯ Exactitude (Accuracy)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # ðŸŽ¯ PrÃ©cision, Rappel et F1-score (pondÃ©rÃ©s)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # ðŸŽ¯ Score de Cohen's Kappa (pondÃ©rÃ©)\n",
    "    cohen_kappa = cohen_kappa_score(labels, predictions, weights=\"quadratic\")\n",
    "\n",
    "    # ðŸŽ¯ CorrÃ©lation de Pearson\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)  # Retourne (coef, p-valeur), on garde seulement coef\n",
    "\n",
    "     # ðŸŽ¯ Classification Report\n",
    "    class_report = classification_report(labels, predictions, output_dict=True)  # Get a dictionary of the report\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"cohen_kappa\": cohen_kappa,\n",
    "        \"pearson_corr\": pearson_corr,\n",
    "        \"classification_report\": class_report  # Add classification report to the return\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/bert-ft-efcamdat-augmented\",\n",
    "    evaluation_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=250,\n",
    "    eval_steps=250,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 2 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta Model Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9644a5c9754a7697912935cdcd1f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c2a010189841e0bb406fc94cf80ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18308a1d587e453cb6c343d374d2b6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16dd5ca3c08497dad4da6ba5d76388d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaaf8c34b7d4ebab6129d6f55547a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 35396, 3320, 12183, 35, 132, 646, 3388, 510, 742, 42944, 35, 27705, 21700, 103, 1964, 9, 5296, 47, 32, 2811, 2159, 804, 4, 646, 3388, 510, 742, 19121, 35, 939, 524, 12793, 5326, 154, 907, 118, 154, 10, 278, 9, 29784, 3119, 61, 16, 2933, 6, 44477, 2629, 1459, 6, 8, 182, 2721, 4, 635, 24, 16, 1341, 3214, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_test = tokenizer(dataset_not_synthetic_in_train[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3370b6514e34f8db1f2c68f74d1f010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7059 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adc9b70f8f2489688b1de4bfa4ea141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/882 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68185de50784c189c97a6a0c7d8d47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Prompt Level: 2 [SEP] Prompt: What activities do you do at school? [SEP] Response: I'm studying computer science and engineering, I'm learning programming languages like python, java, c++, and I'm doing project in android app development and web development, I'm also learning data science\",\n",
       " 'level': 2,\n",
       " 'item_id': 80,\n",
       " 'synthetic': True,\n",
       " 'label': 2,\n",
       " '__index_level_0__': 8371}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf504c06fb4b4f60bde7e1dfbd61d484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-large\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/roberta-large-ft-efcamdat-augmented\",\n",
    "    eval_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='2652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 200/2652 01:01 < 12:36, 3.24 it/s, Epoch 0.45/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2652, training_loss=0.34042270513051953, metrics={'train_runtime': 946.4422, 'train_samples_per_second': 44.751, 'train_steps_per_second': 2.802, 'total_flos': 1.9735710527609856e+16, 'train_loss': 0.34042270513051953, 'epoch': 6.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.35331130027771,\n",
       " 'eval_accuracy': 0.8129251700680272,\n",
       " 'eval_precision': 0.816128975356663,\n",
       " 'eval_recall': 0.8129251700680272,\n",
       " 'eval_f1': 0.8130910869145741,\n",
       " 'eval_cohen_kappa': 0.9117223933128025,\n",
       " 'eval_pearson_corr': 0.9124799412910857,\n",
       " 'eval_classification_report': {'0': {'precision': 0.8907103825136612,\n",
       "   'recall': 0.8489583333333334,\n",
       "   'f1-score': 0.8693333333333333,\n",
       "   'support': 192.0},\n",
       "  '1': {'precision': 0.7975206611570248,\n",
       "   'recall': 0.7423076923076923,\n",
       "   'f1-score': 0.7689243027888446,\n",
       "   'support': 260.0},\n",
       "  '2': {'precision': 0.7942122186495176,\n",
       "   'recall': 0.8487972508591065,\n",
       "   'f1-score': 0.8205980066445183,\n",
       "   'support': 291.0},\n",
       "  '3': {'precision': 0.7321428571428571,\n",
       "   'recall': 0.8367346938775511,\n",
       "   'f1-score': 0.780952380952381,\n",
       "   'support': 98.0},\n",
       "  '4': {'precision': 0.9411764705882353,\n",
       "   'recall': 0.7804878048780488,\n",
       "   'f1-score': 0.8533333333333334,\n",
       "   'support': 41.0},\n",
       "  'accuracy': 0.8129251700680272,\n",
       "  'macro avg': {'precision': 0.8311525180102592,\n",
       "   'recall': 0.8114571550511464,\n",
       "   'f1-score': 0.818628271410482,\n",
       "   'support': 882.0},\n",
       "  'weighted avg': {'precision': 0.816128975356663,\n",
       "   'recall': 0.8129251700680272,\n",
       "   'f1-score': 0.8130910869145741,\n",
       "   'support': 882.0}},\n",
       " 'eval_runtime': 4.2528,\n",
       " 'eval_samples_per_second': 207.392,\n",
       " 'eval_steps_per_second': 13.168,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600/tokenizer_config.json',\n",
       " '../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600/special_tokens_map.json',\n",
       " '../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600/vocab.json',\n",
       " '../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600/merges.txt',\n",
       " '../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600/added_tokens.json',\n",
       " '../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save tokenizer\n",
    "#tokenizer.save_pretrained(\"../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600\")  # Save tokenizer to the same path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distilroberta FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_test = tokenizer(dataset[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert/distilroberta-base\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/distilroberta-base-ft-efcamdat-augmented\",\n",
    "    eval_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flan T5 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "\n",
    "model_id=\"google/flan-t5-base\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "valid_df = pd.DataFrame(dataset['valid'])\n",
    "\n",
    "dataset.clear()\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "valid_df['label'] = valid_df['label'].astype(str)\n",
    "\n",
    "dataset['train'] = Dataset.from_pandas(train_df)\n",
    "dataset['test'] = Dataset.from_pandas(test_df)\n",
    "dataset['valid'] = Dataset.from_pandas(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "# The maximum total input sequence length after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"label\"], truncation=True), batched=True, remove_columns=['text', 'label'])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [item for item in sample[\"text\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"label\"], max_length=5, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['text', 'label'])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, average='macro')\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"../../../model_saved/flan-t5-base-ft-efcamdat-augmented\",\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=250,\n",
    "    eval_steps=250,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 2 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic = dataset[\"valid\"][\"item_id\"]\n",
    "list_t_set = set(list_topic)\n",
    "unique_t = (list(list_t_set))\n",
    "\n",
    "list_level = dataset[\"valid\"][\"level\"]\n",
    "list_l_set = set(list_level)\n",
    "unique_l = (list(list_l_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa4207bd1ff4c0ba21f043d036cfc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dffaf9ce596435f94eeefdd8655e246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b386e16828d46da9f2d56815d4c363f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969471c6333d4aca94fc1ae9207ecb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab45bdff35f443d8864a6bba0860449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2276813563d047779c0986528b300397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b46a9cc46b461ab868c4cc6a86139d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af76fa6ed7244b209418081e4372e0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733faccc77724e51b4cc5aafc8457ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2395388793f045bc99180139c302c774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c984295b45441bbbf9286a59d1fb244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99769e4f963545a6be3fb21e8b4cfa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a216b28ba28641358ed182816207ae47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab691aceb72463d988ea21ded52621c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfca0bf1cc6b4d098eed58565114f40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c68b7e0548e47c3b550d85b16c966f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c57b1ede52403da85fc0382a83b4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8ec4e97a9049c8a55a08481a2eab35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b85d8cc4b247eeb05f09bc2a5ea24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05237c468ea4f8598420d56fda5eea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dd1c40a1fd4020be7c5d6e47b1b0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d567c43d0d6e43b0ac7b64aa790425da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ac301cf70b4729a2b4601d9bd74e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98035058ac5c45b7a8bec2ecd485965a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/2 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04899eef5fb2480ab205d207337db5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d23e02454f8417e8cb8044a8470085c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5658aacecf4d491c9ebe393af53b6e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76564bc952449f9bbcbdb4d9c2f73bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2567cee7f6e4cb89c817f1071499aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7749c28797f04f1bad2e17ccabab42ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f26d98b54841c0b938a6851a8299e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987363634f8941308c4759eb3dfca18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfc53cbc45b47b1bc0f55e79f9397ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4096dc8aec4c14b27bad2e38c0bcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fc5999c6194c54b4df5ab93725206f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722141e4fbc545c38da4fe85c4952f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad45a8fdaae24846b5b4247aed90654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b472dcf140143dfb267e73856468815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c24781ceac445a68b84d6fcfcf66a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1228bae71d421a8ab504a8104e4771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1cb6363c5944eaab7eac654c2a67fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae049a47cf44a29a08e1f2f4d91eaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef8c18440d6470d83cdc4f1e5f9dfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24ca89babd740a99148413413d8487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299e146a7a054f0988702fa6b1e157a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbf6becafe342e59c79f35fa4c48203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dae1e464494a21a2b23075511ff92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d63f468d1e4354b5b884a47e653f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a74e8558cda4df38eeee591c0e39503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3689c6a492234855950f252787e44235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_r = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for t in unique_t:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['item_id'] == t)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"item_id\": t,\n",
    "        \"level\": sub_ds[\"level\"][0],\n",
    "        \"synthetic\": sub_ds[\"synthetic\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23043250889042f3a8011dae500d3b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d6f5c8ec2c49dd9099bf72bfcfa7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c947a126a0ad4f43b32812d246e4b7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/5 00:00 < 00:00, 12.83 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e9d1610c0b401ca8b1b758679a82ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7248f1b50c35409bb963dde319077470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb42596ecfd4f6fb000c2def0a7bdfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e638030c384cb7bf7afe6824b4d62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06baa17044b4589b40a72e548429aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3f76494ba547c8af872c6fb0d03986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a274c0aa54e402aa2f0681535eab2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e815955e264e018b8d57c23510216d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/2 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce827ee0c7b49d78a79ce4b55446e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44226d827f1943bcbf3b182cfacf643f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_r_level = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for l in unique_l:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['level'] == l)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"level\": sub_ds[\"level\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r_level.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>level</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ck</th>\n",
       "      <th>pearson</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.869643</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.848590</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.897940</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677124</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.690849</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.785301</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.748434</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.816765</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.812158</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.846451</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.908812</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.815714</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.825723</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.701010</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.824911</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.609674</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.786276</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.850475</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  level  synthetic  accuracy  precision    recall        f1    ck  \\\n",
       "0        0      1      False  0.850000   0.869643  0.850000  0.848590  0.88   \n",
       "1        1      1      False  1.000000   1.000000  1.000000  1.000000  1.00   \n",
       "2        2      1      False  0.666667   0.790123  0.666667  0.677124  0.61   \n",
       "3        3      1      False  0.750000   0.785301  0.750000  0.748434  0.81   \n",
       "4        4      1      False  0.777778   0.814815  0.777778  0.777778  0.80   \n",
       "5        5      2      False  0.833333   0.905556  0.833333  0.846451  0.91   \n",
       "6        6      2      False  0.800000   0.815714  0.800000  0.798611  0.82   \n",
       "7        7      2      False  0.722222   0.736111  0.722222  0.701010  0.81   \n",
       "8        8      2      False  0.625000   0.617857  0.625000  0.609674  0.75   \n",
       "9        9      2      False  0.842105   0.894737  0.842105  0.844444  0.83   \n",
       "\n",
       "    pearson  n_samples  \n",
       "0  0.897940         20  \n",
       "1  1.000000         16  \n",
       "2  0.690849         18  \n",
       "3  0.816765         24  \n",
       "4  0.812158         18  \n",
       "5  0.908812         18  \n",
       "6  0.825723         20  \n",
       "7  0.824911         18  \n",
       "8  0.786276         16  \n",
       "9  0.850475         19  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_eval_results = pd.DataFrame(list_r, columns=[\"item_id\", \"level\", \"synthetic\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results.to_csv(\"result_eval_data_roberta_large_efcamdat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ck</th>\n",
       "      <th>pearson</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.840540</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.833918</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.918251</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.810042</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.803258</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.860232</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.856651</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.932318</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.725035</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.721220</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.896242</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.780491</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.772855</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.853582</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.839487</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.918837</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.807851</td>\n",
       "      <td>0.797872</td>\n",
       "      <td>0.798048</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.885718</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.746489</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.740119</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.840675</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.832411</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.959496</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.877083</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.811806</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.926130</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.794022</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.761951</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.925255</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level  accuracy  precision    recall        f1    ck   pearson  n_samples\n",
       "0       1  0.831933   0.840540  0.831933  0.833918  0.92  0.918251        119\n",
       "1       2  0.801587   0.810042  0.801587  0.803258  0.86  0.858346        126\n",
       "2       3  0.855263   0.860232  0.855263  0.856651  0.93  0.932318         76\n",
       "3       4  0.718447   0.725035  0.718447  0.721220  0.90  0.896242        103\n",
       "4       5  0.776000   0.780491  0.776000  0.772855  0.88  0.883648        125\n",
       "5       6  0.835821   0.853582  0.835821  0.839487  0.92  0.918837         67\n",
       "6       7  0.797872   0.807851  0.797872  0.798048  0.88  0.885718         94\n",
       "7       8  0.750000   0.750000  0.750000  0.750000  0.82  0.818182         16\n",
       "8      10  0.741379   0.746489  0.741379  0.740119  0.83  0.840675         58\n",
       "9      11  1.000000   1.000000  1.000000  1.000000  1.00  1.000000         13\n",
       "10     13  0.826087   0.876812  0.826087  0.832411  0.95  0.959496         23\n",
       "11     14  0.812500   0.877083  0.812500  0.811806  0.92  0.926130         16\n",
       "12     16  0.765957   0.794022  0.765957  0.761951  0.93  0.925255         47"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_eval_results_level = pd.DataFrame(list_r_level, columns=[\"level\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results_level.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results_level.to_csv(\"result_eval_data_roberta_large_efcamdat_by_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ray\n",
    "#!pip install \"ray[tune]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(_temp_dir=\"/home/ec2-user/model_saved/ray_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True  # set this to False to run on CPUs\n",
    "num_workers = 1  # set this to number of GPUs or CPUs you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.data\n",
    "\n",
    "ray_datasets = {\n",
    "    \"train\": ray.data.from_huggingface(raw_dataset[\"train\"]),\n",
    "    \"validation\": ray.data.from_huggingface(raw_dataset[\"eval\"]),\n",
    "    \"test\": ray.data.from_huggingface(raw_dataset[\"test\"]),\n",
    "}\n",
    "ray_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "# Tokenize input sentences\n",
    "def collate_fn(examples: Dict[str, np.array]):\n",
    "    outputs = tokenizer(\n",
    "        list(examples[\"text\"]),\n",
    "        truncation=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    outputs[\"labels\"] = torch.LongTensor(examples[\"label\"])\n",
    "\n",
    "    # Move all input tensors to GPU\n",
    "    for key, value in outputs.items():\n",
    "        outputs[key] = value.cuda()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_metric\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import ray.train\n",
    "from ray.train.huggingface.transformers import prepare_trainer, RayTrainReportCallback\n",
    "\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "task = \"review\"\n",
    "batch_size = 16\n",
    "\n",
    "num_labels = 5\n",
    "metric_name = (\n",
    "    \"accuracy\"\n",
    ")\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "name = f\"{model_name}-finetuned-{task}\"\n",
    "\n",
    "# Calculate the maximum steps per epoch based on the number of rows in the training dataset.\n",
    "# Make sure to scale by the total number of training workers and the per device batch size.\n",
    "max_steps_per_epoch = ray_datasets[\"train\"].count() // (batch_size * num_workers)\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "    metric = load_metric(\"glue\", \"cola\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_checkpoint, num_labels=num_labels\n",
    "    )\n",
    "\n",
    "    train_ds = ray.train.get_dataset_shard(\"train\")\n",
    "    eval_ds = ray.train.get_dataset_shard(\"eval\")\n",
    "\n",
    "    train_ds_iterable = train_ds.iter_torch_batches(\n",
    "        batch_size=batch_size, collate_fn=collate_fn\n",
    "    )\n",
    "    eval_ds_iterable = eval_ds.iter_torch_batches(\n",
    "        batch_size=batch_size, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    print(\"max_steps_per_epoch: \", max_steps_per_epoch)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=config.get(\"learning_rate\", 2e-5),\n",
    "        num_train_epochs=config.get(\"epochs\", 2),\n",
    "        weight_decay=config.get(\"weight_decay\", 0.01),\n",
    "        push_to_hub=False,\n",
    "        max_steps=max_steps_per_epoch * config.get(\"epochs\", 2),\n",
    "        disable_tqdm=True,  # declutter the output a little\n",
    "        no_cuda=not use_gpu,  # you need to explicitly set no_cuda if you want CPUs\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_ds_iterable,\n",
    "        eval_dataset=eval_ds_iterable,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.add_callback(RayTrainReportCallback())\n",
    "\n",
    "    trainer = prepare_trainer(trainer)\n",
    "\n",
    "    print(\"Starting training\")\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=num_workers, \n",
    "        resources_per_worker={\"GPU\": 1, \"CPU\": 1},\n",
    "        use_gpu=use_gpu),\n",
    "    datasets={\n",
    "        \"train\": ray_datasets[\"train\"],\n",
    "        \"eval\": ray_datasets[\"validation\"],\n",
    "    },\n",
    "    run_config=RunConfig(\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=1,\n",
    "            checkpoint_score_attribute=\"eval_loss\",\n",
    "            checkpoint_score_order=\"min\",\n",
    "            \n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onnx Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨le exportÃ© en ONNX : ../../../model_saved/roberta-large-ft-efcamdat-augmented-2600.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.0/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.0/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.1/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.1/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.2/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.2/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.3/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.3/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.4/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.4/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.5/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.5/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.6/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.6/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.7/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.7/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.8/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.8/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.9/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.9/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.10/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.10/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.11/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.11/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.12/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.12/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.13/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.13/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.14/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.14/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.15/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.15/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.16/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.16/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.17/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.17/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.18/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.18/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.19/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.19/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.20/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.20/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.21/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.21/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.22/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.22/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.23/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/roberta/encoder/layer.23/attention/self/MatMul_1]\n",
      "âœ… ModÃ¨le quantifiÃ© en ONNX : ../../../model_saved/roberta-large-ft-efcamdat-augmented-2600-quantized.onnx\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Chemin vers ton dossier contenant le .bin et le config.json\n",
    "model_dir = \"../../../model_saved/roberta-large-ft-efcamdat-augmented/checkpoint-2600\"\n",
    "onnx_model_path = \"../../../model_saved/roberta-large-ft-efcamdat-augmented-2600.onnx\"\n",
    "quantized_model_path = \"../../../model_saved/roberta-large-ft-efcamdat-augmented-2600-quantized.onnx\"\n",
    "\n",
    "# === Ã‰TAPE 1 : Charger le modÃ¨le et tokenizer ===\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")\n",
    "model.eval()\n",
    "\n",
    "# === Ã‰TAPE 2 : PrÃ©parer un input fictif ===\n",
    "dummy_text = \"Texte d'exemple pour conversion ONNX\"\n",
    "inputs = tokenizer(dummy_text, return_tensors=\"pt\", padding=\"max_length\", max_length=32)\n",
    "\n",
    "# === Ã‰TAPE 3 : Exporter vers ONNX ===\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n",
    "    onnx_model_path,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits\": {0: \"batch_size\"},\n",
    "    },\n",
    "    opset_version=14  # â¬…ï¸ change ici\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le exportÃ© en ONNX : {onnx_model_path}\")\n",
    "\n",
    "# === Ã‰TAPE 4 : Quantization dynamique ===\n",
    "quantize_dynamic(\n",
    "    model_input=onnx_model_path,\n",
    "    model_output=quantized_model_path,\n",
    "    weight_type=QuantType.QInt8\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le quantifiÃ© en ONNX : {quantized_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "onnx_session_quant = onnxruntime.InferenceSession(quantized_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256  # Ajuste selon la taille maximale de ton modÃ¨le\n",
    "\n",
    "# Fonction d'infÃ©rence ONNX\n",
    "def onnx_infer(input_texts, onnx_model):\n",
    "    inputs = tokenizer(input_texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()\n",
    "    attention_mask = inputs[\"attention_mask\"].numpy()\n",
    "    onnx_inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "    onnx_outputs = onnx_model.run(None, onnx_inputs)\n",
    "    return onnx_outputs[0]\n",
    "\n",
    "def evaluate_with_metrics(dataset, onnx_model, batch_size=16):\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = batch[\"text\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        logits = onnx_infer(texts, onnx_model)\n",
    "        all_logits.extend(logits)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    all_logits = np.array(all_logits)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # ðŸ”¥ Appliquer compute_metrics\n",
    "    metrics = compute_metrics((all_logits, all_labels))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Evaluation Results ONNX :\n",
      "accuracy: 0.796149490373726\n",
      "precision: 0.8005448097065477\n",
      "recall: 0.796149490373726\n",
      "f1: 0.7972984625934728\n",
      "cohen_kappa: 0.9008232408545239\n",
      "pearson_corr: 0.9021923676059609\n",
      "\n",
      "ðŸ“‹ Classification Report :\n",
      "0: {'precision': 0.9298245614035088, 'recall': 0.8238341968911918, 'f1-score': 0.8736263736263736, 'support': 193.0}\n",
      "1: {'precision': 0.748062015503876, 'recall': 0.7423076923076923, 'f1-score': 0.7451737451737451, 'support': 260.0}\n",
      "2: {'precision': 0.7628205128205128, 'recall': 0.815068493150685, 'f1-score': 0.7880794701986755, 'support': 292.0}\n",
      "3: {'precision': 0.7475728155339806, 'recall': 0.7857142857142857, 'f1-score': 0.7661691542288557, 'support': 98.0}\n",
      "4: {'precision': 0.9230769230769231, 'recall': 0.9, 'f1-score': 0.9113924050632911, 'support': 40.0}\n",
      "accuracy: 0.796149490373726\n",
      "macro avg: {'precision': 0.8222713656677604, 'recall': 0.813384933612771, 'f1-score': 0.8168882296581883, 'support': 883.0}\n",
      "weighted avg: {'precision': 0.8005448097065477, 'recall': 0.796149490373726, 'f1-score': 0.7972984625934728, 'support': 883.0}\n"
     ]
    }
   ],
   "source": [
    "valid_data = dataset[\"valid\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Evaluation Results ONNX :\n",
      "accuracy: 0.7950169875424689\n",
      "precision: 0.8013297252177548\n",
      "recall: 0.7950169875424689\n",
      "f1: 0.7966965609003842\n",
      "cohen_kappa: 0.8988009964168097\n",
      "pearson_corr: 0.8998499346438857\n",
      "\n",
      "ðŸ“‹ Classification Report :\n",
      "0: {'precision': 0.9397590361445783, 'recall': 0.8082901554404145, 'f1-score': 0.8690807799442897, 'support': 193.0}\n",
      "1: {'precision': 0.7282608695652174, 'recall': 0.7730769230769231, 'f1-score': 0.75, 'support': 260.0}\n",
      "2: {'precision': 0.7687296416938111, 'recall': 0.8082191780821918, 'f1-score': 0.7879799666110183, 'support': 292.0}\n",
      "3: {'precision': 0.7708333333333334, 'recall': 0.7551020408163265, 'f1-score': 0.7628865979381443, 'support': 98.0}\n",
      "4: {'precision': 0.9210526315789473, 'recall': 0.875, 'f1-score': 0.8974358974358975, 'support': 40.0}\n",
      "accuracy: 0.7950169875424689\n",
      "macro avg: {'precision': 0.8257271024631775, 'recall': 0.8039376594831712, 'f1-score': 0.81347664838587, 'support': 883.0}\n",
      "weighted avg: {'precision': 0.8013297252177548, 'recall': 0.7950169875424689, 'f1-score': 0.7966965609003842, 'support': 883.0}\n"
     ]
    }
   ],
   "source": [
    "valid_data = dataset[\"valid\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session_quant)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamic_text(prompt_level, prompt, response):\n",
    "    # Construire un texte avec un niveau de prompt, une question (prompt), et une rÃ©ponse\n",
    "    text = f\"Prompt Level: {prompt_level} [SEP] Prompt: {prompt} [SEP] Response: {response}\"\n",
    "    return text\n",
    "\n",
    "def run_test(prompt_level, prompt, response):\n",
    "    # CrÃ©er le texte dynamique\n",
    "    text = create_dynamic_text(prompt_level, prompt, response)\n",
    "    \n",
    "    # Effectuer l'infÃ©rence pour ce texte\n",
    "    logits = onnx_infer(text, onnx_model=onnx_session_quant)\n",
    "    \n",
    "    # Afficher les rÃ©sultats (logits)\n",
    "    print(f\"Logits pour le prompt : '{prompt}' avec niveau {prompt_level}\")\n",
    "    print(logits)\n",
    "    \n",
    "    # DÃ©coder les rÃ©sultats (prÃ©diction de la classe)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    print(f\"PrÃ©diction (classe) : {predictions}\")\n",
    "\n",
    "# === Test dynamique ===\n",
    "prompt_level = 2\n",
    "prompt = \"What activities do you do at school?\"\n",
    "response = \"I'm studying computer science and engineering, I'm learning programming languages like python, java, c++, and I'm doing project in android app development and web development, I'm also learning data science\"\n",
    "run_test(prompt_level, prompt, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ONNX model uploaded to s3://sagemaker-eu-central-1-505049265445/models/writing_text_scoring_model/model_2600_roberta_large.onnx\n"
     ]
    }
   ],
   "source": [
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    \"s3\"\n",
    ")\n",
    "\n",
    "# Define your bucket name and desired path in S3\n",
    "bucket_name = \"sagemaker-eu-central-1-505049265445\"\n",
    "s3_key = \"models/writing_text_scoring_model/model_2600_roberta_large.onnx\"  # Change path as needed\n",
    "quantized_model_path = \"../../../model_saved/roberta-large-ft-efcamdat-augmented-2600-quantized.onnx\"\n",
    "# Upload the ONNX file\n",
    "s3.upload_file(quantized_model_path, bucket_name, s3_key)\n",
    "\n",
    "print(f\"âœ… ONNX model uploaded to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_benchmark = pd.read_csv(\"data/benchmark_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>item_score</th>\n",
       "      <th>level</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Describe your office including its equipment a...</td>\n",
       "      <td>Laptop and class and clinics</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Prompt Level: 1 [SEP] Prompt: Describe your of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a thoughtful and detailed review of a mo...</td>\n",
       "      <td>kalki a telugu movie which is a thriller combi...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Prompt Level: 11 [SEP] Prompt: Write a thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain your step by step plan to achieve your...</td>\n",
       "      <td>It is important to understand what do we want ...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Prompt Level: 7 [SEP] Prompt: Explain your ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a thoughtful and detailed review of a mo...</td>\n",
       "      <td>Last week I saw a beautiful and fantastic movi...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Prompt Level: 11 [SEP] Prompt: Write a thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write an email to introduce yourself.</td>\n",
       "      <td>Hello , my name is hajar i work as an accoutan...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Prompt Level: 1 [SEP] Prompt: Write an email t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Describe your office including its equipment a...   \n",
       "1  Write a thoughtful and detailed review of a mo...   \n",
       "2  Explain your step by step plan to achieve your...   \n",
       "3  Write a thoughtful and detailed review of a mo...   \n",
       "4              Write an email to introduce yourself.   \n",
       "\n",
       "                                              answer  label  synthetic  \\\n",
       "0                       Laptop and class and clinics      0      False   \n",
       "1  kalki a telugu movie which is a thriller combi...      2      False   \n",
       "2  It is important to understand what do we want ...      3      False   \n",
       "3  Last week I saw a beautiful and fantastic movi...      4      False   \n",
       "4  Hello , my name is hajar i work as an accoutan...      2      False   \n",
       "\n",
       "   item_score  level                                         input_text  \n",
       "0         0.0      1  Prompt Level: 1 [SEP] Prompt: Describe your of...  \n",
       "1        54.0     11  Prompt Level: 11 [SEP] Prompt: Write a thought...  \n",
       "2        73.0      7  Prompt Level: 7 [SEP] Prompt: Explain your ste...  \n",
       "3        93.0     11  Prompt Level: 11 [SEP] Prompt: Write a thought...  \n",
       "4        45.0      1  Prompt Level: 1 [SEP] Prompt: Write an email t...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark[\"input_text\"] = df_benchmark.apply(\n",
    "    lambda row: f\"Prompt Level: {row['level']} [SEP] Prompt: {row['prompt']} [SEP] Response: {row['answer']}\",\n",
    "    axis=1\n",
    ")\n",
    "df_benchmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Prompt Level: 1 [SEP] Prompt: Describe your office including its equipment and materials. [SEP] Response: Laptop and class and clinics',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Keep only the relevant columns\n",
    "hf_dataset = Dataset.from_pandas(df_benchmark[[\"input_text\", \"label\"]])\n",
    "hf_dataset = hf_dataset.rename_column(\"input_text\", \"text\")  # Rename to match expected input in evaluate_with_metrics\n",
    "hf_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.656, 'precision': 0.6884781477272841, 'recall': 0.656, 'f1': 0.6545529141717424, 'cohen_kappa': 0.8131182309684821, 'pearson_corr': 0.8392447530686421, 'classification_report': {'0': {'precision': 0.7547169811320755, 'recall': 0.8602150537634409, 'f1-score': 0.8040201005025126, 'support': 93.0}, '1': {'precision': 0.5806451612903226, 'recall': 0.72, 'f1-score': 0.6428571428571429, 'support': 100.0}, '2': {'precision': 0.5857142857142857, 'recall': 0.6721311475409836, 'f1-score': 0.6259541984732825, 'support': 122.0}, '3': {'precision': 0.5416666666666666, 'recall': 0.5131578947368421, 'f1-score': 0.527027027027027, 'support': 76.0}, '4': {'precision': 0.9482758620689655, 'recall': 0.5045871559633027, 'f1-score': 0.6586826347305389, 'support': 109.0}, 'accuracy': 0.656, 'macro avg': {'precision': 0.6822037913744632, 'recall': 0.6540182504009138, 'f1-score': 0.6517082207181009, 'support': 500.0}, 'weighted avg': {'precision': 0.6884781477272841, 'recall': 0.656, 'f1-score': 0.6545529141717424, 'support': 500.0}}}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_with_metrics(hf_dataset, onnx_session_quant)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Evaluation Benchmark dataset Results ONNX :\n",
      "accuracy: 0.656\n",
      "precision: 0.6884781477272841\n",
      "recall: 0.656\n",
      "f1: 0.6545529141717424\n",
      "cohen_kappa: 0.8131182309684821\n",
      "pearson_corr: 0.8392447530686421\n",
      "\n",
      "ðŸ“‹ Classification Report :\n",
      "0: {'precision': 0.7547169811320755, 'recall': 0.8602150537634409, 'f1-score': 0.8040201005025126, 'support': 93.0}\n",
      "1: {'precision': 0.5806451612903226, 'recall': 0.72, 'f1-score': 0.6428571428571429, 'support': 100.0}\n",
      "2: {'precision': 0.5857142857142857, 'recall': 0.6721311475409836, 'f1-score': 0.6259541984732825, 'support': 122.0}\n",
      "3: {'precision': 0.5416666666666666, 'recall': 0.5131578947368421, 'f1-score': 0.527027027027027, 'support': 76.0}\n",
      "4: {'precision': 0.9482758620689655, 'recall': 0.5045871559633027, 'f1-score': 0.6586826347305389, 'support': 109.0}\n",
      "accuracy: 0.656\n",
      "macro avg: {'precision': 0.6822037913744632, 'recall': 0.6540182504009138, 'f1-score': 0.6517082207181009, 'support': 500.0}\n",
      "weighted avg: {'precision': 0.6884781477272841, 'recall': 0.656, 'f1-score': 0.6545529141717424, 'support': 500.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸŽ¯ Evaluation Benchmark dataset Results ONNX :\")\n",
    "for k, v in metrics.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.624, 'precision': 0.6594395434907852, 'recall': 0.624, 'f1': 0.6253174939064662, 'cohen_kappa': 0.8109329869597169, 'pearson_corr': 0.8316285942858317, 'classification_report': {'0': {'precision': 0.7027027027027027, 'recall': 0.8387096774193549, 'f1-score': 0.7647058823529411, 'support': 93.0}, '1': {'precision': 0.559322033898305, 'recall': 0.66, 'f1-score': 0.6055045871559633, 'support': 100.0}, '2': {'precision': 0.5634920634920635, 'recall': 0.5819672131147541, 'f1-score': 0.5725806451612904, 'support': 122.0}, '3': {'precision': 0.47674418604651164, 'recall': 0.5394736842105263, 'f1-score': 0.5061728395061729, 'support': 76.0}, '4': {'precision': 0.9491525423728814, 'recall': 0.5137614678899083, 'f1-score': 0.6666666666666666, 'support': 109.0}, 'accuracy': 0.624, 'macro avg': {'precision': 0.6502827057024929, 'recall': 0.6267824085269088, 'f1-score': 0.6231261241686068, 'support': 500.0}, 'weighted avg': {'precision': 0.6594395434907852, 'recall': 0.624, 'f1-score': 0.6253174939064662, 'support': 500.0}}}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_with_metrics(hf_dataset, onnx_session)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Evaluation Benchmark dataset Results ONNX :\n",
      "accuracy: 0.624\n",
      "precision: 0.6594395434907852\n",
      "recall: 0.624\n",
      "f1: 0.6253174939064662\n",
      "cohen_kappa: 0.8109329869597169\n",
      "pearson_corr: 0.8316285942858317\n",
      "\n",
      "ðŸ“‹ Classification Report :\n",
      "0: {'precision': 0.7027027027027027, 'recall': 0.8387096774193549, 'f1-score': 0.7647058823529411, 'support': 93.0}\n",
      "1: {'precision': 0.559322033898305, 'recall': 0.66, 'f1-score': 0.6055045871559633, 'support': 100.0}\n",
      "2: {'precision': 0.5634920634920635, 'recall': 0.5819672131147541, 'f1-score': 0.5725806451612904, 'support': 122.0}\n",
      "3: {'precision': 0.47674418604651164, 'recall': 0.5394736842105263, 'f1-score': 0.5061728395061729, 'support': 76.0}\n",
      "4: {'precision': 0.9491525423728814, 'recall': 0.5137614678899083, 'f1-score': 0.6666666666666666, 'support': 109.0}\n",
      "accuracy: 0.624\n",
      "macro avg: {'precision': 0.6502827057024929, 'recall': 0.6267824085269088, 'f1-score': 0.6231261241686068, 'support': 500.0}\n",
      "weighted avg: {'precision': 0.6594395434907852, 'recall': 0.624, 'f1-score': 0.6253174939064662, 'support': 500.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸŽ¯ Evaluation Benchmark dataset Results ONNX :\")\n",
    "for k, v in metrics.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(level, prompt, response):\n",
    "    # Construire le texte d'entrÃ©e\n",
    "    text = f\"Prompt Level: {level} [SEP] Prompt: {prompt} [SEP] Response: {response}\"\n",
    "    \n",
    "    # Tokenisation\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()\n",
    "    attention_mask = inputs[\"attention_mask\"].numpy()\n",
    "    \n",
    "    # InfÃ©rence ONNX\n",
    "    onnx_inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "    logits = onnx_session_quant.run(None, onnx_inputs)[0]\n",
    "\n",
    "    # Appliquer softmax pour obtenir des probabilitÃ©s\n",
    "    probs = softmax(logits[0])  # logits[0] car batch size = 1\n",
    "\n",
    "    # Obtenir les 2 meilleures classes avec scores\n",
    "    top2_indices = np.argsort(probs)[::-1][:2]\n",
    "    top2_probs = probs[top2_indices]\n",
    "\n",
    "    results = []\n",
    "    for idx, prob in zip(top2_indices, top2_probs):\n",
    "        results.append((f\"Classe {idx}\", f\"{prob:.4f}\"))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt Level\", placeholder=\"e.g. 2\"),\n",
    "        gr.Textbox(label=\"Prompt\", placeholder=\"e.g. What activities do you do at school?\"),\n",
    "        gr.Textbox(label=\"Response\", placeholder=\"e.g. I'm studying computer science...\")\n",
    "    ],\n",
    "    outputs=gr.Dataframe(headers=[\"Class\", \"Probability Score\"], label=\"Top 2 Predictions\"),\n",
    "    title=\"ðŸ§  ONNX Prediction with RoBERTa\",\n",
    "    description=\"Enter a prompt level, a prompt, and a response. The model will predict the top 2 most likely classes along with their probability scores.\"\n",
    ")\n",
    "\n",
    "# === Launch the interface in the notebook ===\n",
    "interface.launch(share=True, inline=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
