{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "training_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "training_device\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate datasets transformers accelerate==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0015056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3e46481f-4bef-4900-b990-169da9305089</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0000241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>d3ca8e74-ec0f-41a1-8bc3-030edf392772</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>A new colleague is looking for a place to go f...</td>\n",
       "      <td>From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0022001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ad6bb8ac-07c2-415e-8195-19d3791f83d3</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>You work for a market research firm. You take ...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0022165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85dc4eb7-4a04-4142-aeb4-740d466bbad1</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>Write a summary of the report in no more than ...</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0000146</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>57e620bf-efb2-49bf-9f36-ada83b46768d</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>Write a paragraph about how your friend stays ...</td>\n",
       "      <td>My friend stays healthy and fit by exercising ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  nova_judge_score  llama3_judge_score  \\\n",
       "0  CALL0015056                0.0               0.0                 0.0   \n",
       "1  CALL0000241                0.0               0.0                 0.0   \n",
       "2  CALL0022001                0.0               0.0                 0.0   \n",
       "3  CALL0022165                0.0               0.0                 0.0   \n",
       "4  CALL0000146                4.0               5.0                 5.0   \n",
       "\n",
       "   majority_value  agreement_percentage                            writing_id  \\\n",
       "0             0.0            100.000000  3e46481f-4bef-4900-b990-169da9305089   \n",
       "1             0.0            100.000000  d3ca8e74-ec0f-41a1-8bc3-030edf392772   \n",
       "2             0.0            100.000000  ad6bb8ac-07c2-415e-8195-19d3791f83d3   \n",
       "3             0.0            100.000000  85dc4eb7-4a04-4142-aeb4-740d466bbad1   \n",
       "4             5.0             66.666667  57e620bf-efb2-49bf-9f36-ada83b46768d   \n",
       "\n",
       "                                task_id level_title  \\\n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings   \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner   \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research   \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research   \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner   \n",
       "\n",
       "                               activity_instructions  \\\n",
       "0  Your meeting is finishing, and your boss is re...   \n",
       "1  A new colleague is looking for a place to go f...   \n",
       "2  You work for a market research firm. You take ...   \n",
       "3  Write a summary of the report in no more than ...   \n",
       "4  Write a paragraph about how your friend stays ...   \n",
       "\n",
       "                                  student_submission  \n",
       "0  Your meeting is finishing, and your boss is re...  \n",
       "1  From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...  \n",
       "2                                                  s  \n",
       "3                                                  G  \n",
       "4  My friend stays healthy and fit by exercising ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "df = pd.read_csv(\"data/acc_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id\n",
       "cfb893f1-bee1-4894-99f3-43af284493a5    205\n",
       "5c44f26d-2f5c-4039-bcf5-378754d2fe4e    199\n",
       "bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4    196\n",
       "4ce13bf1-4384-44a6-9ff7-5084e02f9e2d    195\n",
       "7e3ee056-1866-488e-88f3-f56af8d22613    193\n",
       "                                       ... \n",
       "e5780a8d-f6ef-4218-9d34-74e064c3e413     25\n",
       "178cfadd-4162-4b5b-aaee-97a1bdcd4d98     25\n",
       "9cf6c0c9-e87b-4e02-84c9-11266ea51d28     25\n",
       "511ccd73-9db8-45e5-8f85-10e244841ce2     23\n",
       "d2196935-4153-4f5c-a1d2-dae31174ae55     19\n",
       "Name: count, Length: 161, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"task_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = (\n",
    "    \"Prompt Level: \" + df['level_title'].astype(str) +\n",
    "    \" [SEP] Prompt: \" + df['activity_instructions'] +\n",
    "    \" [SEP] Response: \" + df['student_submission']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0015056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3e46481f-4bef-4900-b990-169da9305089</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "      <td>Your meeting is finishing, and your boss is re...</td>\n",
       "      <td>Prompt Level: Meetings [SEP] Prompt: Your meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0000241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>d3ca8e74-ec0f-41a1-8bc3-030edf392772</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>A new colleague is looking for a place to go f...</td>\n",
       "      <td>From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...</td>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: A new c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0022001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ad6bb8ac-07c2-415e-8195-19d3791f83d3</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>You work for a market research firm. You take ...</td>\n",
       "      <td>s</td>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: You work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0022165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85dc4eb7-4a04-4142-aeb4-740d466bbad1</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>Write a summary of the report in no more than ...</td>\n",
       "      <td>G</td>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: Write a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0000146</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>57e620bf-efb2-49bf-9f36-ada83b46768d</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>Write a paragraph about how your friend stays ...</td>\n",
       "      <td>My friend stays healthy and fit by exercising ...</td>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: Write a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  nova_judge_score  llama3_judge_score  \\\n",
       "0  CALL0015056                0.0               0.0                 0.0   \n",
       "1  CALL0000241                0.0               0.0                 0.0   \n",
       "2  CALL0022001                0.0               0.0                 0.0   \n",
       "3  CALL0022165                0.0               0.0                 0.0   \n",
       "4  CALL0000146                4.0               5.0                 5.0   \n",
       "\n",
       "   majority_value  agreement_percentage                            writing_id  \\\n",
       "0             0.0            100.000000  3e46481f-4bef-4900-b990-169da9305089   \n",
       "1             0.0            100.000000  d3ca8e74-ec0f-41a1-8bc3-030edf392772   \n",
       "2             0.0            100.000000  ad6bb8ac-07c2-415e-8195-19d3791f83d3   \n",
       "3             0.0            100.000000  85dc4eb7-4a04-4142-aeb4-740d466bbad1   \n",
       "4             5.0             66.666667  57e620bf-efb2-49bf-9f36-ada83b46768d   \n",
       "\n",
       "                                task_id level_title  \\\n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings   \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner   \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research   \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research   \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner   \n",
       "\n",
       "                               activity_instructions  \\\n",
       "0  Your meeting is finishing, and your boss is re...   \n",
       "1  A new colleague is looking for a place to go f...   \n",
       "2  You work for a market research firm. You take ...   \n",
       "3  Write a summary of the report in no more than ...   \n",
       "4  Write a paragraph about how your friend stays ...   \n",
       "\n",
       "                                  student_submission  \\\n",
       "0  Your meeting is finishing, and your boss is re...   \n",
       "1  From_\\nToAll\\nHi, there.\\n\\nCan you help me? I...   \n",
       "2                                                  s   \n",
       "3                                                  G   \n",
       "4  My friend stays healthy and fit by exercising ...   \n",
       "\n",
       "                                                text  \n",
       "0  Prompt Level: Meetings [SEP] Prompt: Your meet...  \n",
       "1  Prompt Level: 2-Beginner [SEP] Prompt: A new c...  \n",
       "2  Prompt Level: Research [SEP] Prompt: You work ...  \n",
       "3  Prompt Level: Research [SEP] Prompt: Write a s...  \n",
       "4  Prompt Level: 2-Beginner [SEP] Prompt: Write a...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: Meetings [SEP] Prompt: Your meet...</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: A new c...</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: You work ...</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: Write a s...</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: Write a...</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: Meetings [SEP] Prompt: Your meet...   \n",
       "1  Prompt Level: 2-Beginner [SEP] Prompt: A new c...   \n",
       "2  Prompt Level: Research [SEP] Prompt: You work ...   \n",
       "3  Prompt Level: Research [SEP] Prompt: Write a s...   \n",
       "4  Prompt Level: 2-Beginner [SEP] Prompt: Write a...   \n",
       "\n",
       "                                task_id level_title  label  \n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings    0.0  \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner    0.0  \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research    0.0  \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research    0.0  \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner    5.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"task_id\", \"level_title\", \"majority_value\"]]\n",
    "df = df.rename(columns={'majority_value': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: Meetings [SEP] Prompt: Your meet...</td>\n",
       "      <td>af3c3b87-9a8a-449e-b4f0-737d76275fb9</td>\n",
       "      <td>Meetings</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: A new c...</td>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: You work ...</td>\n",
       "      <td>03251188-de56-444f-8971-e68e55719bc9</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: Research [SEP] Prompt: Write a s...</td>\n",
       "      <td>3bdca4ab-e3ee-4d24-bab1-4de708580e2e</td>\n",
       "      <td>Research</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 2-Beginner [SEP] Prompt: Write a...</td>\n",
       "      <td>b3285147-d9b6-42f7-9ffb-7482cd450db7</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: Meetings [SEP] Prompt: Your meet...   \n",
       "1  Prompt Level: 2-Beginner [SEP] Prompt: A new c...   \n",
       "2  Prompt Level: Research [SEP] Prompt: You work ...   \n",
       "3  Prompt Level: Research [SEP] Prompt: Write a s...   \n",
       "4  Prompt Level: 2-Beginner [SEP] Prompt: Write a...   \n",
       "\n",
       "                                task_id level_title  label  \n",
       "0  af3c3b87-9a8a-449e-b4f0-737d76275fb9    Meetings    0.0  \n",
       "1  fa1e732b-7698-4b57-85da-907fc3660ec3  2-Beginner    0.0  \n",
       "2  03251188-de56-444f-8971-e68e55719bc9    Research    0.0  \n",
       "3  3bdca4ab-e3ee-4d24-bab1-4de708580e2e    Research    0.0  \n",
       "4  b3285147-d9b6-42f7-9ffb-7482cd450db7  2-Beginner    5.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the mapping to the 'labels' column\n",
    "#df['label'] = df['label'].map(label_mapping)\n",
    "df.dropna(subset=['label'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "5.0    5733\n",
       "2.0    3778\n",
       "0.0    3675\n",
       "3.0    3069\n",
       "4.0    3010\n",
       "1.0     969\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'task_id', 'level_title', 'label'],\n",
       "    num_rows: 20234\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751cb3a9bf40451dba8e499fd69a4af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/20234 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 16187\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 2023\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'task_id', 'level_title', 'label'],\n",
       "        num_rows: 2024\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Value, Sequence\n",
    "new_features = ds.features.copy()\n",
    "new_features[\"label\"] = ClassLabel(names=[0, 1, 2, 3, 4])\n",
    "ds = ds.cast(new_features)\n",
    "\n",
    "# Step 1: Initial train/test split with stratification\n",
    "train_test_ds = ds.train_test_split(test_size=0.20, seed=20)\n",
    "\n",
    "# Step 2: Split the test set into half test, half validation\n",
    "test_valid_split = train_test_ds['test'].train_test_split(test_size=0.5, seed=20)\n",
    "\n",
    "# Step 3: Combine everything into a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_test_ds['train'],\n",
    "    'test': test_valid_split['train'],    # This becomes the test set\n",
    "    'validation': test_valid_split['test']  # This becomes the validation set\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts: Counter({5: 4546, 2: 3010, 0: 2931, 3: 2481, 4: 2446, 1: 773})\n",
      "Test label counts: Counter({5: 600, 2: 387, 0: 363, 3: 297, 4: 277, 1: 99})\n",
      "Validation label counts: Counter({5: 587, 0: 381, 2: 381, 3: 291, 4: 287, 1: 97})\n"
     ]
    }
   ],
   "source": [
    "# Verify label distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Train label counts:\", Counter(ds['train']['label']))\n",
    "print(\"Test label counts:\", Counter(ds['test']['label']))\n",
    "print(\"Validation label counts:\", Counter(ds['validation']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fonction utilitaire pour sauvegarder un split en JSONL\n",
    "def save_split_to_jsonl(dataset_split, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for record in dataset_split:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Sauvegarde des trois splits\n",
    "save_split_to_jsonl(ds['train'], 'data/train.jsonl')\n",
    "save_split_to_jsonl(ds['test'], 'data/test.jsonl')\n",
    "save_split_to_jsonl(ds['validation'], 'data/validation.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score, classification_report\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convertir les logits en classes prÃ©dictes\n",
    "\n",
    "    # ðŸŽ¯ Exactitude (Accuracy)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # ðŸŽ¯ PrÃ©cision, Rappel et F1-score (pondÃ©rÃ©s)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # ðŸŽ¯ Score de Cohen's Kappa (pondÃ©rÃ©)\n",
    "    cohen_kappa = cohen_kappa_score(labels, predictions, weights=\"quadratic\")\n",
    "\n",
    "    # ðŸŽ¯ CorrÃ©lation de Pearson\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)  # Retourne (coef, p-valeur), on garde seulement coef\n",
    "\n",
    "     # ðŸŽ¯ Classification Report\n",
    "    class_report = classification_report(labels, predictions, output_dict=True)  # Get a dictionary of the report\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"cohen_kappa\": cohen_kappa,\n",
    "        \"pearson_corr\": pearson_corr,\n",
    "        \"classification_report\": class_report  # Add classification report to the return\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb4b24916374447a21069a169038266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613ef58d1948434ea0bfc169c060f77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7580bcd1f9ed4b23b72117a91ed3cd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'task_id', 'level_title', 'label'],\n",
      "        num_rows: 16187\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'task_id', 'level_title', 'label'],\n",
      "        num_rows: 2023\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['text', 'task_id', 'level_title', 'label'],\n",
      "        num_rows: 2024\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# Charger les fichiers JSONL en DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=\"data/train.jsonl\")[\"train\"],\n",
    "    \"test\": load_dataset(\"json\", data_files=\"data/test.jsonl\")[\"train\"],\n",
    "    \"valid\": load_dataset(\"json\", data_files=\"data/validation.jsonl\")[\"train\"]\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Prompt Level: 5-Elementary [SEP] Prompt: Write about a movie you recently saw. Give facts and opinions about it. Who starred in the movie? Who directed it? What was it about? Type in the input box. Write 60-100 words. Use your own words where possible. [SEP] Response: Sweet bean\\n\\nIt is a movie from Japan. It was directed by Naomi Kawase. What I liked most was the photography. There were so many beautiful scenes with the trees and the old lady working together with the young man. That man runs an small \"dorayaki\" shop without too much interest and then an old lady appears applying for a job. That is the beginning of a very beautiful story. The plot was really original and I think it\\'s a great movie to see.',\n",
       " 'task_id': 'bd802cec-aaac-4a24-a654-01d84a6a972d',\n",
       " 'level_title': '5-Elementary',\n",
       " 'label': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 35396, 3320, 12183, 35, 195, 12, 46331, 1766, 646, 3388, 510, 742, 42944, 35, 21062, 10, 1551, 9, 10, 2391, 147, 47, 33, 18804, 682, 4, 10391, 59, 5, 689, 6, 5, 850, 8, 932, 1493, 47, 206, 16, 505, 13, 82, 7, 216, 4, 7773, 11, 5, 8135, 2233, 4, 21062, 1191, 12, 1866, 1617, 4, 152, 1940, 16, 786, 12, 9471, 4, 646, 3388, 510, 742, 19121, 35, 229, 33850, 298, 2161, 1236, 298, 705, 4740, 267, 26144, 41460, 1717, 3252, 506, 1368, 26310, 26310, 1717, 219, 4147, 42339, 298, 725, 42339, 298, 725, 326, 19043, 8873, 8470, 14791, 3145, 14791, 3145, 1423, 506, 14791, 506, 1368, 3145, 326, 90, 428, 5967, 326, 571, 43336, 282, 385, 21978, 267, 42898, 2359, 267, 1368, 26029, 417, 1236, 1187, 344, 417, 475, 5655, 741, 21978, 4, 1437, 3296, 1910, 344, 1176, 1526, 42898, 2359, 267, 344, 1439, 1236, 267, 605, 687, 1437, 9211, 449, 330, 33130, 1717, 45882, 4112, 2359, 4112, 267, 11538, 438, 385, 330, 1071, 330, 506, 1236, 26029, 417, 1021, 14555, 10, 1910, 2628, 1176, 2628, 1910, 384, 2794, 261, 1236, 26029, 417, 1236, 26029, 417, 939, 1879, 25933, 12520, 449, 27762, 385, 27762, 33845, 705, 16743, 295, 4214, 1236, 26029, 15983, 449, 27762, 449, 506, 42915, 506, 13561, 139, 109, 330, 33845, 43357, 385, 330, 43357, 385, 330, 43357, 449, 43357, 449, 43357, 1437, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_test = tokenizer(dataset[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e35b1ad4384fdda01553f833b49e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_train \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(tokenize_function, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m tokenized_test \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmap(tokenize_function, batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m tokenized_valid \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmap(tokenize_function, batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    561\u001b[0m datasets: \u001b[39mlist\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/arrow_dataset.py:3318\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3316\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3317\u001b[0m         \u001b[39mfor\u001b[39;00m unprocessed_kwargs \u001b[39min\u001b[39;00m unprocessed_kwargs_per_job:\n\u001b[0;32m-> 3318\u001b[0m             \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39munprocessed_kwargs):\n\u001b[1;32m   3319\u001b[0m                 check_if_shard_done(rank, done, content)\n\u001b[1;32m   3321\u001b[0m \u001b[39m# Avoids PermissionError on Windows (the error: https://github.com/huggingface/datasets/actions/runs/4026734820/jobs/6921621805)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/arrow_dataset.py:3674\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[1;32m   3672\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3673\u001b[0m     _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> 3674\u001b[0m     \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m iter_outputs(shard_iterable):\n\u001b[1;32m   3675\u001b[0m         num_examples_in_batch \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(i)\n\u001b[1;32m   3676\u001b[0m         \u001b[39mif\u001b[39;00m update_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/arrow_dataset.py:3624\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3623\u001b[0m     \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3624\u001b[0m         \u001b[39myield\u001b[39;00m i, apply_function(example, i, offset\u001b[39m=\u001b[39;49moffset)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3545\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[39m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[39m=\u001b[39moffset)\n\u001b[0;32m-> 3547\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3548\u001b[0m \u001b[39mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m, in \u001b[0;36mtokenize_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtokenize_function\u001b[39m(examples):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer(\n\u001b[1;32m      3\u001b[0m         examples[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      4\u001b[0m         padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m         truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      6\u001b[0m         max_length\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m\n\u001b[1;32m      7\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2854\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2852\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2853\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2854\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2855\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2942\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2938\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2939\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2940\u001b[0m         )\n\u001b[1;32m   2941\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2942\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2943\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2944\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2945\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2946\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2947\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2948\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2949\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2950\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2951\u001b[0m         padding_side\u001b[39m=\u001b[39;49mpadding_side,\n\u001b[1;32m   2952\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2953\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2954\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2955\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2956\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2957\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2958\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2959\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2960\u001b[0m         split_special_tokens\u001b[39m=\u001b[39;49msplit_special_tokens,\n\u001b[1;32m   2961\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2962\u001b[0m     )\n\u001b[1;32m   2963\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2964\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2965\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2966\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2984\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2985\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3143\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3133\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3134\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3135\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   3136\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3140\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   3141\u001b[0m )\n\u001b[0;32m-> 3143\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   3144\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   3145\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   3146\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   3147\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   3148\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   3149\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   3150\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   3151\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   3152\u001b[0m     padding_side\u001b[39m=\u001b[39;49mpadding_side,\n\u001b[1;32m   3153\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   3154\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   3155\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   3156\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   3157\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   3158\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   3159\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   3160\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   3161\u001b[0m     split_special_tokens\u001b[39m=\u001b[39;49msplit_special_tokens,\n\u001b[1;32m   3162\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3163\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:217\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m is_split_into_words \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mis_split_into_words\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    212\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_prefix_space \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    213\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou need to instantiate \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with add_prefix_space=True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mto use it with pretokenized inputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_batch_encode_plus(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:553\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer\u001b[39m.\u001b[39mencode_special_tokens \u001b[39m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    551\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer\u001b[39m.\u001b[39mencode_special_tokens \u001b[39m=\u001b[39m split_special_tokens\n\u001b[0;32m--> 553\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[1;32m    554\u001b[0m     batch_text_or_text_pairs,\n\u001b[1;32m    555\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m    556\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    559\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# `Tokens` has type: tuple[\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[39m#                       list[dict[str, list[list[int]]]] or list[dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[39m#                       list[EncodingFast]\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    565\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[1;32m    567\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[1;32m    577\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset[\"valid\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-large\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/roberta-large-ft-efcamdat-augmented\",\n",
    "    eval_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [201/828 01:01 < 03:14, 3.23 it/s, Epoch 1.45/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/18 00:00 < 00:01, 12.82 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=828, training_loss=0.5889229829184675, metrics={'train_runtime': 299.1896, 'train_samples_per_second': 44.28, 'train_steps_per_second': 2.767, 'total_flos': 6173196781289472.0, 'train_loss': 0.5889229829184675, 'epoch': 6.0})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/18 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1551573276519775,\n",
       " 'eval_accuracy': 0.75,\n",
       " 'eval_precision': 0.7535852468077532,\n",
       " 'eval_recall': 0.75,\n",
       " 'eval_f1': 0.7431084449411779,\n",
       " 'eval_cohen_kappa': 0.9014164752905702,\n",
       " 'eval_pearson_corr': 0.9070230789560548,\n",
       " 'eval_classification_report': {'0': {'precision': 0.9411764705882353,\n",
       "   'recall': 0.9411764705882353,\n",
       "   'f1-score': 0.9411764705882353,\n",
       "   'support': 34.0},\n",
       "  '1': {'precision': 1.0,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.6666666666666666,\n",
       "   'support': 8.0},\n",
       "  '2': {'precision': 0.9111111111111111,\n",
       "   'recall': 0.7192982456140351,\n",
       "   'f1-score': 0.803921568627451,\n",
       "   'support': 57.0},\n",
       "  '3': {'precision': 0.5641025641025641,\n",
       "   'recall': 0.6285714285714286,\n",
       "   'f1-score': 0.5945945945945946,\n",
       "   'support': 35.0},\n",
       "  '4': {'precision': 0.4857142857142857,\n",
       "   'recall': 0.38636363636363635,\n",
       "   'f1-score': 0.43037974683544306,\n",
       "   'support': 44.0},\n",
       "  '5': {'precision': 0.7647058823529411,\n",
       "   'recall': 0.9285714285714286,\n",
       "   'f1-score': 0.8387096774193549,\n",
       "   'support': 98.0},\n",
       "  'accuracy': 0.75,\n",
       "  'macro avg': {'precision': 0.7778017189781896,\n",
       "   'recall': 0.683996868284794,\n",
       "   'f1-score': 0.7125747874552909,\n",
       "   'support': 276.0},\n",
       "  'weighted avg': {'precision': 0.7535852468077532,\n",
       "   'recall': 0.75,\n",
       "   'f1-score': 0.7431084449411779,\n",
       "   'support': 276.0}},\n",
       " 'eval_runtime': 1.3617,\n",
       " 'eval_samples_per_second': 202.686,\n",
       " 'eval_steps_per_second': 13.219,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic = dataset[\"valid\"][\"task_id\"]\n",
    "list_t_set = set(list_topic)\n",
    "unique_t = (list(list_t_set))\n",
    "\n",
    "list_level = dataset[\"valid\"][\"level_title\"]\n",
    "list_l_set = set(list_level)\n",
    "unique_l = (list(list_l_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ede1fdc702484c9eacbb566442cb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b495ef40d4b4b4198a7a052b9d8e4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8d209335fb487b8d85ec2d12a3b597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbd8cb08a0b483495f7415d03c02a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da8167eb6224df28cae5b22daf7f376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2eae502a03446ca6c82ec542f32763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc14ac453d04a4aae9642444d0f957c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4076dc441b940a1b55555a770eab844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d260481f094ddeb8bd0c60ec45096a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0db11555ac4884a8e9309dbc345f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ade3c37908b4df5892717a7de50b6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58acd0800a0847ab9ba39dfa02227361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e26179fc6742f49de2aaa75e4886cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b15e0ce9a5e48d99538f8cdec8175c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40647e9d048c468c924d057e605bcbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f8e4fcc4bc46dc940556fc719df98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e88446435da47d3a97b7aee3a275258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69faaa5039774c72b5c2b24a8929f572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425c5600641d4979a4f77c3b0a4a5abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4306b11f672c43b6bcc23e0970ac01f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9c213b988f4d238e1bb208ea65f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b94ae130ee4e5cbe255fb0c80b1fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c6687a8cf9454fb67dc14a143ccce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469eed795106445ea9a6a387bfadf804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575a0245544a48bb8aa79aa5b2c46d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7f8180352474ba799fe265382728e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42650185d83e48aaacde1878aef7511c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc83706e84294a6bb3250912576cec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffb1fa1ff424ad8aea78b5da9a0574a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_r = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for t in unique_t:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['task_id'] == t)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"task_id\": t,\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d2e74ca3254fec811467f2c3904821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/2 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc824277bc84694872c0f425eb4d83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de83fe2932c44189bfa2c18d5d51982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c89e0319554555a6b88db18f21bc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b28721cce414e92b1244d63b45dd4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffbe265c13c4d2d94f80a02bbfe6b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6214e9982aa4451904ef38fbc77a9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400ec004f65847a09e5039719b390d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b83795334ec4630aed0c3b218cf935d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e95c7c1cd944da91ecd648b95b95b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae17b7b244f465b8c9116c6640a09b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1f4e339b4f4a8292f41a9ab1cdab3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814c87ad12d744d4bc42af4d42fd6363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7385151103742aea9eaf475b2e6d6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7109f85bd9124cddb14a836594be84d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "list_r_level = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for l in unique_l:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['level_title'] == l)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r_level.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>level_title</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ck</th>\n",
       "      <th>pearson</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>493dffa9-7513-4408-be4b-5b010a1bf051</td>\n",
       "      <td>10-Upper Intermediate</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.497863</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dcdc664b-404c-407a-99a6-b9a1f99a859a</td>\n",
       "      <td>7-Intermediate</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.837415</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9032f3ed-5da1-4efe-b4dd-c9470bb35d65</td>\n",
       "      <td>16-Upper Advanced</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.847094</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de7a1159-0c06-49bf-a273-7bdd195d6a32</td>\n",
       "      <td>11-Upper Intermediate</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fa1e732b-7698-4b57-85da-907fc3660ec3</td>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.965908</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b4ba34ff-949d-4a82-9f56-ea472f177a71</td>\n",
       "      <td>13-Advanced</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.824022</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43d154ea-bd72-4b54-9339-7c12f992b56a</td>\n",
       "      <td>15-Advanced</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469048</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.712525</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23c3d59a-61d5-470f-90d1-1217b0006929</td>\n",
       "      <td>10-Upper Intermediate</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8f1a0c16-d259-4737-af06-b6b6eb9e9799</td>\n",
       "      <td>13-Advanced</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.979796</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2667a44c-a31b-4b3e-a33e-144d61884196</td>\n",
       "      <td>3-Beginner</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.926179</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                task_id            level_title  accuracy  \\\n",
       "0  493dffa9-7513-4408-be4b-5b010a1bf051  10-Upper Intermediate  0.333333   \n",
       "1  dcdc664b-404c-407a-99a6-b9a1f99a859a         7-Intermediate  0.363636   \n",
       "2  9032f3ed-5da1-4efe-b4dd-c9470bb35d65      16-Upper Advanced  0.666667   \n",
       "3  de7a1159-0c06-49bf-a273-7bdd195d6a32  11-Upper Intermediate  0.666667   \n",
       "4  fa1e732b-7698-4b57-85da-907fc3660ec3             2-Beginner  0.333333   \n",
       "5  b4ba34ff-949d-4a82-9f56-ea472f177a71            13-Advanced  0.363636   \n",
       "6  43d154ea-bd72-4b54-9339-7c12f992b56a            15-Advanced  0.500000   \n",
       "7  23c3d59a-61d5-470f-90d1-1217b0006929  10-Upper Intermediate  1.000000   \n",
       "8  8f1a0c16-d259-4737-af06-b6b6eb9e9799            13-Advanced  0.833333   \n",
       "9  2667a44c-a31b-4b3e-a33e-144d61884196             3-Beginner  0.375000   \n",
       "\n",
       "   precision    recall        f1    ck   pearson  n_samples  \n",
       "0   0.407407  0.333333  0.355556  0.37  0.497863          9  \n",
       "1   0.545455  0.363636  0.430303  0.81  0.837415         11  \n",
       "2   0.633333  0.666667  0.617284  0.84  0.847094          9  \n",
       "3   0.740741  0.666667  0.698413  0.88  0.881818          9  \n",
       "4   0.222222  0.333333  0.250000  0.86  0.965908          6  \n",
       "5   0.200000  0.363636  0.256494  0.74  0.824022         11  \n",
       "6   0.479167  0.500000  0.469048  0.67  0.712525          8  \n",
       "7   1.000000  1.000000  1.000000  1.00  1.000000          8  \n",
       "8   0.833333  0.833333  0.833333  0.94  0.979796          6  \n",
       "9   0.687500  0.375000  0.437500  0.84  0.926179          8  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_eval_results = pd.DataFrame(list_r, columns=[\"task_id\", \"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results.to_csv(\"result_eval_data_roberta_large_writing_task_acc_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_title</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ck</th>\n",
       "      <th>pearson</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-Upper Intermediate</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.653119</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.679126</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-Upper Intermediate</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-Upper Advanced</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.872180</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.834308</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.887413</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-Advanced</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.736953</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750265</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.854543</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-Upper Intermediate</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.626923</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.903542</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-Beginner</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.869748</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.794838</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-Beginner</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.649242</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.957737</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4-Elementary</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.869444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.819400</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.732632</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8-Intermediate</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.492524</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14-Advanced</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.786190</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.963761</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7-Intermediate</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.544928</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.527260</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.900612</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5-Elementary</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.512444</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.526458</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.893280</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13-Advanced</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.398693</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.448529</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.895942</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9-Intermediate</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503968</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.456397</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.780885</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6-Elementary</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.487245</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.485261</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.960324</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              level_title  accuracy  precision    recall        f1    ck  \\\n",
       "0   10-Upper Intermediate  0.647059   0.666667  0.647059  0.653119  0.63   \n",
       "1   12-Upper Intermediate  1.000000   1.000000  1.000000  1.000000  1.00   \n",
       "2       16-Upper Advanced  0.842105   0.872180  0.842105  0.834308  0.89   \n",
       "3             15-Advanced  0.777778   0.736953  0.777778  0.750265  0.84   \n",
       "4   11-Upper Intermediate  0.650000   0.607143  0.650000  0.626923  0.88   \n",
       "5              2-Beginner  0.647059   0.869748  0.647059  0.663000  0.77   \n",
       "6              3-Beginner  0.625000   0.739583  0.625000  0.649242  0.95   \n",
       "7            4-Elementary  0.833333   0.869444  0.833333  0.819400  0.75   \n",
       "8          8-Intermediate  0.625000   0.504167  0.625000  0.554167  0.49   \n",
       "9             14-Advanced  0.750000   0.900000  0.750000  0.786190  0.94   \n",
       "10         7-Intermediate  0.521739   0.544928  0.521739  0.527260  0.89   \n",
       "11           5-Elementary  0.560000   0.512444  0.560000  0.526458  0.84   \n",
       "12            13-Advanced  0.529412   0.398693  0.529412  0.448529  0.85   \n",
       "13         9-Intermediate  0.500000   0.503968  0.500000  0.456397  0.78   \n",
       "14           6-Elementary  0.571429   0.487245  0.571429  0.485261  0.92   \n",
       "\n",
       "     pearson  n_samples  \n",
       "0   0.679126         17  \n",
       "1   1.000000         19  \n",
       "2   0.887413         19  \n",
       "3   0.854543         18  \n",
       "4   0.903542         20  \n",
       "5   0.794838         17  \n",
       "6   0.957737         16  \n",
       "7   0.732632         18  \n",
       "8   0.492524         16  \n",
       "9   0.963761         20  \n",
       "10  0.900612         23  \n",
       "11  0.893280         25  \n",
       "12  0.895942         17  \n",
       "13  0.780885         18  \n",
       "14  0.960324         14  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_eval_results_level = pd.DataFrame(list_r_level, columns=[\"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results_level.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results_level.to_csv(\"result_eval_data_roberta_large_acc_sample_by_level.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
