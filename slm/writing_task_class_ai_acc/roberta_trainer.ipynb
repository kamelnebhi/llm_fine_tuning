{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "training_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "import numpy as np\n",
    "training_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" evaluate==0.4 dataset==4.5.0 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>gpt4o_evaluation</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>nova_evaluation</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>llama3_evaluation</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "      <th>strength</th>\n",
       "      <th>area_for_improvement</th>\n",
       "      <th>comment</th>\n",
       "      <th>raw_correction</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0003862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The student's submission consists of a list of...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student demonstrates a high level of contr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1a7a5582-06e1-4cb5-8374-485b3931288e</td>\n",
       "      <td>111aad8d-1388-499f-b9b9-96b11e2d1c8f</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Read the email from your manager. Then respond...</td>\n",
       "      <td>1.Analyze current workflows to identify ineffi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0004705</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The student demonstrates basic control over em...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The student demonstrates a fair level of gramm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The student has several grammatical errors: ve...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>db061cf3-0ddd-454b-9691-d813a12929e9</td>\n",
       "      <td>fdbea680-2895-4e87-a252-28ff562e6903</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Read the list of issues that you need to discu...</td>\n",
       "      <td>I am really sorry to disturb you but we have s...</td>\n",
       "      <td>['You started with a polite apology.', 'Your e...</td>\n",
       "      <td>[\"Check spelling for words like 'issuses', 'po...</td>\n",
       "      <td>Great job on a clear and well-structured email...</td>\n",
       "      <td>I am really sorry to disturb you, but we have ...</td>\n",
       "      <td>&lt;input&gt;I am really sorry to disturb you&lt;code a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0007813</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The submission displays control over a variety...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The student demonstrates a good control of gra...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The student demonstrates control over complex ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>c61054d2-ebd9-43b7-bfe3-f95f089fd88f</td>\n",
       "      <td>01e27f6c-3c08-4d7c-8c58-fbe93505be01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Write a paragraph describing how robots are be...</td>\n",
       "      <td>Currently the robots are being used for very p...</td>\n",
       "      <td>['You answered the prompt about robots being u...</td>\n",
       "      <td>['Try adding a brief conclusion to summarize t...</td>\n",
       "      <td>Great job explaining the use and impact of rob...</td>\n",
       "      <td>Currently, robots are being used for very peti...</td>\n",
       "      <td>&lt;input&gt;Currently&lt;code a=\"ORTH\" c=\"\"&gt; &lt;/code&gt;&lt;c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0007674</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student demonstrates advanced grammatical ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The student's submission demonstrates advanced...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The student demonstrates advanced control over...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>596e01cf-addc-45ac-8c94-01d8be746073</td>\n",
       "      <td>51184f66-e317-457a-bda9-d73a241b7871</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Using your notes, draft a speech with a consis...</td>\n",
       "      <td>Ladies and Gentlemen,\\n\\nToday, I am thrilled ...</td>\n",
       "      <td>['Clear and engaging speech with motivational ...</td>\n",
       "      <td>['Try adding specific examples to support your...</td>\n",
       "      <td>Great job! Your speech is clear and motivation...</td>\n",
       "      <td>Ladies and Gentlemen,\\n\\nToday, I am thrilled ...</td>\n",
       "      <td>&lt;input&gt;Ladies and Gentlemen,\\n\\nToday, I am th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0001649</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The student demonstrates good control over bas...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The student's submission shows a fair control ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The student demonstrates good control over gra...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>8a1b605f-82ac-4ef0-a1c8-e8c112a05d96</td>\n",
       "      <td>d040caa5-7bd8-412c-aee2-3d9010b91821</td>\n",
       "      <td>12.0</td>\n",
       "      <td>You're going to reply to Alice's blog post abo...</td>\n",
       "      <td>In my culture people are apt to be direct comm...</td>\n",
       "      <td>[\"You clearly explain your own culture's commu...</td>\n",
       "      <td>[\"Start with a greeting or reference to Alice'...</td>\n",
       "      <td>Good job explaining your culture! Add a greeti...</td>\n",
       "      <td>In my culture, people usually communicate dire...</td>\n",
       "      <td>&lt;input&gt;In my culture&lt;code a=\"PUNCT\" c=\", \"&gt;&lt;/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  \\\n",
       "0  CALL0003862                NaN   \n",
       "1  CALL0004705                2.0   \n",
       "2  CALL0007813                3.0   \n",
       "3  CALL0007674                5.0   \n",
       "4  CALL0001649                3.0   \n",
       "\n",
       "                                    gpt4o_evaluation  nova_judge_score  \\\n",
       "0                                                NaN               0.0   \n",
       "1  The student demonstrates basic control over em...               2.0   \n",
       "2  The submission displays control over a variety...               2.0   \n",
       "3  The student demonstrates advanced grammatical ...               4.0   \n",
       "4  The student demonstrates good control over bas...               3.0   \n",
       "\n",
       "                                     nova_evaluation  llama3_judge_score  \\\n",
       "0  The student's submission consists of a list of...                 5.0   \n",
       "1  The student demonstrates a fair level of gramm...                 1.0   \n",
       "2  The student demonstrates a good control of gra...                 3.0   \n",
       "3  The student's submission demonstrates advanced...                 4.0   \n",
       "4  The student's submission shows a fair control ...                 2.0   \n",
       "\n",
       "                                   llama3_evaluation  majority_value  \\\n",
       "0  The student demonstrates a high level of contr...             0.0   \n",
       "1  The student has several grammatical errors: ve...             2.0   \n",
       "2  The student demonstrates control over complex ...             3.0   \n",
       "3  The student demonstrates advanced control over...             4.0   \n",
       "4  The student demonstrates good control over gra...             3.0   \n",
       "\n",
       "   agreement_percentage                            writing_id  \\\n",
       "0             50.000000  1a7a5582-06e1-4cb5-8374-485b3931288e   \n",
       "1             66.666667  db061cf3-0ddd-454b-9691-d813a12929e9   \n",
       "2             66.666667  c61054d2-ebd9-43b7-bfe3-f95f089fd88f   \n",
       "3             66.666667  596e01cf-addc-45ac-8c94-01d8be746073   \n",
       "4             66.666667  8a1b605f-82ac-4ef0-a1c8-e8c112a05d96   \n",
       "\n",
       "                                task_id  ef_level  \\\n",
       "0  111aad8d-1388-499f-b9b9-96b11e2d1c8f      10.0   \n",
       "1  fdbea680-2895-4e87-a252-28ff562e6903       8.0   \n",
       "2  01e27f6c-3c08-4d7c-8c58-fbe93505be01      16.0   \n",
       "3  51184f66-e317-457a-bda9-d73a241b7871      14.0   \n",
       "4  d040caa5-7bd8-412c-aee2-3d9010b91821      12.0   \n",
       "\n",
       "                               activity_instructions  \\\n",
       "0  Read the email from your manager. Then respond...   \n",
       "1  Read the list of issues that you need to discu...   \n",
       "2  Write a paragraph describing how robots are be...   \n",
       "3  Using your notes, draft a speech with a consis...   \n",
       "4  You're going to reply to Alice's blog post abo...   \n",
       "\n",
       "                                  student_submission  \\\n",
       "0  1.Analyze current workflows to identify ineffi...   \n",
       "1  I am really sorry to disturb you but we have s...   \n",
       "2  Currently the robots are being used for very p...   \n",
       "3  Ladies and Gentlemen,\\n\\nToday, I am thrilled ...   \n",
       "4  In my culture people are apt to be direct comm...   \n",
       "\n",
       "                                            strength  \\\n",
       "0                                                 []   \n",
       "1  ['You started with a polite apology.', 'Your e...   \n",
       "2  ['You answered the prompt about robots being u...   \n",
       "3  ['Clear and engaging speech with motivational ...   \n",
       "4  [\"You clearly explain your own culture's commu...   \n",
       "\n",
       "                                area_for_improvement  \\\n",
       "0                                                 []   \n",
       "1  [\"Check spelling for words like 'issuses', 'po...   \n",
       "2  ['Try adding a brief conclusion to summarize t...   \n",
       "3  ['Try adding specific examples to support your...   \n",
       "4  [\"Start with a greeting or reference to Alice'...   \n",
       "\n",
       "                                             comment  \\\n",
       "0                                                NaN   \n",
       "1  Great job on a clear and well-structured email...   \n",
       "2  Great job explaining the use and impact of rob...   \n",
       "3  Great job! Your speech is clear and motivation...   \n",
       "4  Good job explaining your culture! Add a greeti...   \n",
       "\n",
       "                                      raw_correction  \\\n",
       "0                                                NaN   \n",
       "1  I am really sorry to disturb you, but we have ...   \n",
       "2  Currently, robots are being used for very peti...   \n",
       "3  Ladies and Gentlemen,\\n\\nToday, I am thrilled ...   \n",
       "4  In my culture, people usually communicate dire...   \n",
       "\n",
       "                                          correction  \n",
       "0                                                NaN  \n",
       "1  <input>I am really sorry to disturb you<code a...  \n",
       "2  <input>Currently<code a=\"ORTH\" c=\"\"> </code><c...  \n",
       "3  <input>Ladies and Gentlemen,\\n\\nToday, I am th...  \n",
       "4  <input>In my culture<code a=\"PUNCT\" c=\", \"></c...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "median_map = {\n",
    "    \"A1\": 2,\n",
    "    \"A2\": 5,\n",
    "    \"B1\": 8,\n",
    "    \"B2\": 11,\n",
    "    \"C1\": 14,\n",
    "    \"C2\": 16\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"data_v2/sample_data_acc_gec.csv\")\n",
    "\n",
    "#df['ef_level'] = df.apply(lambda row: median_map[row['cefr_level']] if pd.isna(row['ef_level']) else row['ef_level'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id\n",
       "cfc369d9-74da-4013-be4c-b8148993f658    84\n",
       "64058d7e-9b06-4ed8-9b01-5b7efb9fb3ef    82\n",
       "78f976f6-a505-4597-877b-94d9bca3b217    79\n",
       "d8e67c00-1b68-450a-93f8-ed8f40a1c167    78\n",
       "0abfaced-7d7a-4d10-b8d6-a1847e6c3913    77\n",
       "                                        ..\n",
       "a1c194e8-e83e-4645-90f4-3b99a7b91145    10\n",
       "a1471208-6755-4814-aa1a-ab276be4d644     9\n",
       "d2196935-4153-4f5c-a1d2-dae31174ae55     7\n",
       "e7943e9e-0f41-4fe5-bd2c-906f06a219b1     6\n",
       "bfc49596-9ed7-4db3-90e3-2e3fa078c99b     4\n",
       "Name: count, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"task_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = (\n",
    "    \"Prompt Level: \" + df['ef_level'].astype(str) +\n",
    "    \" [SEP] Prompt: \" + df['activity_instructions'] +\n",
    "    \" [SEP] Response: \" + df['student_submission']\n",
    "    #+ \" [SEP] Correction: \" + df['correction']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Prompt Level: 8.0 [SEP] Prompt: Read the list of issues that you need to discuss with your boss. Then write only the body of an email to your boss. You do not need to write the addresses, greetings or the closing. Use a formal tone. Type in the input box. Write 80-100 words. Use your own words where possible. [SEP] Response: I am really sorry to disturb you but we have some issuses to revsolve and I'd like to find a solution for everyone in the shortest time possibile. \\nFirst of all, I war wondering if I have to go to the conference in Paris next month because flights to France are ending.\\nFurthermore I would need to know if we have to postpone the company meeting until after the Parisian conference. I know that it will be next month but we have to reserve the hotel rooms for our guests before they finish.\\nIn the end I have to ask a question tu you: who is researching a replacement for you? If no one has been designed, I can help you in the research. \""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: 10.0 [SEP] Prompt: Read the emai...</td>\n",
       "      <td>111aad8d-1388-499f-b9b9-96b11e2d1c8f</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 8.0 [SEP] Prompt: Read the list ...</td>\n",
       "      <td>fdbea680-2895-4e87-a252-28ff562e6903</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: 16.0 [SEP] Prompt: Write a parag...</td>\n",
       "      <td>01e27f6c-3c08-4d7c-8c58-fbe93505be01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: 14.0 [SEP] Prompt: Using your no...</td>\n",
       "      <td>51184f66-e317-457a-bda9-d73a241b7871</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 12.0 [SEP] Prompt: You're going ...</td>\n",
       "      <td>d040caa5-7bd8-412c-aee2-3d9010b91821</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: 10.0 [SEP] Prompt: Read the emai...   \n",
       "1  Prompt Level: 8.0 [SEP] Prompt: Read the list ...   \n",
       "2  Prompt Level: 16.0 [SEP] Prompt: Write a parag...   \n",
       "3  Prompt Level: 14.0 [SEP] Prompt: Using your no...   \n",
       "4  Prompt Level: 12.0 [SEP] Prompt: You're going ...   \n",
       "\n",
       "                                task_id  ef_level  label  \n",
       "0  111aad8d-1388-499f-b9b9-96b11e2d1c8f      10.0    0.0  \n",
       "1  fdbea680-2895-4e87-a252-28ff562e6903       8.0    2.0  \n",
       "2  01e27f6c-3c08-4d7c-8c58-fbe93505be01      16.0    3.0  \n",
       "3  51184f66-e317-457a-bda9-d73a241b7871      14.0    4.0  \n",
       "4  d040caa5-7bd8-412c-aee2-3d9010b91821      12.0    3.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"task_id\", \"ef_level\", \"majority_value\"]]\n",
    "df = df.rename(columns={'majority_value': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: 10.0 [SEP] Prompt: Read the emai...</td>\n",
       "      <td>111aad8d-1388-499f-b9b9-96b11e2d1c8f</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 8.0 [SEP] Prompt: Read the list ...</td>\n",
       "      <td>fdbea680-2895-4e87-a252-28ff562e6903</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: 16.0 [SEP] Prompt: Write a parag...</td>\n",
       "      <td>01e27f6c-3c08-4d7c-8c58-fbe93505be01</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: 14.0 [SEP] Prompt: Using your no...</td>\n",
       "      <td>51184f66-e317-457a-bda9-d73a241b7871</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 12.0 [SEP] Prompt: You're going ...</td>\n",
       "      <td>d040caa5-7bd8-412c-aee2-3d9010b91821</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: 10.0 [SEP] Prompt: Read the emai...   \n",
       "1  Prompt Level: 8.0 [SEP] Prompt: Read the list ...   \n",
       "2  Prompt Level: 16.0 [SEP] Prompt: Write a parag...   \n",
       "3  Prompt Level: 14.0 [SEP] Prompt: Using your no...   \n",
       "4  Prompt Level: 12.0 [SEP] Prompt: You're going ...   \n",
       "\n",
       "                                task_id  ef_level  label  \n",
       "0  111aad8d-1388-499f-b9b9-96b11e2d1c8f      10.0    0.0  \n",
       "1  fdbea680-2895-4e87-a252-28ff562e6903       8.0    2.0  \n",
       "2  01e27f6c-3c08-4d7c-8c58-fbe93505be01      16.0    3.0  \n",
       "3  51184f66-e317-457a-bda9-d73a241b7871      14.0    4.0  \n",
       "4  d040caa5-7bd8-412c-aee2-3d9010b91821      12.0    3.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the mapping to the 'labels' column\n",
    "#df['label'] = df['label'].map(label_mapping)\n",
    "df.dropna(subset=['label', 'text'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2.0    1585\n",
       "4.0    1270\n",
       "3.0    1236\n",
       "5.0    1179\n",
       "1.0     575\n",
       "0.0     136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'task_id', 'ef_level', 'label'],\n",
       "    num_rows: 5981\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf70a0abf7e4c8f8f0296988fbe541a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5981 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'task_id', 'ef_level', 'label'],\n",
       "    num_rows: 5981\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Value, Sequence\n",
    "new_features = ds.features.copy()\n",
    "new_features[\"label\"] = ClassLabel(names=[0, 1, 2, 3, 4, 5])\n",
    "ds = ds.cast(new_features)\n",
    "\n",
    "# Step 1: Initial train/test split with stratification\n",
    "train_test_ds = ds.train_test_split(test_size=0.20, seed=20)\n",
    "\n",
    "# Step 2: Split the test set into half test, half validation\n",
    "test_valid_split = train_test_ds['test'].train_test_split(test_size=0.5, seed=20)\n",
    "\n",
    "# Step 3: Combine everything into a single DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_ds['train'],\n",
    "    'test': test_valid_split['train'],    # This becomes the test set\n",
    "    'validation': test_valid_split['test']  # This becomes the validation set\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column train not in the dataset. Current columns in the dataset: ['text', 'task_id', 'ef_level', 'label']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Verify label distribution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcollections\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Counter\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain label counts:\u001b[39m\u001b[39m\"\u001b[39m, Counter(ds[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest label counts:\u001b[39m\u001b[39m\"\u001b[39m, Counter(ds[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation label counts:\u001b[39m\u001b[39m\"\u001b[39m, Counter(ds[\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/arrow_dataset.py:2658\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2657\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2658\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/arrow_dataset.py:2642\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2640\u001b[0m format_kwargs \u001b[39m=\u001b[39m format_kwargs \u001b[39mif\u001b[39;00m format_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m   2641\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2642\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, key, indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   2643\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2644\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39mformatter, format_columns\u001b[39m=\u001b[39mformat_columns, output_all_columns\u001b[39m=\u001b[39moutput_all_columns\n\u001b[1;32m   2645\u001b[0m )\n\u001b[1;32m   2646\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/formatting/formatting.py:585\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    583\u001b[0m     _raise_bad_key_type(key)\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 585\u001b[0m     _check_valid_column_key(key, table\u001b[39m.\u001b[39;49mcolumn_names)\n\u001b[1;32m    586\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     size \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mnum_rows \u001b[39mif\u001b[39;00m indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m table\u001b[39m.\u001b[39mnum_rows\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/datasets/formatting/formatting.py:525\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[0;34m(key, columns)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_check_valid_column_key\u001b[39m(key: \u001b[39mstr\u001b[39m, columns: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m columns:\n\u001b[0;32m--> 525\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[39m{\u001b[39;00mcolumns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column train not in the dataset. Current columns in the dataset: ['text', 'task_id', 'ef_level', 'label']\""
     ]
    }
   ],
   "source": [
    "# Verify label distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Train label counts:\", Counter(ds['train']['label']))\n",
    "print(\"Test label counts:\", Counter(ds['test']['label']))\n",
    "print(\"Validation label counts:\", Counter(ds['validation']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fonction utilitaire pour sauvegarder un split en JSONL\n",
    "def save_split_to_jsonl(dataset_split, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for record in dataset_split:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Sauvegarde des trois splits\n",
    "save_split_to_jsonl(ds['train'], 'data/train_gec.jsonl')\n",
    "save_split_to_jsonl(ds['test'], 'data/test_gec.jsonl')\n",
    "save_split_to_jsonl(ds['validation'], 'data/validation_gec.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score, classification_report\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convertir les logits en classes prÃ©dictes\n",
    "\n",
    "    # ðŸŽ¯ Exactitude (Accuracy)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # ðŸŽ¯ PrÃ©cision, Rappel et F1-score (pondÃ©rÃ©s)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # ðŸŽ¯ Score de Cohen's Kappa (pondÃ©rÃ©)\n",
    "    cohen_kappa = cohen_kappa_score(labels, predictions, weights=\"quadratic\")\n",
    "\n",
    "    # ðŸŽ¯ CorrÃ©lation de Pearson\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)  # Retourne (coef, p-valeur), on garde seulement coef\n",
    "\n",
    "     # ðŸŽ¯ Classification Report\n",
    "    class_report = classification_report(labels, predictions, output_dict=True)  # Get a dictionary of the report\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"cohen_kappa\": cohen_kappa,\n",
    "        \"pearson_corr\": pearson_corr,\n",
    "        \"classification_report\": class_report  # Add classification report to the return\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# Charger les fichiers JSONL en DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=\"data/train_gec.jsonl\")[\"train\"],\n",
    "    \"test\": load_dataset(\"json\", data_files=\"data/test_gec.jsonl\")[\"train\"],\n",
    "    \"valid\": load_dataset(\"json\", data_files=\"data/validation_gec.jsonl\")[\"train\"]\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"FacebookAI/roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/vocab.json\n",
      "loading file merges.txt from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/merges.txt\n",
      "loading file tokenizer.json from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"FacebookAI/roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Prompt Level: 15.0 [SEP] Prompt: You're going to write about an interesting, fictional event that happened to a friend. Write your blog post. Type in the input box. Write 150-200 words. [SEP] Response: My friend is a Star \\n\\n\\nMy freind and me like to know new places for to take a drink, hear good music and seethe crowd.  Was the saturday night and go to for a new pub. But the queue it was huge.  we had been ther fo more onde hour when the security of Pub came to meet with us requesting that into to the pub by end of doors. In that moment i found very strange, but follow in direcion the security. He open the door  and request that look for other security, that which I would be taking to the table where we would be watching the show from the box. He asked if we wanted a drink or something to eat and said it was all on the house. Me and my friend only accepted and smile one for other. When the waiter came until us and left the drinks, called my friend  the Silvester Stalone. At that moment we understood why we were able to enter the Pub. \",\n",
       " 'task_id': '56de3bdd-b83e-4dd4-9213-446b7e00e3cd',\n",
       " 'ef_level': 15.0,\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 35396, 3320, 12183, 35, 290, 4, 288, 646, 3388, 510, 742, 42944, 35, 1163, 5, 889, 9, 743, 14, 47, 240, 7, 2268, 19, 110, 3504, 4, 1892, 3116, 129, 5, 809, 9, 41, 1047, 7, 110, 3504, 4, 370, 109, 45, 240, 7, 3116, 5, 8480, 6, 17395, 1033, 50, 5, 3172, 4, 7627, 10, 4828, 6328, 4, 7773, 11, 5, 8135, 2233, 4, 21062, 1812, 12, 1866, 1617, 4, 7627, 110, 308, 1617, 147, 678, 4, 646, 3388, 510, 742, 19121, 35, 305, 6998, 24, 28, 678, 7, 278, 10, 529, 19, 47, 116, 50118, 100, 33, 130, 1142, 8, 38, 240, 7, 2268, 59, 141, 7, 432, 19, 106, 4, 50118, 50118, 47326, 13755, 47, 164, 7, 2725, 5, 1019, 220, 353, 116, 50118, 47326, 31231, 52, 342, 160, 5, 138, 529, 454, 71, 5, 1019, 116, 38, 5170, 14, 5, 529, 26012, 268, 40, 45, 2725, 5, 138, 529, 4, 50118, 47326, 12375, 16, 21252, 10, 5010, 13, 69, 116, 38, 5170, 114, 38, 240, 7, 4559, 7404, 9, 5010, 19, 951, 54, 16, 21252, 4, 50140, 50140, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_test = tokenizer(dataset[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=312\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55381ebe9614ec09f4b0c9f9b2ebfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d730b64a621f4e1ab73ca76cced5e3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/598 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231a1335c3de41a78cc6f202486d1038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset[\"validation\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/ec2-user/.cache/huggingface/hub/models--FacebookAI--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/model.safetensors\n",
      "Some weights of the model checkpoint at FacebookAI/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-large\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented\",\n",
    "    evaluation_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:593: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: task_id, text, ef_level. If task_id, text, ef_level are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4784\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1196\n",
      "  Number of trainable parameters = 355365894\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='1196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 155/1196 01:10 < 08:00, 2.17 it/s, Epoch 0.52/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: task_id, text, ef_level. If task_id, text, ef_level are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 598\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 598\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1000] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1200] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: task_id, text, ef_level. If task_id, text, ef_level are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 598\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1400] due to args.save_total_limit\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1600] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1196, training_loss=0.7992473047313882, metrics={'train_runtime': 602.7212, 'train_samples_per_second': 31.749, 'train_steps_per_second': 1.984, 'total_flos': 1.0867398500395008e+16, 'train_loss': 0.7992473047313882, 'epoch': 4.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: task_id, text, ef_level. If task_id, text, ef_level are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 598\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/38 00:04 < 00:00, 7.44 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'0': {'precision': 0.5625, 'recall': 0.5294117647058824, 'f1-score': 0.5454545454545454, 'support': 17.0}, '1': {'precision': 0.5581395348837209, 'recall': 0.4528301886792453, 'f1-score': 0.5, 'support': 53.0}, '2': {'precision': 0.6390977443609023, 'recall': 0.5902777777777778, 'f1-score': 0.6137184115523465, 'support': 144.0}, '3': {'precision': 0.5319148936170213, 'recall': 0.6097560975609756, 'f1-score': 0.5681818181818182, 'support': 123.0}, '4': {'precision': 0.5596330275229358, 'recall': 0.49193548387096775, 'f1-score': 0.5236051502145923, 'support': 124.0}, '5': {'precision': 0.717948717948718, 'recall': 0.8175182481751825, 'f1-score': 0.764505119453925, 'support': 137.0}, 'accuracy': 0.6120401337792643, 'macro avg': {'precision': 0.5948723197222164, 'recall': 0.5819549267950053, 'f1-score': 0.5859108408095378, 'support': 598.0}, 'weighted avg': {'precision': 0.6092859067282929, 'recall': 0.6120401337792643, 'f1-score': 0.6081919434187725, 'support': 598.0}}\" of type <class 'dict'> for key \"eval_classification_report\" as a metric. MLflow's log_metric() only accepts float and int types so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9818981885910034,\n",
       " 'eval_accuracy': 0.6120401337792643,\n",
       " 'eval_precision': 0.6092859067282929,\n",
       " 'eval_recall': 0.6120401337792643,\n",
       " 'eval_f1': 0.6081919434187725,\n",
       " 'eval_cohen_kappa': 0.8447930086654261,\n",
       " 'eval_pearson_corr': 0.8468238074941701,\n",
       " 'eval_classification_report': {'0': {'precision': 0.5625,\n",
       "   'recall': 0.5294117647058824,\n",
       "   'f1-score': 0.5454545454545454,\n",
       "   'support': 17.0},\n",
       "  '1': {'precision': 0.5581395348837209,\n",
       "   'recall': 0.4528301886792453,\n",
       "   'f1-score': 0.5,\n",
       "   'support': 53.0},\n",
       "  '2': {'precision': 0.6390977443609023,\n",
       "   'recall': 0.5902777777777778,\n",
       "   'f1-score': 0.6137184115523465,\n",
       "   'support': 144.0},\n",
       "  '3': {'precision': 0.5319148936170213,\n",
       "   'recall': 0.6097560975609756,\n",
       "   'f1-score': 0.5681818181818182,\n",
       "   'support': 123.0},\n",
       "  '4': {'precision': 0.5596330275229358,\n",
       "   'recall': 0.49193548387096775,\n",
       "   'f1-score': 0.5236051502145923,\n",
       "   'support': 124.0},\n",
       "  '5': {'precision': 0.717948717948718,\n",
       "   'recall': 0.8175182481751825,\n",
       "   'f1-score': 0.764505119453925,\n",
       "   'support': 137.0},\n",
       "  'accuracy': 0.6120401337792643,\n",
       "  'macro avg': {'precision': 0.5948723197222164,\n",
       "   'recall': 0.5819549267950053,\n",
       "   'f1-score': 0.5859108408095378,\n",
       "   'support': 598.0},\n",
       "  'weighted avg': {'precision': 0.6092859067282929,\n",
       "   'recall': 0.6120401337792643,\n",
       "   'f1-score': 0.6081919434187725,\n",
       "   'support': 598.0}},\n",
       " 'eval_runtime': 5.0386,\n",
       " 'eval_samples_per_second': 118.683,\n",
       " 'eval_steps_per_second': 7.542,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic = dataset[\"valid\"][\"task_id\"]\n",
    "list_t_set = set(list_topic)\n",
    "unique_t = (list(list_t_set))\n",
    "\n",
    "list_level = dataset[\"valid\"][\"level_title\"]\n",
    "list_l_set = set(list_level)\n",
    "unique_l = (list(list_l_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for t in unique_t:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['task_id'] == t)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"task_id\": t,\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r_level = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for l in unique_l:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['level_title'] == l)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r_level.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results = pd.DataFrame(list_r, columns=[\"task_id\", \"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results.to_csv(\"result_eval_data_roberta_large_writing_task_acc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results_level = pd.DataFrame(list_r_level, columns=[\"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results_level.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results_level.to_csv(\"result_eval_data_roberta_large_acc_by_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Chemin vers ton dossier contenant le .bin et le config.json\n",
    "#model_dir = \"model_saved/roberta-large-ft-acc-writing-task-augmented/checkpoint-1800\"\n",
    "model_dir=\"/tmp/tmpdxu3_htb\"\n",
    "onnx_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800.onnx\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800-quantized.onnx\"\n",
    "\n",
    "# === Ã‰TAPE 1 : Charger le modÃ¨le et tokenizer ===\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")\n",
    "model.eval()\n",
    "\n",
    "# === Ã‰TAPE 2 : PrÃ©parer un input fictif ===\n",
    "dummy_text = \"Texte d'exemple pour conversion ONNX\"\n",
    "inputs = tokenizer(dummy_text, return_tensors=\"pt\", padding=\"max_length\", max_length=256)\n",
    "\n",
    "# === Ã‰TAPE 3 : Exporter vers ONNX ===\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n",
    "    onnx_model_path,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits\": {0: \"batch_size\"},\n",
    "    },\n",
    "    opset_version=14  # â¬…ï¸ change ici\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le exportÃ© en ONNX : {onnx_model_path}\")\n",
    "\n",
    "# === Ã‰TAPE 4 : Quantization dynamique ===\n",
    "quantize_dynamic(\n",
    "    model_input=onnx_model_path,\n",
    "    model_output=quantized_model_path,\n",
    "    weight_type=QuantType.QInt8\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le quantifiÃ© en ONNX : {quantized_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "onnx_session_quant = onnxruntime.InferenceSession(quantized_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256  # Ajuste selon la taille maximale de ton modÃ¨le\n",
    "\n",
    "# Fonction d'infÃ©rence ONNX\n",
    "def onnx_infer(input_texts, onnx_model):\n",
    "    inputs = tokenizer(input_texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()\n",
    "    attention_mask = inputs[\"attention_mask\"].numpy()\n",
    "    onnx_inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "    onnx_outputs = onnx_model.run(None, onnx_inputs)\n",
    "    return onnx_outputs[0]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_with_metrics(dataset, onnx_model, batch_size=16):\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    # tqdm pour afficher la progression sur les batches\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Evaluation\"):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = batch[\"text\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        logits = onnx_infer(texts, onnx_model)\n",
    "        all_logits.extend(logits)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    all_logits = np.array(all_logits)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # ðŸ”¥ Appliquer compute_metrics\n",
    "    metrics = compute_metrics((all_logits, all_labels))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session_quant)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    \"s3\"\n",
    ")\n",
    "\n",
    "# Define your bucket name and desired path in S3\n",
    "bucket_name = \"sagemaker-studio-oxs6vznjds\"\n",
    "\n",
    "s3_key = \"writing_task_models/accuracy/model_1800_quantized_roberta_large.onnx\"  # Change path as needed\n",
    "# Upload the ONNX file\n",
    "bucket_path = \"sagemaker-studio-oxs6vznjds\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800-quantized.onnx\"\n",
    "\n",
    "s3.upload_file(quantized_model_path, bucket_path, s3_key)\n",
    "\n",
    "print(f\"âœ… ONNX model uploaded to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Onnx from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Define S3 bucket and model key\n",
    "bucket_name = 'sagemaker-studio-oxs6vznjds'\n",
    "model_key = 'writing_task_models/accuracy/model_1800_quantized_roberta_large.onnx'\n",
    "local_model_path = '/tmp/roberta-large-ft-acc-writing-task-1800-quant.onnx'  # or wherever you want to save temporarily\n",
    "\n",
    "# Initialize boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Download the ONNX model from S3 to local path\n",
    "s3.download_file(bucket_name, model_key, local_model_path)\n",
    "\n",
    "# Load the ONNX model using onnxruntime\n",
    "session = ort.InferenceSession(local_model_path)\n",
    "\n",
    "print(\"ONNX model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_with_metrics(valid_data, onnx_model=session)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
