{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "training_device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "import numpy as np\n",
    "training_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" evaluate==0.4 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>gpt4o_judge_score</th>\n",
       "      <th>gpt4o_evaluation</th>\n",
       "      <th>nova_judge_score</th>\n",
       "      <th>nova_evaluation</th>\n",
       "      <th>llama3_judge_score</th>\n",
       "      <th>llama3_evaluation</th>\n",
       "      <th>majority_value</th>\n",
       "      <th>agreement_percentage</th>\n",
       "      <th>writing_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>activity_instructions</th>\n",
       "      <th>student_submission</th>\n",
       "      <th>strength</th>\n",
       "      <th>area_for_improvement</th>\n",
       "      <th>comment</th>\n",
       "      <th>raw_correction</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALL0008518</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student demonstrates advanced control over...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student's submission is grammatically accu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student's submission is grammatically accu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99047bf8-f90c-441c-b144-c5c967ba1bed</td>\n",
       "      <td>41c301bb-948b-4f55-a421-9da9be1aea3e</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Listen again to the flight attendant. Type out...</td>\n",
       "      <td>A flight attendant is responsible for the safe...</td>\n",
       "      <td>['You described the role of a flight attendant...</td>\n",
       "      <td>['Try adding an example to support your points...</td>\n",
       "      <td>You made good use of appropriate vocabulary an...</td>\n",
       "      <td>A flight attendant is responsible for the safe...</td>\n",
       "      <td>&lt;input&gt;A flight attendant is responsible for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALL0009642</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student submission demonstrates advanced g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The student submission is generally well-const...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student demonstrates strong control over g...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>86cedceb-f077-4f06-a4ba-5cb433277597</td>\n",
       "      <td>6bd37619-8520-4e9f-b5e8-4d1b218f8a0d</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Read the blog post. Then write about a city yo...</td>\n",
       "      <td>Last year I visited Paris, and it was an unfor...</td>\n",
       "      <td>['You described personal experiences and obser...</td>\n",
       "      <td>['Try adding a brief summary before the conclu...</td>\n",
       "      <td>Great job describing your visit to Paris! Your...</td>\n",
       "      <td>Last year I visited Tokyo, and it was an unfor...</td>\n",
       "      <td>&lt;input&gt;Last year I visited &lt;code a=\"NOUN\" c=\"T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALL0009103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The student demonstrates strong control over g...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The student demonstrates fair control over a v...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The student demonstrates good control over gra...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>01d1b3d2-dc1d-4cd4-86bc-d7f99aeddaf2</td>\n",
       "      <td>8f1a0c16-d259-4737-af06-b6b6eb9e9799</td>\n",
       "      <td>13.0</td>\n",
       "      <td>A website has invited you to write your opinio...</td>\n",
       "      <td>I believe that everyone who lives in this worl...</td>\n",
       "      <td>['Clear opinion with logical argumentation', '...</td>\n",
       "      <td>['Add more specific examples to support argume...</td>\n",
       "      <td>Good job on a clear and structured opinion art...</td>\n",
       "      <td>I believe that everyone who lives in this worl...</td>\n",
       "      <td>&lt;input&gt;I believe that everyone who lives in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALL0008310</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student demonstrates high control over gra...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student demonstrates advanced control over...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The student demonstrates excellent control ove...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>fafb7e00-2f10-4181-a5d1-83a91b3194ee</td>\n",
       "      <td>bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Write a comparison-contrast essay about your f...</td>\n",
       "      <td>To create a comparison and contrast between my...</td>\n",
       "      <td>['Your essay effectively compares and contrast...</td>\n",
       "      <td>[\"Try adding a hook in the introduction to gra...</td>\n",
       "      <td>Great job on your comparison essay! Keep using...</td>\n",
       "      <td>To create a comparison and contrast between my...</td>\n",
       "      <td>&lt;input&gt;To create a comparison and contrast bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALL0028198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The student's submission consists of a fragmen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The student's submission is incomplete and doe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The student did not produce a meaningful respo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>19e802df-05a6-4a2b-9562-d5d3fc6f4e38</td>\n",
       "      <td>919c4050-62f4-4659-92e0-b8a696061e03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Write a summary of the medical profession as o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Your response shows an appropriate attempt t...</td>\n",
       "      <td>['Add a comparison section to highlight simila...</td>\n",
       "      <td>You have a good start, add more details and co...</td>\n",
       "      <td>It's hard work.</td>\n",
       "      <td>&lt;input&gt;&lt;code a=\"PRON\" c=\"It\"&gt;Its &lt;/code&gt;&lt;code ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordId  gpt4o_judge_score  \\\n",
       "0  CALL0008518                5.0   \n",
       "1  CALL0009642                5.0   \n",
       "2  CALL0009103                4.0   \n",
       "3  CALL0008310                5.0   \n",
       "4  CALL0028198                0.0   \n",
       "\n",
       "                                    gpt4o_evaluation  nova_judge_score  \\\n",
       "0  The student demonstrates advanced control over...               5.0   \n",
       "1  The student submission demonstrates advanced g...               1.0   \n",
       "2  The student demonstrates strong control over g...               3.0   \n",
       "3  The student demonstrates high control over gra...               5.0   \n",
       "4  The student's submission consists of a fragmen...               1.0   \n",
       "\n",
       "                                     nova_evaluation  llama3_judge_score  \\\n",
       "0  The student's submission is grammatically accu...                 5.0   \n",
       "1  The student submission is generally well-const...                 5.0   \n",
       "2  The student demonstrates fair control over a v...                 4.0   \n",
       "3  The student demonstrates advanced control over...                 5.0   \n",
       "4  The student's submission is incomplete and doe...                 0.0   \n",
       "\n",
       "                                   llama3_evaluation  majority_value  \\\n",
       "0  The student's submission is grammatically accu...             5.0   \n",
       "1  The student demonstrates strong control over g...             5.0   \n",
       "2  The student demonstrates good control over gra...             4.0   \n",
       "3  The student demonstrates excellent control ove...             5.0   \n",
       "4  The student did not produce a meaningful respo...             0.0   \n",
       "\n",
       "   agreement_percentage                            writing_id  \\\n",
       "0            100.000000  99047bf8-f90c-441c-b144-c5c967ba1bed   \n",
       "1             66.666667  86cedceb-f077-4f06-a4ba-5cb433277597   \n",
       "2             66.666667  01d1b3d2-dc1d-4cd4-86bc-d7f99aeddaf2   \n",
       "3            100.000000  fafb7e00-2f10-4181-a5d1-83a91b3194ee   \n",
       "4             66.666667  19e802df-05a6-4a2b-9562-d5d3fc6f4e38   \n",
       "\n",
       "                                task_id  ef_level  \\\n",
       "0  41c301bb-948b-4f55-a421-9da9be1aea3e       7.0   \n",
       "1  6bd37619-8520-4e9f-b5e8-4d1b218f8a0d      11.0   \n",
       "2  8f1a0c16-d259-4737-af06-b6b6eb9e9799      13.0   \n",
       "3  bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4      15.0   \n",
       "4  919c4050-62f4-4659-92e0-b8a696061e03       7.0   \n",
       "\n",
       "                               activity_instructions  \\\n",
       "0  Listen again to the flight attendant. Type out...   \n",
       "1  Read the blog post. Then write about a city yo...   \n",
       "2  A website has invited you to write your opinio...   \n",
       "3  Write a comparison-contrast essay about your f...   \n",
       "4  Write a summary of the medical profession as o...   \n",
       "\n",
       "                                  student_submission  \\\n",
       "0  A flight attendant is responsible for the safe...   \n",
       "1  Last year I visited Paris, and it was an unfor...   \n",
       "2  I believe that everyone who lives in this worl...   \n",
       "3  To create a comparison and contrast between my...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            strength  \\\n",
       "0  ['You described the role of a flight attendant...   \n",
       "1  ['You described personal experiences and obser...   \n",
       "2  ['Clear opinion with logical argumentation', '...   \n",
       "3  ['Your essay effectively compares and contrast...   \n",
       "4  ['Your response shows an appropriate attempt t...   \n",
       "\n",
       "                                area_for_improvement  \\\n",
       "0  ['Try adding an example to support your points...   \n",
       "1  ['Try adding a brief summary before the conclu...   \n",
       "2  ['Add more specific examples to support argume...   \n",
       "3  [\"Try adding a hook in the introduction to gra...   \n",
       "4  ['Add a comparison section to highlight simila...   \n",
       "\n",
       "                                             comment  \\\n",
       "0  You made good use of appropriate vocabulary an...   \n",
       "1  Great job describing your visit to Paris! Your...   \n",
       "2  Good job on a clear and structured opinion art...   \n",
       "3  Great job on your comparison essay! Keep using...   \n",
       "4  You have a good start, add more details and co...   \n",
       "\n",
       "                                      raw_correction  \\\n",
       "0  A flight attendant is responsible for the safe...   \n",
       "1  Last year I visited Tokyo, and it was an unfor...   \n",
       "2  I believe that everyone who lives in this worl...   \n",
       "3  To create a comparison and contrast between my...   \n",
       "4                                    It's hard work.   \n",
       "\n",
       "                                          correction  \n",
       "0  <input>A flight attendant is responsible for t...  \n",
       "1  <input>Last year I visited <code a=\"NOUN\" c=\"T...  \n",
       "2  <input>I believe that everyone who lives in th...  \n",
       "3  <input>To create a comparison and contrast bet...  \n",
       "4  <input><code a=\"PRON\" c=\"It\">Its </code><code ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "median_map = {\n",
    "    \"A1\": 2,\n",
    "    \"A2\": 5,\n",
    "    \"B1\": 8,\n",
    "    \"B2\": 11,\n",
    "    \"C1\": 14,\n",
    "    \"C2\": 16\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"data_v2/sample_data_acc_gec.csv\")\n",
    "df = df[df[\"agreement_percentage\"] >= 60]\n",
    "#df['ef_level'] = df.apply(lambda row: median_map[row['cefr_level']] if pd.isna(row['ef_level']) else row['ef_level'], axis=1)\n",
    "\n",
    "#df[\"agreement_percentage\"].value_counts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id\n",
       "2d726061-d067-49a6-a950-5c33482ce17f    170\n",
       "cfc369d9-74da-4013-be4c-b8148993f658    169\n",
       "51184f66-e317-457a-bda9-d73a241b7871    168\n",
       "de7a1159-0c06-49bf-a273-7bdd195d6a32    166\n",
       "28757296-8797-428f-a562-0b03c304b341    166\n",
       "                                       ... \n",
       "178cfadd-4162-4b5b-aaee-97a1bdcd4d98     17\n",
       "511ccd73-9db8-45e5-8f85-10e244841ce2     16\n",
       "3ef52563-7f79-446a-b692-6435408e5461     15\n",
       "a1471208-6755-4814-aa1a-ab276be4d644     13\n",
       "d2196935-4153-4f5c-a1d2-dae31174ae55     10\n",
       "Name: count, Length: 160, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"task_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = (\n",
    "    \"Prompt Level: \" + df['ef_level'].astype(str) +\n",
    "    \" [SEP] Prompt: \" + df['activity_instructions'] +\n",
    "    \" [SEP] Response: \" + df['student_submission'] +\n",
    "    \" [SEP] Correction: \" + df['correction']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompt Level: 11.0 [SEP] Prompt: Read the blog post. Then write about a city you visited. Type in the input box. Write 90-110 words. Use your own words where possible. [SEP] Response: Last year I visited Paris, and it was an unforgettable experience. The city is famous for its elegance, art, and history. I loved walking along the Seine River and seeing the Eiffel Tower sparkle at night. I spent hours at the Louvre, where I admired the Mona Lisa and many other masterpieces. Montmartre was another highlightâ€”its artistic vibe and the view from the SacrÃ©-CÅ“ur were stunning. I also enjoyed tasting French cuisine, especially croissants and macarons. Paris is a magical city that combines beauty, culture, and charm. I canâ€™t wait to go back one day.\\n [SEP] Correction: <input>Last year I visited <code a=\"NOUN\" c=\"Tokyo\">Paris</code>, and it was an unforgettable experience. The city is famous for its <code a=\"NOUN\" c=\"technology\">elegance</code>, art, and history. I loved walking <code a=\"PREP\" c=\"through\">along</code> <code a=\"DET\" c=\"\">the </code><code a=\"NOUN\" c=\"Shibuya\">Seine River</code> and seeing the <code a=\"NOUN\" c=\"Tokyo\">Eiffel</code> Tower sparkle at night. I spent hours at the <code a=\"NOUN\" c=\"Tokyo National Museum\">Louvre</code>, where I admired <code a=\"PHRA\" c=\"ancient artifacts\">the Mona Lisa</code> and <code a=\"ADJ\" c=\"modern\">many other</code> <code a=\"NOUN\" c=\"art\">masterpieces</code>. <code a=\"NOUN\" c=\"Akihabara\">Montmartre</code> was another highlightâ€”its <code a=\"ADJ\" c=\"vibrant\">artistic</code> <code a=\"NOUN\" c=\"tech shops\">vibe</code> and <code a=\"PHRA\" c=\"anime culture\">the view from the SacrÃ©-CÅ“ur</code> were <code a=\"ADJ\" c=\"fascinating\">stunning</code>. I also enjoyed tasting <code a=\"ADJ\" c=\"Japanese\">French</code> cuisine, especially <code a=\"NOUN\" c=\"sushi\">croissants</code> and <code a=\"NOUN\" c=\"ramen\">macarons</code>. <code a=\"NOUN\" c=\"Tokyo\">Paris</code> is a magical city that combines beauty, culture, and <code a=\"NOUN\" c=\"innovation\">charm</code>. I canâ€™t wait to <code a=\"PHRA\" c=\"return\">go back</code> one day.<code a=\"PHRA\" c=\"\">\\n</code></input>'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: 7.0 [SEP] Prompt: Listen again t...</td>\n",
       "      <td>41c301bb-948b-4f55-a421-9da9be1aea3e</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 11.0 [SEP] Prompt: Read the blog...</td>\n",
       "      <td>6bd37619-8520-4e9f-b5e8-4d1b218f8a0d</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: 13.0 [SEP] Prompt: A website has...</td>\n",
       "      <td>8f1a0c16-d259-4737-af06-b6b6eb9e9799</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: 15.0 [SEP] Prompt: Write a compa...</td>\n",
       "      <td>bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>919c4050-62f4-4659-92e0-b8a696061e03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: 7.0 [SEP] Prompt: Listen again t...   \n",
       "1  Prompt Level: 11.0 [SEP] Prompt: Read the blog...   \n",
       "2  Prompt Level: 13.0 [SEP] Prompt: A website has...   \n",
       "3  Prompt Level: 15.0 [SEP] Prompt: Write a compa...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                task_id  ef_level  label  \n",
       "0  41c301bb-948b-4f55-a421-9da9be1aea3e       7.0    5.0  \n",
       "1  6bd37619-8520-4e9f-b5e8-4d1b218f8a0d      11.0    5.0  \n",
       "2  8f1a0c16-d259-4737-af06-b6b6eb9e9799      13.0    4.0  \n",
       "3  bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4      15.0    5.0  \n",
       "4  919c4050-62f4-4659-92e0-b8a696061e03       7.0    0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"task_id\", \"ef_level\", \"majority_value\"]]\n",
    "df = df.rename(columns={'majority_value': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task_id</th>\n",
       "      <th>ef_level</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt Level: 7.0 [SEP] Prompt: Listen again t...</td>\n",
       "      <td>41c301bb-948b-4f55-a421-9da9be1aea3e</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt Level: 11.0 [SEP] Prompt: Read the blog...</td>\n",
       "      <td>6bd37619-8520-4e9f-b5e8-4d1b218f8a0d</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt Level: 13.0 [SEP] Prompt: A website has...</td>\n",
       "      <td>8f1a0c16-d259-4737-af06-b6b6eb9e9799</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt Level: 15.0 [SEP] Prompt: Write a compa...</td>\n",
       "      <td>bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt Level: 7.0 [SEP] Prompt: Write an onlin...</td>\n",
       "      <td>6e8793e1-760b-43e0-a8a9-44dc11336782</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Prompt Level: 7.0 [SEP] Prompt: Listen again t...   \n",
       "1  Prompt Level: 11.0 [SEP] Prompt: Read the blog...   \n",
       "2  Prompt Level: 13.0 [SEP] Prompt: A website has...   \n",
       "3  Prompt Level: 15.0 [SEP] Prompt: Write a compa...   \n",
       "4  Prompt Level: 7.0 [SEP] Prompt: Write an onlin...   \n",
       "\n",
       "                                task_id  ef_level  label  \n",
       "0  41c301bb-948b-4f55-a421-9da9be1aea3e       7.0    5.0  \n",
       "1  6bd37619-8520-4e9f-b5e8-4d1b218f8a0d      11.0    5.0  \n",
       "2  8f1a0c16-d259-4737-af06-b6b6eb9e9799      13.0    4.0  \n",
       "3  bdd2883c-b71b-4fb7-a44c-a53e7bbf26f4      15.0    5.0  \n",
       "4  6e8793e1-760b-43e0-a8a9-44dc11336782       7.0    2.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the mapping to the 'labels' column\n",
    "#df['label'] = df['label'].map(label_mapping)\n",
    "df.dropna(subset=['label', 'text'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2.0    2069\n",
       "4.0    1651\n",
       "3.0    1541\n",
       "5.0    1445\n",
       "1.0     636\n",
       "0.0     130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'task_id', 'ef_level', 'label'],\n",
       "    num_rows: 7472\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d968d617f9d54a0ea1ee90ee543bedf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/7472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'task_id', 'ef_level', 'label'],\n",
       "    num_rows: 7472\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Value, Sequence\n",
    "new_features = ds.features.copy()\n",
    "new_features[\"label\"] = ClassLabel(names=[0, 1, 2, 3, 4, 5])\n",
    "ds = ds.cast(new_features)\n",
    "\n",
    "# Step 1: Initial train/test split with stratification\n",
    "train_test_ds = ds.train_test_split(test_size=0.20, seed=20)\n",
    "\n",
    "# Step 2: Split the test set into half test, half validation\n",
    "test_valid_split = train_test_ds['test'].train_test_split(test_size=0.5, seed=20)\n",
    "\n",
    "# Step 3: Combine everything into a single DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_ds['train'],\n",
    "    'test': test_valid_split['train'],    # This becomes the test set\n",
    "    'validation': test_valid_split['test']  # This becomes the validation set\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts: Counter({2: 1658, 4: 1285, 3: 1248, 5: 1163, 1: 525, 0: 98})\n",
      "Test label counts: Counter({2: 197, 4: 195, 5: 144, 3: 142, 1: 56, 0: 13})\n",
      "Validation label counts: Counter({2: 214, 4: 171, 3: 151, 5: 138, 1: 55, 0: 19})\n"
     ]
    }
   ],
   "source": [
    "# Verify label distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"Train label counts:\", Counter(dataset['train']['label']))\n",
    "print(\"Test label counts:\", Counter(dataset['test']['label']))\n",
    "print(\"Validation label counts:\", Counter(dataset['validation']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Fonction utilitaire pour sauvegarder un split en JSONL\n",
    "def save_split_to_jsonl(dataset_split, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for record in dataset_split:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Sauvegarde des trois splits\n",
    "save_split_to_jsonl(dataset['train'], 'data/train_gec.jsonl')\n",
    "save_split_to_jsonl(dataset['test'], 'data/test_gec.jsonl')\n",
    "save_split_to_jsonl(dataset['validation'], 'data/validation_gec.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de7761585ae4429938a2bfb6130fe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, cohen_kappa_score, classification_report\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convertir les logits en classes prÃ©dictes\n",
    "\n",
    "    # ðŸŽ¯ Exactitude (Accuracy)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # ðŸŽ¯ PrÃ©cision, Rappel et F1-score (pondÃ©rÃ©s)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # ðŸŽ¯ Score de Cohen's Kappa (pondÃ©rÃ©)\n",
    "    cohen_kappa = cohen_kappa_score(labels, predictions, weights=\"quadratic\")\n",
    "\n",
    "    # ðŸŽ¯ CorrÃ©lation de Pearson\n",
    "    pearson_corr, _ = pearsonr(labels, predictions)  # Retourne (coef, p-valeur), on garde seulement coef\n",
    "\n",
    "     # ðŸŽ¯ Classification Report\n",
    "    class_report = classification_report(labels, predictions, output_dict=True)  # Get a dictionary of the report\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"cohen_kappa\": cohen_kappa,\n",
    "        \"pearson_corr\": pearson_corr,\n",
    "        \"classification_report\": class_report  # Add classification report to the return\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "# Charger les fichiers JSONL en DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=\"data/train_gec.jsonl\")[\"train\"],\n",
    "    \"test\": load_dataset(\"json\", data_files=\"data/test_gec.jsonl\")[\"train\"],\n",
    "    \"validation\": load_dataset(\"json\", data_files=\"data/validation_gec.jsonl\")[\"train\"]\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3b7310176f41d281d4f3eee1b06340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c050f8ceb5bf464b851021fbc1d4d010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16edc6e48bcd47cab3af752e72836ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba3d014e1964e61823242e7b8eade89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a49eb65c6d64162bb695f2e5071c4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Prompt Level: 7.0 [SEP] Prompt: What problems can happen on board a ship? What are some solutions? Use your own ideas. Choose from one or two of the options provided and write 80-100 words. Options: general cargo safety and stowage; staffing levels and working conditions; general condition and maintenance of the vessel; safety standards; pollution [SEP] Response: A common problem onboard is related to the safety and stowage of general cargo. If cargo is poorly stowed, it can shift during navigation, causing damage to the vessel or even putting the crew at risk. To avoid this, it is essential to follow a proper stowage plan, use appropriate containment materials, and conduct regular inspections of the holds. Another important issue involves safety standards. Equipment such as life jackets and fire extinguishers must be accessible and within their expiration date. Regular training and emergency drills help keep the crew prepared for any situation.\\n\\n  [SEP] Correction: <input>A common problem onboard is related to the safety and stowage of general cargo. If cargo is poorly stowed, it can shift during navigation, causing damage to the vessel or even putting the crew at risk. To avoid this, it is essential to follow a proper stowage plan, use appropriate containment materials, and conduct regular inspections of the holds. Another important issue involves safety standards. Equipment such as life jackets and fire extinguishers must be accessible and within their expiration date. Regular training and emergency drills help keep the crew prepared for any situation.<code a=\"PHRA\" c=\"\">\\n\\n </code></input>',\n",
       " 'task_id': '3e9aee0e-9908-4ad0-aa60-a2f09ad38119',\n",
       " 'ef_level': 7.0,\n",
       " 'label': 5}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 35396, 3320, 12183, 35, 262, 4, 288, 646, 3388, 510, 742, 42944, 35, 978, 3116, 110, 3231, 12, 4892, 30999, 4, 9427, 7, 1606, 5, 1575, 5, 2257, 138, 56, 45, 1165, 36, 771, 6222, 2257, 6, 588, 12, 958, 2502, 420, 138, 8, 70, 2539, 6, 1950, 6818, 3748, 518, 238, 8, 67, 304, 103, 9, 110, 308, 2956, 4, 21062, 727, 12, 6115, 1617, 4, 7627, 5, 2788, 7, 244, 47, 4, 646, 3388, 510, 742, 19121, 35, 12191, 2488, 6362, 6006, 50118, 50118, 170, 236, 47, 7, 1606, 55, 1575, 7, 5, 695, 7, 5731, 18044, 2688, 11, 84, 609, 4, 1541, 138, 782, 16487, 13247, 14, 817, 84, 1230, 1074, 3013, 8, 18618, 4, 50118, 50118, 6715, 6, 465, 874, 5, 12628, 2192, 52, 236, 47, 7, 1606, 11, 5, 11554, 1743, 2257, 35, 50118, 12, 83, 12332, 14, 5, 2111, 64, 304, 7, 1349, 11, 697, 5, 18866, 9, 3057, 50118, 12, 32048, 62, 10, 980, 147, 916, 32, 441, 7, 8469, 19, 84, 518, 6, 10, 449, 9433, 9, 7359, 13, 697, 323, 50118, 12, 83, 1914, 2931, 14, 2029, 916, 41, 2319, 2996, 1248, 50118, 50118, 20867, 209, 1575, 6, 52, 351, 75, 28, 441, 7, 3014, 84, 17755, 4, 50140, 646, 3388, 510, 742, 35648, 35, 28696, 46797, 15698, 23314, 2488, 28696, 20414, 10, 40635, 3411, 3732, 113, 740, 40635, 37040, 46479, 8827, 6006, 49138, 20414, 49007, 20414, 10, 40635, 510, 4154, 7164, 113, 740, 5214, 4332, 49526, 20414, 15698, 50118, 50118, 170, 236, 47, 7, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_test = tokenizer(dataset[\"train\"][1][\"text\"], max_length=256, truncation=True)\n",
    "tok_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=312\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e80e39561b4597b8ca34263b5fccfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5977 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695873dd68ac41b99ef4526bbd9d7670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/747 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28abe5475e0545c2abedd8ef39a9e436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True)\n",
    "tokenized_valid = dataset[\"validation\"].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cf7a5bf9c74864a1b9cbf1accfa701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-large\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented\",\n",
    "    evaluation_strategy=\"steps\",  # Ã‰valuation aux mÃªmes intervalles que la sauvegarde\n",
    "    save_strategy=\"steps\",  # Sauvegarde tous les 500 steps\n",
    "    save_steps=200,\n",
    "    eval_steps=200,  # âš  IMPORTANT : Ã‰valuation aux mÃªmes steps\n",
    "    save_total_limit=4,  # Ne garde que 4 checkpoints max\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\", \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in PromptModelConfig has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "Using cuda_amp half precision backend\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:593: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5977\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1496\n",
      "  Number of trainable parameters = 355365894\n",
      "2026/02/23 12:05:40 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/02/23 12:05:40 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/02/23 12:05:40 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/02/23 12:05:40 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/02/23 12:05:40 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/02/23 12:05:40 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/02/23 12:05:41 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/02/23 12:05:41 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/02/23 12:05:41 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/23 12:05:41 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/02/23 12:05:41 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/02/23 12:05:41 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/02/23 12:05:41 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/02/23 12:05:42 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/02/23 12:05:43 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/02/23 12:05:43 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/02/23 12:05:43 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/02/23 12:05:43 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/02/23 12:05:43 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/02/23 12:05:43 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/02/23 12:05:43 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/02/23 12:05:44 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/02/23 12:05:44 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/02/23 12:05:44 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/02/23 12:05:44 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/02/23 12:05:44 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/02/23 12:05:45 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/02/23 12:05:45 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/02/23 12:05:45 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/02/23 12:05:45 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/02/23 12:05:45 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/02/23 12:05:46 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/02/23 12:05:46 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/02/23 12:05:46 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/02/23 12:05:46 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/02/23 12:05:46 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/02/23 12:05:47 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/02/23 12:05:47 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/02/23 12:05:47 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/02/23 12:05:48 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/02/23 12:05:48 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/02/23 12:05:48 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/02/23 12:05:48 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
      "2026/02/23 12:05:49 INFO alembic.runtime.migration: Running upgrade 1bd49d398cd23 -> b7c8d9e0f1a2, add trace metrics table\n",
      "2026/02/23 12:05:49 INFO alembic.runtime.migration: Running upgrade b7c8d9e0f1a2 -> 5d2d30f0abce, update job table\n",
      "2026/02/23 12:05:50 INFO alembic.runtime.migration: Running upgrade 5d2d30f0abce -> c9d4e5f6a7b8, add routing strategy to endpoints and linkage type to mappings\n",
      "2026/02/23 12:05:50 INFO alembic.runtime.migration: Running upgrade c9d4e5f6a7b8 -> 2c33131f4dae, add online_scoring_configs table\n",
      "2026/02/23 12:05:50 INFO alembic.runtime.migration: Running upgrade 2c33131f4dae -> d3e4f5a6b7c8, add display_name to endpoint_bindings\n",
      "2026/02/23 12:05:50 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/02/23 12:05:50 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='1496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  49/1496 00:22 < 11:28, 2.10 it/s, Epoch 0.13/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200/pytorch_model.bin\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400/pytorch_model.bin\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-600/pytorch_model.bin\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800/pytorch_model.bin\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1000\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1000/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1000\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1000/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-200] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1200\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1200/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1200\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1200/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-400] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: ef_level, task_id, text. If ef_level, task_id, text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 747\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1400\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1400/config.json\n",
      "Saving model checkpoint to ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1400\n",
      "Configuration saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1400/config.json\n",
      "Model weights saved in ../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [../../../model_saved/roberta-base-ft-acc-writing-gec-task-augmented/checkpoint-800] due to args.save_total_limit\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/trainer.py:2504: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  else torch.cuda.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic = dataset[\"valid\"][\"task_id\"]\n",
    "list_t_set = set(list_topic)\n",
    "unique_t = (list(list_t_set))\n",
    "\n",
    "list_level = dataset[\"valid\"][\"level_title\"]\n",
    "list_l_set = set(list_level)\n",
    "unique_l = (list(list_l_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for t in unique_t:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['task_id'] == t)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"task_id\": t,\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_r_level = []\n",
    "\n",
    "# Assuming 'unique_t' is a list of unique item_ids and 'trainer' is already defined\n",
    "for l in unique_l:  # Iterate over the first item in unique_t\n",
    "    sub_ds = tokenized_valid.filter(lambda example: example['level_title'] == l)\n",
    "    # Get predictions using the trainer\n",
    "    predictions = trainer.predict(sub_ds)\n",
    "    # Raw output logits (size [batch_size, num_classes])\n",
    "    outputs = predictions.predictions\n",
    "    # Convert logits to predicted class labels (taking the argmax across the classes)\n",
    "    predicted_labels = np.argmax(outputs, axis=-1)\n",
    "    ref_label = predictions.label_ids\n",
    "    # Print or save the predicted classes (this will be a numpy array with the predicted class indices)\n",
    "    ck = round(cohen_kappa_score(predicted_labels, ref_label, weights=\"quadratic\"), 2)  \n",
    "    pearson_corr, _ = pearsonr(ref_label, predicted_labels)\n",
    "    accuracy = accuracy_score(ref_label, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ref_label, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    r = {\n",
    "        \"level_title\": sub_ds[\"level_title\"][0],\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"ck\": ck,\n",
    "        \"pearson\": pearson_corr,\n",
    "        \"n_samples\": len(sub_ds)\n",
    "    }\n",
    "    list_r_level.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results = pd.DataFrame(list_r, columns=[\"task_id\", \"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results.to_csv(\"result_eval_data_roberta_large_writing_task_acc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_eval_results_level = pd.DataFrame(list_r_level, columns=[\"level_title\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"ck\", \"pearson\", \"n_samples\"])\n",
    "df_eval_results_level.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results_level.to_csv(\"result_eval_data_roberta_large_acc_by_level.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Chemin vers ton dossier contenant le .bin et le config.json\n",
    "#model_dir = \"model_saved/roberta-large-ft-acc-writing-task-augmented/checkpoint-1800\"\n",
    "model_dir=\"/tmp/tmpdxu3_htb\"\n",
    "onnx_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800.onnx\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800-quantized.onnx\"\n",
    "\n",
    "# === Ã‰TAPE 1 : Charger le modÃ¨le et tokenizer ===\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")\n",
    "model.eval()\n",
    "\n",
    "# === Ã‰TAPE 2 : PrÃ©parer un input fictif ===\n",
    "dummy_text = \"Texte d'exemple pour conversion ONNX\"\n",
    "inputs = tokenizer(dummy_text, return_tensors=\"pt\", padding=\"max_length\", max_length=256)\n",
    "\n",
    "# === Ã‰TAPE 3 : Exporter vers ONNX ===\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),\n",
    "    onnx_model_path,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits\": {0: \"batch_size\"},\n",
    "    },\n",
    "    opset_version=14  # â¬…ï¸ change ici\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le exportÃ© en ONNX : {onnx_model_path}\")\n",
    "\n",
    "# === Ã‰TAPE 4 : Quantization dynamique ===\n",
    "quantize_dynamic(\n",
    "    model_input=onnx_model_path,\n",
    "    model_output=quantized_model_path,\n",
    "    weight_type=QuantType.QInt8\n",
    ")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le quantifiÃ© en ONNX : {quantized_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "onnx_session_quant = onnxruntime.InferenceSession(quantized_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256  # Ajuste selon la taille maximale de ton modÃ¨le\n",
    "\n",
    "# Fonction d'infÃ©rence ONNX\n",
    "def onnx_infer(input_texts, onnx_model):\n",
    "    inputs = tokenizer(input_texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()\n",
    "    attention_mask = inputs[\"attention_mask\"].numpy()\n",
    "    onnx_inputs = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "    onnx_outputs = onnx_model.run(None, onnx_inputs)\n",
    "    return onnx_outputs[0]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_with_metrics(dataset, onnx_model, batch_size=16):\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    # tqdm pour afficher la progression sur les batches\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Evaluation\"):\n",
    "        batch = dataset[i:i + batch_size]\n",
    "        texts = batch[\"text\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        logits = onnx_infer(texts, onnx_model)\n",
    "        all_logits.extend(logits)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    all_logits = np.array(all_logits)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # ðŸ”¥ Appliquer compute_metrics\n",
    "    metrics = compute_metrics((all_logits, all_labels))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset\n",
    "# === Lancer l'Ã©valuation ===\n",
    "results = evaluate_with_metrics(valid_data, onnx_model=onnx_session_quant)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    \"s3\"\n",
    ")\n",
    "\n",
    "# Define your bucket name and desired path in S3\n",
    "bucket_name = \"sagemaker-studio-oxs6vznjds\"\n",
    "\n",
    "s3_key = \"writing_task_models/accuracy/model_1800_quantized_roberta_large.onnx\"  # Change path as needed\n",
    "# Upload the ONNX file\n",
    "bucket_path = \"sagemaker-studio-oxs6vznjds\"\n",
    "quantized_model_path = \"model_saved/roberta-large-ft-acc-writing-task-1800-quantized.onnx\"\n",
    "\n",
    "s3.upload_file(quantized_model_path, bucket_path, s3_key)\n",
    "\n",
    "print(f\"âœ… ONNX model uploaded to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Onnx from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Define S3 bucket and model key\n",
    "bucket_name = 'sagemaker-studio-oxs6vznjds'\n",
    "model_key = 'writing_task_models/accuracy/model_1800_quantized_roberta_large.onnx'\n",
    "local_model_path = '/tmp/roberta-large-ft-acc-writing-task-1800-quant.onnx'  # or wherever you want to save temporarily\n",
    "\n",
    "# Initialize boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Download the ONNX model from S3 to local path\n",
    "s3.download_file(bucket_name, model_key, local_model_path)\n",
    "\n",
    "# Load the ONNX model using onnxruntime\n",
    "session = ort.InferenceSession(local_model_path)\n",
    "\n",
    "print(\"ONNX model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = ds[\"validation\"]  # Ou \"valid\" selon ton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_with_metrics(valid_data, onnx_model=session)\n",
    "print(\"ðŸŽ¯ Evaluation Results ONNX :\")\n",
    "for k, v in results.items():\n",
    "    if k == \"classification_report\":\n",
    "        print(\"\\nðŸ“‹ Classification Report :\")\n",
    "        for label, metrics in v.items():\n",
    "            print(f\"{label}: {metrics}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
